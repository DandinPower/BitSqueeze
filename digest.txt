Directory structure:
└── BitSqueeze/
    ├── README.md
    ├── LICENSE
    ├── Makefile
    ├── run_all_tests.sh
    ├── docs/
    │   ├── float_family.md
    │   └── iq2_family.md
    ├── include/
    │   ├── bitsqueeze.h
    │   ├── datatype/
    │   │   ├── bf16.h
    │   │   └── fp16/
    │   │       ├── bitcasts.h
    │   │       ├── fp16.h
    │   │       └── macros.h
    │   ├── float_quantization/
    │   │   ├── bf16_impl.h
    │   │   ├── fp16_impl.h
    │   │   ├── fp4_impl.h
    │   │   ├── fp8_impl.h
    │   │   ├── mxfp4_impl.h
    │   │   ├── mxfp8_impl.h
    │   │   ├── nf4_dq_impl.h
    │   │   ├── nf4_impl.h
    │   │   └── nvfp4_impl.h
    │   ├── int_quantization/
    │   │   ├── iq2_s_impl.h
    │   │   ├── iq2_xs_impl.h
    │   │   ├── iq2_xxs_impl.h
    │   │   ├── q2_k_impl.h
    │   │   ├── q4_0_impl.h
    │   │   └── q8_0_impl.h
    │   ├── sparsity/
    │   │   └── topk_impl.h
    │   └── utils/
    │       ├── evaluation.h
    │       └── random.h
    ├── src/
    │   ├── bitsqueeze.c
    │   ├── float_quantization/
    │   │   ├── bf16_impl.c
    │   │   ├── fp16_impl.c
    │   │   ├── fp4_impl.c
    │   │   ├── fp8_impl.c
    │   │   ├── mxfp4_impl.c
    │   │   ├── mxfp8_impl.c
    │   │   ├── nf4_dq_impl.c
    │   │   ├── nf4_impl.c
    │   │   └── nvfp4_impl.c
    │   ├── int_quantization/
    │   │   ├── iq2_s_impl.c
    │   │   ├── iq2_xs_impl.c
    │   │   ├── iq2_xxs_impl.c
    │   │   ├── q2_k_impl.c
    │   │   ├── q4_0_impl.c
    │   │   └── q8_0_impl.c
    │   ├── sparsity_quantization/
    │   │   └── topk_impl.c
    │   └── utils/
    │       └── random.c
    └── test/
        ├── test_bf16_impl.c
        ├── test_fp16_impl.c
        ├── test_fp4_impl.c
        ├── test_fp8_impl.c
        ├── test_iq2_s_impl.c
        ├── test_iq2_xs_impl.c
        ├── test_iq2_xxs_impl.c
        ├── test_mxfp4_impl.c
        ├── test_mxfp8_impl.c
        ├── test_nf4_dq_impl.c
        ├── test_nf4_impl.c
        ├── test_nvfp4_impl.c
        ├── test_q2_k_impl.c
        ├── test_q4_0_impl.c
        ├── test_q8_0_impl.c
        ├── test_topk_impl.c
        └── legacy/
            ├── test_activation_example.c
            ├── test_bf16_datatype.c
            └── test_fp16_datatype.c

================================================
FILE: README.md
================================================
# BitSqueeze

## Introduction
BitSqueeze is a tiny C library for compressing float32 tensors with GGML-style integer quantization (Q8_0, Q4_0, Q2_K, NF4, NVFP4), compact floating formats (FP4, MXFP4, NF4_DQ, FP8, MXFP8, FP16, BF16), and Top-K sparsity. Implementations live in src/, headers in include/, and ready-to-run tests in test/. The focus is small, dependency-free C11 code that can be dropped into inference pipelines to trade accuracy for bandwidth.

## Quick start (pre-written tests)
Prereqs: C toolchain + make. All binaries land in `build/`.

```bash
# Build everything
make

# 1D quantizers and float downcasts
./build/test_q2_k_impl
./build/test_q4_0_impl
./build/test_q8_0_impl
./build/test_nf4_impl
./build/test_nf4_dq_impl
./build/test_nvfp4_impl
./build/test_fp4_impl
./build/test_fp8_impl
./build/test_fp16_impl
./build/test_bf16_impl
./build/test_mxfp4_impl
./build/test_mxfp8_impl

# 2D Top-K sparsity
./build/test_topk_impl
```

Notes:
- Each test emits per-array size and error metrics (MAE, MSE, MaxAbs).
- `test/legacy` is currently out-of-date; ignore it for now.

## bitsqueeze API essentials

### Core types
- `bsq_method_t` methods: `Q8_0`, `Q4_0`, `Q2_K`, `TOPK`, `BF16`, `FP16`.
- `bsq_shape_t`: captures 1D length or 2D token/feature counts (plus requested `sparse_ratio` for TOPK).
- `bitsqueeze_buffer_t`: opaque holder for compressed payloads. Always free with `bsq_free`.

### Entry points
- `bsq_compress_1d(const float *src, uint64_t num_elements, bsq_method_t method, bitsqueeze_buffer_t **out);`
- `bsq_compress_2d(const float *src, uint16_t num_tokens, uint16_t num_features, float sparse_ratio, bsq_method_t method, bitsqueeze_buffer_t **out);` (use with `TOPK`)
- `bsq_decompress(const bitsqueeze_buffer_t *buf, float *dst, uint64_t dst_num_elements);`
- `bsq_get_packed_size(const bitsqueeze_buffer_t *buf);` returns packed byte count.
- `load_bsq_from_buffer(const void *buffer, int64_t buffer_size);` to rehydrate from serialized bytes.
- `bsq_free(bitsqueeze_buffer_t *buf);`

### Minimal 1D usage
```c
#include "bitsqueeze.h"

const uint64_t N = 1048576;
float *src = ...;  /* your float32 data */

bitsqueeze_buffer_t *buf = NULL;
if (bsq_compress_1d(src, N, Q8_0, &buf) == 0) {
    float *dst = malloc(N * sizeof(float));
    bsq_decompress(buf, dst, N);

    int64_t packed_bytes = bsq_get_packed_size(buf);
    /* ... use dst ... */

    free(dst);
    bsq_free(buf);
}
```

### Minimal 2D TOPK usage
```c
#include "bitsqueeze.h"

const uint16_t TOKENS = 512, FEATURES = 8192;
const float SPARSE_RATIO = 0.1f; /* keep top 10% features per token */
const uint64_t N = (uint64_t)TOKENS * FEATURES;
float *src = ...;  /* flattened row-major [TOKENS, FEATURES] */

bitsqueeze_buffer_t *buf = NULL;
if (bsq_compress_2d(src, TOKENS, FEATURES, SPARSE_RATIO, TOPK, &buf) == 0) {
    float *dst = malloc(N * sizeof(float));
    bsq_decompress(buf, dst, N);
    bsq_free(buf);
    free(dst);
}
```

## Current method comparison (synthetic random data)
The following results come from the bundled tests using 5 arrays of length 4,194,304 drawn uniformly from [-10, 10] (Top-K uses 512x8,192). `B/W` is bits-per-value; lower means smaller storage. Originals are 32 b/value.

| Method        | Shape                         | Packed size (KB) | B/W      | MAE       | MSE        | MaxAbs   | Notes                     |
|---------------|-------------------------------|------------------|----------|-----------|------------|----------|---------------------------|
| BF16          | N=4,194,304                   | 8,192.047        | 16.00009 | 0.007295  | 0.000102   | 0.031250 | BF16 mantissa drop        |
| FP16          | N=4,194,304                   | 8,192.047        | 16.00009 | 0.000912  | 0.000002   | 0.003906 | 2-byte IEEE half          |
| TOPK (20%)    | 512x8,192 tokens/features     | 4,914.055        | 9.59776  | 3.198804  | 17.057529  | 8.116994 | Keeps 20% largest values  |
| Q8_0          | N=4,194,304                   | 4,608.070        | 9.00014  | 0.018508  | 0.000472   | 0.039366 | 8-bit per 32-value block  |
| MXFP8         | N=4,194,304                   | 4,224.070        | 8.25014  | 0.116640  | 0.026185   | 0.499999 | Mixed-precision 8-bit     |
| FP8           | N=4,194,304                   | 4,096.055        | 8.00011  | 0.110497  | 0.021687   | 0.357143 | 8-bit float               |
| Q4_0          | N=4,194,304                   | 2,560.070        | 5.00014  | 0.335504  | 0.155091   | 0.714271 | 4-bit per 32-value block  |
| TOPK (10%)    | 512x8,192 tokens/features     | 2,457.055        | 4.79893  | 4.048771  | 24.292203  | 9.102604 | Keeps 10% largest values  |
| NVFP4         | N=4,194,304                   | 2,304.078        | 4.50015  | 0.440604  | 0.342659   | 1.666665 | NVIDIA FP4                |
| NF4           | N=4,194,304                   | 2,304.070        | 4.50014  | 0.404979  | 0.277983   | 1.518787 | Normal-fused 4-bit        |
| MXFP4         | N=4,194,304                   | 2,176.070        | 4.25014  | 0.500061  | 0.433629   | 1.999998 | Mixed-precision 4-bit     |
| NF4_DQ        | N=4,194,304                   | 2,112.078        | 4.12515  | 0.413354  | 0.285722   | 1.519034 | Normal-fused 4-bit, decompressed |
| FP4           | N=4,194,304                   | 2,048.055        | 4.00011  | 0.485940  | 0.404944   | 1.666666 | Tiny float, 1 exponent bit |
| Q2_K          | N=4,194,304 (sb=256, b=16)    | 1,344.062        | 2.62512  | 1.335691  | 2.579342   | 3.330325 | K-quants, 2 bits + scales |

## License and contribution
- License: MIT (see `LICENSE`).
- Contributions: Issues and PRs welcome. Please keep changes focused, add/refresh tests under `test/`, and follow the existing C11 style (`-Wall -Wextra -Wpedantic`).



================================================
FILE: LICENSE
================================================
MIT License

Copyright (c) 2025 Gata.xyz, Yong-Cheng Liaw

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.


================================================
FILE: Makefile
================================================
CC      = gcc
CFLAGS  = -Wall -Wextra -Wpedantic -O3 -std=c11
LDFLAGS = -lm

INCLUDE_DIR = include
SRC_DIR     = src
BUILD_DIR   = build
TEST_DIR    = test

# -------------------------------------------------------------
# Sources
# -------------------------------------------------------------
LIB_SRCS  := $(shell find $(SRC_DIR) -name '*.c')
LIB_OBJS  := $(patsubst $(SRC_DIR)/%.c,$(BUILD_DIR)/%.o,$(LIB_SRCS))

TEST_SRCS := $(wildcard $(TEST_DIR)/*.c)
TEST_OBJS := $(patsubst $(TEST_DIR)/%.c,$(BUILD_DIR)/%.o,$(TEST_SRCS))
TEST_BINS := $(patsubst $(TEST_DIR)/%.c,$(BUILD_DIR)/%,$(TEST_SRCS))

# -------------------------------------------------------------
# Targets
# -------------------------------------------------------------
.PHONY: all clean

all: $(TEST_BINS)

$(BUILD_DIR)/%: $(BUILD_DIR)/%.o $(LIB_OBJS) | $(BUILD_DIR)
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) -I$(INCLUDE_DIR) -o $@ $^ $(LDFLAGS)

$(BUILD_DIR)/%.o: $(SRC_DIR)/%.c | $(BUILD_DIR)
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) -I$(INCLUDE_DIR) -c -o $@ $<

$(BUILD_DIR)/%.o: $(TEST_DIR)/%.c | $(BUILD_DIR)
	@mkdir -p $(dir $@)
	$(CC) $(CFLAGS) -I$(INCLUDE_DIR) -c -o $@ $<

$(BUILD_DIR):
	mkdir -p $(BUILD_DIR)

clean:
	rm -rf $(BUILD_DIR)



================================================
FILE: run_all_tests.sh
================================================
#!/bin/bash

# Configuration
TEST_DIR="build"
LOG_FILE="test_results.log"
GLOBAL_EXIT_CODE=0

# 1. Sanity Check: Does the directory exist?
if [ ! -d "$TEST_DIR" ]; then
    echo "Error: Directory '$TEST_DIR' not found."
    echo "Make sure you have built the project before running tests."
    exit 1
fi

echo "Searching for test_* executables in '$TEST_DIR'..."
echo "Output will be captured in $LOG_FILE for analysis."

# Clear previous log
> "$LOG_FILE"

# 2. Enable nullglob: prevents the loop from running once with the literal string 
# "build/test_*" if no files match.
shopt -s nullglob

FOUND_COUNT=0

for test_file in "$TEST_DIR"/test_*; do
    # 3. Check if it is a file and is executable
    if [ -f "$test_file" ] && [ -x "$test_file" ]; then
        ((FOUND_COUNT++))
        echo "---------------------------------------------------"
        echo "Running: $test_file"
        
        # Execute the test and pipe output to both console (tee) and log file
        # We wrap in a subshell to capture exit code correctly with PIPESTATUS if needed,
        # but here we just need to run it.
        "$test_file" | tee -a "$LOG_FILE"
        
        # Check exit code of the test (pipestatus[0] would be the test command)
        TEST_RESULT=${PIPESTATUS[0]}
        
        if [ $TEST_RESULT -ne 0 ]; then
            echo "FAILED: $test_file (Exit code: $TEST_RESULT)"
            GLOBAL_EXIT_CODE=1
        else
            echo "PASSED: $test_file"
        fi
    elif [ -f "$test_file" ]; then
        echo "WARNING: Found '$test_file' but it is not executable. Skipping."
        echo "         Run 'chmod +x $test_file' to fix this."
    fi
done

echo "---------------------------------------------------"

# 4. Final Report
if [ "$FOUND_COUNT" -eq 0 ]; then
    echo "No test executables found in '$TEST_DIR'."
    exit 0 
fi

if [ $GLOBAL_EXIT_CODE -eq 0 ]; then
    echo "SUCCESS: All $FOUND_COUNT tests passed."
    
    # 5. Parse logs and generate intermediate stats file
    # We use mktemp to create a safe temporary file for the raw stats
    RAW_STATS=$(mktemp)
    
    awk '
    BEGIN {
        # No header here, we print raw data for sorting
    }
    # Pattern 1: Capture Algorithm Name and Metrics (B/W, MAE, etc.)
    /B\/W=/ {
        name = $1;
        gsub(":", "", name);
        gsub(",", "", $0);

        for(i=1; i<=NF; i++) {
            if($i ~ /^B\/W=/) { split($i, a, "="); bw = a[2]; }
            if($i ~ /^MAE=/)  { split($i, a, "="); mae = a[2]; }
            if($i ~ /^MSE=/)  { split($i, a, "="); mse = a[2]; }
            if($i ~ /^MaxAbs=/) { split($i, a, "="); maxabs = a[2]; }
        }

        sum_bw[name] += bw;
        sum_mae[name] += mae;
        sum_mse[name] += mse;
        sum_maxabs[name] += maxabs;
        count[name]++;
        active_algo = name;
    }

    # Pattern 2: Capture Times
    /CompTime=/ {
        if (active_algo != "") {
            gsub(",", "", $0);
            ct = 0; dt = 0;
            for(i=1; i<=NF; i++) {
                if($i ~ /^CompTime=/)   { split($i, a, "="); ct = a[2]; }
                if($i ~ /^DecompTime=/) { split($i, a, "="); dt = a[2]; }
            }
            sum_comp[active_algo] += ct;
            sum_decomp[active_algo] += dt;
        }
    }

    END {
        # Print Aggregated Results: Name BW Comp Decomp MAE MSE MaxAbs
        for (name in count) {
            n = count[name];
            if (n > 0) {
                printf "%s %.5f %.3f %.3f %.6f %.6f %.6f\n", 
                    name, 
                    sum_bw[name]/n, 
                    sum_comp[name]/n, 
                    sum_decomp[name]/n, 
                    sum_mae[name]/n, 
                    sum_mse[name]/n, 
                    sum_maxabs[name]/n
            }
        }
    }' "$LOG_FILE" > "$RAW_STATS"

    # Define a helper variable for the table formatting awk script to reuse it
    FORMAT_AWK='
    BEGIN {
        print "-------------------------------------------------------------------------------------------------------";
        printf "%-12s | %-10s | %-12s | %-12s | %-10s | %-10s | %-10s\n", "Datatype", "B/W", "Comp(ms)", "Decomp(ms)", "MAE", "MSE", "MaxAbs";
        print "-------------------------------------------------------------------------------------------------------";
    }
    {
        printf "%-12s | %-10.5f | %-12.3f | %-12.3f | %-10.6f | %-10.6f | %-10.6f\n", $1, $2, $3, $4, $5, $6, $7;
    }'

    # --- Table 1: Sorted by B/W (Column 2) ---
    echo ""
    echo "================ PERFORMANCE SUMMARY (Sorted by B/W) ================"
    sort -k2 -n "$RAW_STATS" | awk "$FORMAT_AWK"

    # --- Table 2: Sorted by CompTime (Column 3) ---
    echo ""
    echo "================ PERFORMANCE SUMMARY (Sorted by CompTime) ==========="
    sort -k3 -n "$RAW_STATS" | awk "$FORMAT_AWK"

    # --- Table 3: Sorted by MSE (Column 6) ---
    echo ""
    echo "================ PERFORMANCE SUMMARY (Sorted by MSE) ================"
    sort -k6 -n "$RAW_STATS" | awk "$FORMAT_AWK"

    # Clean up
    rm "$RAW_STATS"

else
    echo "FAILURE: One or more tests failed."
fi

exit $GLOBAL_EXIT_CODE


================================================
FILE: docs/float_family.md
================================================
# Floating-point Quantization Formats: FP16/BF16 → FP8 → FP4/NF4

## 16-bit formats: FP16 and BF16

These share the same width (16 bits) but trade exponent vs mantissa differently.

![image.png](Floating-point%20Quantization%20Formats%20FP16%20BF16%20%E2%86%92%20FP/image.png)

### Format and properties

- **FP16 (half precision)**
    - Bit layout: 1 sign, 5 exponent, 10 mantissa bits.
    - Higher precision than BF16 for values within its range, but significantly narrower dynamic range than FP32.
- **BF16 (bfloat16)**
    - Bit layout: 1 sign, 8 exponent, 7 mantissa bits.
    - Same exponent range as FP32, so almost the same *dynamic range* but with much less precision.
    - Widely supported on TPUs and modern GPUs for large-model training.

### Quantization / dequantization

From an FP32 tensor:

- **Quantization**
    - Convert each FP32 value to FP16 or BF16 via IEEE rounding to nearest representable value.
    - No explicit scaling factor; the exponent/mantissa structure is fixed.
- **Dequantization**
    - Cast back to FP32. The cast is exact in the sense that it perfectly recovers the FP16/BF16 value encoded; the error is solely from the earlier rounding.

### Bits per weight (8,192-element tensor for 72b activation)

For both FP16 and BF16:

- Data: 16 bits per weight.
- Total: 8,192 × 16 = 131,072 bits.
- Effective bits/weight: **16.00**.

---

## 8-bit formats: FP8 E4M3 and E5M2 (general FP8)

Proposed by NVIDIA, INTEL, ARM: https://arxiv.org/abs/2209.05433

![Screenshot 2025-11-17 at 1.46.28 PM.png](Floating-point%20Quantization%20Formats%20FP16%20BF16%20%E2%86%92%20FP/Screenshot_2025-11-17_at_1.46.28_PM.png)

### Format and properties

- **E4M3**
    - 1 sign, 4 exponent, 3 mantissa bits.
    - Better *precision* inside a narrower dynamic range.
    - Typically used for *weights and activations* in FP8 training.
- **E5M2**
    - 1 sign, 5 exponent, 2 mantissa bits.
    - Larger dynamic range but less precision.
    - Typically used for *gradients*, which need range more than fine mantissa.

### Hypothesis and motivation

- Hypothesis: we can push precision down to 8 bits if we:
    - Carefully choose which tensors use which FP8 variant.
    - Introduce scaling factors per tensor (or block) instead of a single global loss scale.
- Motivation:
    - 2× memory reduction versus FP16.
    - Higher Tensor Core throughput, especially on Hopper/Blackwell.
    - With proper scaling “recipes” (*one* FP32 scale per tensor.), training convergence can match BF16 for many LLMs.

### Quantization / dequantization

From FP32 to FP8:

1. Choose a scaling factor `s` (FP32), e.g. via amax history or current tensor stats.
2. For each FP32 element `x`:
    - Compute `x_scaled = x / s`.
    - Round `x_scaled` to the nearest representable FP8 value in E4M3 or E5M2.
    - Store `x_fp8`.

Dequantization back to FP32:

- Read `x_fp8`, cast to FP32: `x_fp8_fp32`.
- Reconstruct `x_hat = s * x_fp8_fp32`.

The error comes from:

- Rounding into FP8.
- Any mismatch between the tensor’s actual distribution and the chosen `s`.

### Bits per weight (8,192-element tensor)

Assuming 1 FP32 scale per whole tensor:

- Data: 8 bits × 8,192 = 65,536 bits.
- Scale: 1 FP32 = 32 bits.
- Total bits: 65,536 + 32 = 65,568 bits.
- Effective bits/weight: 65,568 / 8,192 ≈ **8.00** bits (≈ 8.004).

---

## MXFP8 (micro-scaling FP8)

MXFP8 is a *block-scaled* FP8 scheme introduced by Open Compute Project: [https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf)

![image.png](Floating-point%20Quantization%20Formats%20FP16%20BF16%20%E2%86%92%20FP/image%201.png)

### Format and properties

- Data: FP8 values in **E4M3** for all tensors.
- Scaling:
    - Tensor is partitioned into contiguous blocks of **32 values**.
    - Each 32-value block has its own scale, encoded as an **E8M0** 8-bit exponent-only format (power-of-two scaling).

### Hypothesis and motivation

- Standard FP8 with a *single* FP32 scale per tensor can struggle with tensors that have wide dynamic range; some values saturate or collapse to zero.
- Hypothesis: if we assign a scale per small block, each block can use the high-precision E4M3 format without needing E5M2.
- Motivation:
    - Improve FP8 accuracy by better matching local magnitude structure.
    - Still keep 8-bit data and compact 8-bit scales managed in hardware.

### Quantization / dequantization

Given FP32 tensor `X`:

1. Partition `X` into blocks of 32 consecutive values.
2. For each block `b`:
    - Select scale `s_b` as an E8M0 value (power-of-two) that best fits that block (e.g., via amax or MSE minimization).
    - Compute `x_scaled = X_b / s_b`.
    - Quantize `x_scaled` elementwise to FP8 E4M3, storing 8-bit codes.
3. Dequantization:
    - For each block, convert `s_b` (E8M0) to FP32.
    - Cast FP8 codes back to FP32 values, multiply by `s_b` to reconstruct.

### Bits per weight (8,192-element tensor)

- Data: 8 bits × 8,192 = 65,536 bits.
- Scales:
    - Blocks: 8,192 / 32 = 256 blocks.
    - One 8-bit E8M0 scale per block → 256 × 8 = 2,048 bits.
- Total: 65,536 + 2,048 = 67,584 bits.
- Effective bits/weight: 67,584 / 8,192 = **8.25** bits.

---

## FP4 family: FP4 (E2M1), MXFP4, NVFP4

Mainstream float4 datatypes include three main 4-bit floating point schemes based on an E2M1 core: FP4, MXFP4, and NVFP4.

All of them use a 4-bit float:

- 1 sign, 2 exponent, 1 mantissa bit.
- Values roughly in range about −6 to 6 (examples given: 0.0, 0.5, 1.0, 1.5, 2, 3, 4, 6, and negatives).

### Plain FP4 (E2M1 + scale)

**Format and properties**

- Data: 4-bit E2M1 FP plus a “FP32 Scale Factor”

**Hypothesis and motivation**

- Hypothesis: For some inference workloads, 4 bits are enough if we allow a good float scale.
- Motivation:
    - Up to 4× less memory than FP16.
    - But quantization error can be large; accuracy often noticeably worse than FP8.

**Quantization / dequantization**

From FP32 tensor `X`:

1. Choose a scale `s` (FP32) for the entire tensor or for a coarse block.
2. Quantization:
    - `x_scaled = X / s`.
    - Round `x_scaled` into the nearest representable E2M1 value, store as 4-bit FP4.
3. Dequantization:
    - Cast FP4 to FP32, then multiply by `s`.

**Bits per weight (8,192-element tensor)**

Assume one FP32 scale for entire tensor:

- Data: 4 bits × 8,192 = 32,768 bits.
- Scale: 32 bits.
- Total: 32,768 + 32 = 32,800 bits.
- Effective bits/weight: 32,800 / 8,192 ≈ **4.00** bits (≈ 4.004).

---

### MXFP4 (E2M1 + per-block E8M0 scale)

also introduced by Open Compute Project: [https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf)

**Format and properties**

- Data: 4-bit E2M1.
- Scaling: One shared **power-of-two scale** (E8M0) per block of **32 values**.

**Hypothesis and motivation**

- FP4 with only a per-tensor scale can drop accuracy aggressively.
- Hypothesis: finer-grained per-block scaling cuts error significantly while keeping formats simple.
- Motivation:
    - Still up to 4× less memory than FP16.
    - Simpler scales (power-of-two) are cheap, but may be coarse so better than pure FP4

**Quantization / dequantization**

Given FP32 tensor:

1. Partition into 32-value blocks.
2. For each block:
    - Choose E8M0 scale `s_b` (power-of-two) that minimizes quantization error for that block.
    - Compute `x_scaled = X_b / s_b`.
    - Quantize `x_scaled` into 4-bit FP4 E2M1.
3. Dequantization:
    - `x_hat = s_b * cast_fp4_to_fp32(x_q)` for each value in the block.

**Bits per weight (8,192-element tensor)**

- Data: 4 bits × 8,192 = 32,768 bits.
- Scales:
    - Blocks: 8,192 / 32 = 256 blocks.
    - Each block has one 8-bit E8M0 scale → 256 × 8 = 2,048 bits.
- Total: 32,768 + 2,048 = 34,816 bits.
- Effective bits/weight: 34,816 / 8,192 = **4.25** bits.

---

### NVFP4 (E2M1 + FP8 E4M3 micro-block scale + FP32 tensor scale)

![Screenshot 2025-11-17 at 1.58.09 PM.png](Floating-point%20Quantization%20Formats%20FP16%20BF16%20%E2%86%92%20FP/Screenshot_2025-11-17_at_1.58.09_PM.png)

NVFP4 is a new 4-bit format introduced for Blackwell, designed to achieve near-FP8 accuracy at FP4 cost.

**Format and properties**

- Core data: 4-bit E2M1 (weights in −6 to 6-ish).
- Scaling:
    - Per 16-value micro-block: a shared FP8 **E4M3** scale factor.
    - Per tensor: a second FP32 scale factor.
- So reconstructed values look like:
    - `x ≈ S_tensor * s_block * x_q`, where:
        - `x_q` is 4-bit E2M1,
        - `s_block` is FP8 E4M3,
        - `S_tensor` is FP32.

**Hypothesis and motivation**

![image.png](Floating-point%20Quantization%20Formats%20FP16%20BF16%20%E2%86%92%20FP/image%202.png)

- Hypothesis: 4-bit E2M1 plus *two-level scaling* can preserve “model intelligence” close to FP8.
- Motivation:
    - Smaller block size (16 vs 32 in MXFP4) improves how well scaling matches local dynamic range.
    - E4M3 scales allow fractional (non-power-of-two) scaling, lowering MSE compared to E8M0.
    - NVIDIA reports roughly 3.5× memory reduction relative to FP16 and 1.8× relative to FP8 with small accuracy drop on LLM benchmarks.

**Quantization / dequantization**

For FP32 tensor `X`:

1. Compute a per-tensor scale `S_tensor` (FP32) to normalize the overall range so that per-block E4M3 scales stay in a good range.
2. Partition `X` (already normalized by `S_tensor`) into blocks of **16 values**.
3. For each 16-value block:
    - Choose FP8 E4M3 scale `s_block` that minimizes block error.
    - Compute `x_norm = X_block / (S_tensor * s_block)`.
    - Quantize `x_norm` to 4-bit E2M1 (FP4) values `x_q`.
4. Dequantization:
    - For each block: `x_hat = S_tensor * s_block * cast_fp4_to_fp32(x_q)`.

**Bits per weight (8,192-element tensor)**

- Data: 4 bits × 8,192 = 32,768 bits.
- FP8 E4M3 per-block scales:
    - Blocks: 8,192 / 16 = 512.
    - Each scale: 8 bits → 512 × 8 = 4,096 bits.
- FP32 per-tensor scale: 32 bits.
- Total: 32,768 + 4,096 + 32 = 36,896 bits.
- Effective bits/weight: 36,896 / 8,192 ≈ **4.50** bits (≈ 4.504).

---

## NF4 (NormalFloat 4 from QLoRA)

NF4 is *not* a sign/exponent/mantissa float. It is a 4-bit nonuniform quantizer designed specifically for zero-mean normal distributions, used in QLoRA for 4-bit LLM finetuning: https://arxiv.org/abs/2305.14314

### Format and properties

- NF4 defines 16 real-valued levels `q_i` in the range [−1, 1], chosen as quantiles of a standard normal distribution N(0, 1) and then normalized.
- Its key property: *each quantization bin has equal expected probability* under N(0, 1), making it information-theoretically optimal for normally distributed weights.
- Zero is explicitly included as one of the levels so padding or exact zeros can be represented losslessly.

In practice QLoRA uses NF4 for weights and BF16 for compute.

### Hypothesis and motivation

- Empirical observation: pretrained transformer weights are close to zero-mean, Gaussian-distributed with varying standard deviations.
- Hypothesis: if we design a quantizer matched to N(0, 1), then after a simple blockwise normalization, we can:
    - Use only 4 bits per weight.
    - Achieve much lower quantization error than uniform/linear or log quantization.
- Motivation:
    - Enable PEFT finetuning of large LLMs with 4-bit base weights while retaining near 16-bit quality.

### Quantization / dequantization in QLoRA

QLoRA uses *block-wise* NF4 with **block size B = 64** and **Double Quantization (DQ)** for the scales.

For each block of 64 FP32 weights:

1. **Compute first-level quantization constant `c2` (FP32)**
    - Typically via absmax or similar normalization:
        - Normalize weights: `w_norm = w / c2`, bringing them into [−1, 1].
2. **Quantize to NF4**
    - For each normalized value `w_norm`:
        - Find nearest NF4 level `q_i`.
            
            ```c
            [-1.0, -0.6961928009986877, -0.5250730514526367,
            -0.39491748809814453, -0.28444138169288635, -0.18477343022823334,
            -0.09105003625154495, 0.0, 0.07958029955625534, 0.16093020141124725,
            0.24611230194568634, 0.33791524171829224, 0.44070982933044434,
            0.5626170039176941, 0.7229568362236023, 1.0]
            ```
            
        - Store index `i` as a 4-bit code.
3. **Double Quantization of scales**
    - All first-level FP32 scales `c2` are themselves grouped (block size 256) and quantized using an FP8 format with its own FP32 scale `c1`.
    - This reduces per-weight scale overhead from 32/64 = 0.5 bits to:
        - `8/64 + 32/(64 · 256) ≈ 0.127` bits per parameter.

Dequantization:

- Recover `c2` via FP8 dequantization using `c1`, then recover each block:
    - `w_hat ≈ c2 * q_i`, then cast to BF16 for compute.

### Bits per weight (8,192-element tensor)

- NF4 codes:
    - 4 bits × 8,192 = 32,768 bits.
- Scale overhead:
    - We have 8192 / 64 = 128 blocks
    - FP8 Block scaling overhead bits = 128 x 8 = 1024 bits
    - Fp32 Scaling factor for FP8 Block Scaling factors = 32 bits
- Total bits: 32,768 + 1,024 + 32 =  = 33,824 bits.
- Effective bits/weight: 33,824 / 8,192 ≈ **4.13** bits.

For comparison, without Double Quantization, NF4 with FP32 scales per 64 weights would use 4.50 bits/weight (4 bits + 32/64).

---

## Summary Comparison Table (8192 FP32 weights)

| Format / Scheme | Width & core structure | Scaling strategy | Bits per weight |
| --- | --- | --- | --- |
| FP32 | 32-bit, 1-8-23 | None | **32.00** |
| FP16 | 16-bit, 1-5-10 | None | **16.00** |
| BF16 | 16-bit, 1-8-7 | None | **16.00** |
| MXFP8 (E4M3 + E8M0 per 32 blk) | 8-bit E4M3 | E8M0 scale per 32-value block | **8.25** |
| FP8 (E4M3/E5M2 + FP32 tensor) | 8-bit E4M3 or E5M2 | 1 FP32 scale per tensor | **8.00** |
| NVFP4 (E2M1 + E4M3 + FP32) | 4-bit E2M1 | FP8 E4M3 per 16-value block + FP32 per tensor | **4.50** |
| NF4 (w/o DQ) | 4-bit NF4 (16 quantile-based levels) | FP32 scale per 64-value block | 4.50 |
| MXFP4 (E2M1 + E8M0 per 32 blk) | 4-bit E2M1 | E8M0 scale per 32-value block | **4.25** |
| NF4 (w DQ) | 4-bit NF4 (16 quantile-based levels) | FP32+FP8 Double Quantization of block scales | **4.13** |
| FP4 (E2M1 + FP32 tensor) | 4-bit E2M1 | 1 FP32 scale per tensor | **4.00** |

---

## References:

1. MXFP8, MXFP4: [https://arxiv.org/pdf/2310.10537](https://arxiv.org/pdf/2310.10537)
2. MXFP8, MXFP4: [https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf](https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf)
3. FP8: [https://arxiv.org/pdf/2209.05433](https://arxiv.org/pdf/2209.05433)
4. NVFP4: [https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/](https://developer.nvidia.com/blog/introducing-nvfp4-for-efficient-and-accurate-low-precision-inference/)
5. NVFP4: [https://arxiv.org/pdf/2509.25149v1](https://arxiv.org/pdf/2509.25149v1)
6. NF4: [https://arxiv.org/pdf/2305.14314](https://arxiv.org/pdf/2305.14314)


================================================
FILE: docs/iq2_family.md
================================================
# A Deep Dive into GGML IQ2 Quantization

This tutorial explains how GGML's IQ2 (Importance-matrix Quantization, 2-bit) family works, based entirely on the source code provided. IQ2 is a sophisticated approach to achieving near-2-bit-per-weight compression while maintaining quality through clever encoding tricks.

## High-Level Concept

### The Core Idea: Constrained Codebook Quantization

Traditional 2-bit quantization would allow each weight to independently take one of 4 values (00, 01, 10, 11). IQ2 takes a radically different approach: instead of quantizing individual values, it quantizes **groups of 8 values together** by constraining them to lie on a precomputed **grid** (codebook) of valid combinations.

Think of it this way: if you have 8 values each taking 4 possible states independently, you'd have 4^8 = 65,536 possible combinations. But IQ2 restricts this to only 256, 512, or 1024 carefully chosen combinations (depending on the variant). This restriction actually *improves* quality because the valid grid points are selected to match typical neural network weight distributions.

### The Three IQ2 Variants

The code defines three variants with increasing bits-per-weight (bpw):

| Variant | bpw | Grid Size | Key Tradeoff |
|---------|-----|-----------|--------------|
| IQ2_XXS | 2.0625 | 256 | Smallest, most compressed |
| IQ2_XS | 2.3125 | 512 | Middle ground |
| IQ2_S | 2.5625 | 1024 | Highest quality |

The "extra" bits beyond 2.0 come from storing per-group scales and using larger grids.

---

## Data Structures

Let me walk through the block structures, since understanding them is essential:

```c
#define QK_K 256  // Super-block size: 256 values per block

// IQ2_XXS: 2.0625 bpw
typedef struct {
    ggml_half d;              // 16-bit block scale
    uint16_t qs[QK_K/8];      // 32 uint16's = 64 bytes of quantized data
} block_iq2_xxs;              // Total: 2 + 64 = 66 bytes for 256 values
```

For 256 values in 66 bytes: 66 * 8 / 256 = **2.0625 bpw**. The math checks out.

```c
// IQ2_XS: 2.3125 bpw
typedef struct {
    ggml_half d;              // 16-bit block scale
    uint16_t qs[QK_K/8];      // 32 uint16's
    uint8_t scales[QK_K/32];  // 8 additional scale bytes
} block_iq2_xs;               // Total: 2 + 64 + 8 = 74 bytes
```

74 * 8 / 256 = **2.3125 bpw**.

---

## The Grid Tables: The Heart of IQ2

The magic lies in these lookup tables. Let's examine `iq2xxs_grid`:

```c
GGML_TABLE_BEGIN(uint64_t, iq2xxs_grid, 256)
    0x0808080808080808, 0x080808080808082b, 0x0808080808081919, ...
GGML_TABLE_END()
```

Each 64-bit entry encodes 8 values (one per byte). The bytes represent the **dequantized values directly**. Looking at the initialization code reveals the encoding:

```c
for (int k = 0; k < grid_size; ++k) {
    int8_t * pos = (int8_t *)(the_grid + k);
    for (int i = 0; i < 8; ++i) {
        int l = (kgrid[k] >> 2*i) & 0x3;  // Extract 2-bit index (0-3)
        pos[i] = 2*l + 1;                  // Map to {1, 3, 5, 7}
    }
}
```

So the 2-bit indices {0, 1, 2, 3} map to odd values {1, 3, 5, 7}. The actual grid entries store these decoded values directly for fast dequantization.

**Example**: The hex value `0x08` = 8 in decimal, but looking at the raw grid source:
- `kgrid_2bit_256[0] = 0` means all 2-bit indices are 0, giving eight 1's → stored as `0x0101010101010101`

Wait, let me re-examine. The grid stores the *decoded* odd values {1, 3, 5, 7}... actually looking at `0x08`, that's just 8. Looking more carefully at the bytes:

- `0x08` = 8, `0x19` = 25, `0x2b` = 43

These don't immediately correspond to {1,3,5,7}. Let me trace through the dequantization to understand the actual encoding.

---

## Dequantization Flow (The Easier Direction)

Let's trace through `dequantize_row_iq2_xxs` to understand how data is unpacked:

```c
void dequantize_row_iq2_xxs(const block_iq2_xxs * x, float * y, int64_t k) {
    const int64_t nb = k / QK_K;  // Number of blocks
    
    uint32_t aux32[2];
    const uint8_t * aux8 = (const uint8_t *)aux32;

    for (int i = 0; i < nb; i++) {
        const float d = GGML_FP16_TO_FP32(x[i].d);  // Block scale
        
        for (int ib32 = 0; ib32 < QK_K/32; ++ib32) {  // 8 groups of 32 values
            // Load 8 bytes of quantized data
            memcpy(aux32, x[i].qs + 4*ib32, 2*sizeof(uint32_t));
            
            // Extract group scale from upper 4 bits of aux32[1]
            const float db = d * (0.5f + (aux32[1] >> 28)) * 0.25f;
            
            for (int l = 0; l < 4; ++l) {  // 4 sub-groups of 8 values
                // aux8[l] is the grid index (0-255)
                const uint8_t * grid = (const uint8_t *)(iq2xxs_grid + aux8[l]);
                
                // Extract 7-bit sign pattern
                const uint8_t signs = ksigns_iq2xs[(aux32[1] >> 7*l) & 127];
                
                for (int j = 0; j < 8; ++j) {
                    y[j] = db * grid[j] * (signs & kmask_iq2xs[j] ? -1.f : 1.f);
                }
                y += 8;
            }
        }
    }
}
```

### Breaking Down the Dequantization Step-by-Step

**Step 1: Block Structure**
- Each block contains 256 values
- Processed in 8 groups of 32 values each
- Each 32-value group uses 8 bytes (64 bits) of `qs` data

**Step 2: Data Packing in aux32**
The 8 bytes for each 32-value group are interpreted as two 32-bit words:
- `aux32[0]`: Contains 4 grid indices (bytes 0-3), each indexing into `iq2xxs_grid`
- `aux32[1]`: Contains sign patterns and the group scale

**Step 3: Scale Computation**
```c
const float db = d * (0.5f + (aux32[1] >> 28)) * 0.25f;
```
- `aux32[1] >> 28` extracts a 4-bit scale factor (0-15)
- This gives a multiplier range of 0.5 to 15.5, then divided by 4
- Combined with block scale `d`, this gives fine-grained control

**Step 4: Grid Lookup**
```c
const uint8_t * grid = (const uint8_t *)(iq2xxs_grid + aux8[l]);
```
Each byte `aux8[l]` (values 0-255) indexes directly into the 256-entry grid to get 8 dequantized values.

**Step 5: Sign Application**
```c
const uint8_t signs = ksigns_iq2xs[(aux32[1] >> 7*l) & 127];
```

This is clever! The sign pattern for each 8-value sub-group is stored in 7 bits (not 8). How? Through a **parity constraint**: the product of all 8 signs is forced to be +1 (even number of negatives). Given 7 bits, the 8th sign is determined.

The `ksigns_iq2xs` table maps 7-bit patterns to 8-bit sign masks:
```c
GGML_TABLE_BEGIN(uint8_t, ksigns_iq2xs, 128)
    0, 129, 130, 3, 132, 5, 6, 135, ...
GGML_TABLE_END()
```

Looking at a few entries:
- Index 0 → 0 (00000000): no negatives
- Index 1 → 129 (10000001): bits 0 and 7 set
- Index 3 → 3 (00000011): bits 0 and 1 set

Each output has an even number of 1-bits, confirming the parity constraint.

---

## Quantization Flow (The Complex Direction)

Now let's trace `quantize_row_iq2_xxs_impl`, which is more involved:

### Phase 1: Setup and Importance Weighting

```c
const float * xbl = x + QK_K*ibl;
float sumx2 = 0;
for (int i = 0; i < QK_K; ++i) sumx2 += xbl[i]*xbl[i];
float sigma2 = sumx2/QK_K;  // Variance estimate

// Later, for each value:
weight[i] = qw[i] * sqrtf(sigma2 + xb[i]*xb[i]);
```

The quantization is **importance-weighted**: values with larger magnitude get more weight in the optimization. This is the "importance matrix" in IQ - it's not a literal matrix, but rather per-value weights that prioritize accurate representation of larger weights.

### Phase 2: Sign Handling with Parity Constraint

```c
for (int k = 0; k < 4; ++k) {
    int nflip = 0;
    uint8_t s = 0;
    for (int i = 0; i < 8; ++i) {
        if (xb[8*k + i] >= 0) 
            xval[8*k + i] = xb[8*k + i];
        else {
            xval[8*k + i] = -xb[8*k + i];  // Make positive
            ++nflip; 
            s |= (1 << i);  // Record sign
        }
    }
    // Enforce even parity
    if (nflip % 2) {
        // Find the value with smallest weighted magnitude
        int imin = 0; 
        float min = weight[8*k+imin]*xb[8*k+imin]*xb[8*k+imin];
        for (int i = 1; i < 8; ++i) {
            float ax = weight[8*k+i]*xb[8*k+i]*xb[8*k+i];
            if (ax < min) { min = ax; imin = i; }
        }
        // Flip the least important sign
        xval[8*k+imin] = -xval[8*k+imin];
        s ^= (1 << imin);
    }
    block_signs[k] = s & 127;  // Store only 7 bits
}
```

This is beautiful! When there's an odd number of negatives (violating parity), the algorithm finds the **least important** value and flips its sign. The 8th sign bit is implicit from parity.

### Phase 3: Scale Search and Grid Matching

```c
float scale = make_qp_quants(32, kMaxQ+1, xval, (uint8_t*)L, weight);
float best = 0;

for (int is = -6; is <= 6; ++is) {  // Search around initial scale
    float id = (2*kMaxQ-1+is*0.1f)/eff_max;
    float this_scale = 1/id;
    
    for (int k = 0; k < 4; ++k) {
        // Quantize to 2-bit indices
        for (int i = 0; i < 8; ++i) {
            int l = nearest_int(0.5f*(id*xval[8*k+i]-1));
            Laux[8*k+i] = MAX(0, MIN(kMaxQ-1, l));
        }
        
        // Check if this combination is on the grid
        uint16_t u = 0;
        for (int i = 0; i < 8; ++i) u |= (Laux[8*k+i] << 2*i);
        int grid_index = kmap_q2xs[u];
        
        if (grid_index < 0) {
            // Not on grid! Find nearest neighbor
            const uint16_t * neighbours = kneighbors_q2xs - kmap_q2xs[u] - 1;
            grid_index = iq2_find_best_neighbour(neighbours, kgrid_q2xs, 
                                                  xval + 8*k, waux + 8*k, 
                                                  this_scale, Laux + 8*k);
        }
    }
    
    // Compute weighted reconstruction error
    float sumqx = 0, sumq2 = 0;
    for (int i = 0; i < 32; ++i) {
        float w = weight[i];
        float q = 2*Laux[i] + 1;  // Dequantized value
        sumqx += w*xval[i]*q;
        sumq2 += w*q*q;
    }
    
    // Keep best scale (least weighted MSE)
    if (sumq2 > 0 && sumqx*sumqx > best*sumq2) {
        scale = sumqx/sumq2; 
        best = scale*sumqx;
        memcpy(L, Laux, 32);
    }
}
```

### Phase 4: The Neighbor Search System

The initialization code (`iq2xs_init_impl`) builds a neighbor lookup for points not on the grid:

```c
// For each possible 16-bit combination (4^8 = 65536 total)
for (int i = 0; i < kmap_size; ++i) {
    if (kmap_q2xs[i] >= 0) continue;  // Already on grid
    
    // Compute distance to all grid points
    for (int j = 0; j < grid_size; ++j) {
        const int8_t * pg = (const int8_t *)(kgrid_q2xs + j);
        int d2 = 0;
        for (int k = 0; k < 8; ++k) 
            d2 += (pg[k] - pos[k])*(pg[k] - pos[k]);
        dist2[2*j+0] = d2;
        dist2[2*j+1] = j;
    }
    qsort(dist2, grid_size, 2*sizeof(int), iq2_compare_func);
    
    // Store nearest neighbors (typically 2 closest distinct distances)
    kmap_q2xs[i] = -(counter + 1);  // Negative = index into neighbors
    // ... store neighbor list
}
```

The `kmap_q2xs` array serves dual purpose:
- **Positive value**: direct grid index (point is on grid)
- **Negative value**: encoded pointer to neighbor list (point is off grid)

---

## Implementation Details You Should Care About

### 1. The Parity Trick Saves 12.5% on Signs

By constraining each 8-value group to have even parity, you encode 8 signs in 7 bits. Over 256 values, that's 256/8 * 7 = 224 sign bits instead of 256. This is a 12.5% savings on sign storage.

### 2. Hierarchical Scaling

IQ2 uses two levels of scales:
- **Block scale** (`d`): 16-bit float for the entire 256-value block
- **Group scales**: 4 bits per 32-value group (16 groups = 64 bits = 8 bytes for IQ2_XS)

The dequantization formula reveals the scale combination:
```c
db = d * (0.5f + group_scale) * 0.25f
```

The `0.5 + group_scale` with `group_scale` in [0,15] gives range [0.5, 15.5], then scaled by 0.25 to give effective multiplier range [0.125, 3.875]. This provides good dynamic range within each block.

### 3. Grid Selection is Critical

The grids (`kgrid_2bit_256`, etc.) aren't arbitrary - they're specifically chosen to minimize expected quantization error for neural network weights. The raw grid values like:

```c
static const uint16_t kgrid_2bit_256[256] = {
    0, 2, 5, 8, 10, 17, 20, 32, ...
};
```

Each 16-bit value encodes 8 × 2-bit indices. These were likely found through optimization on representative weight distributions.

### 4. Importance Weighting During Quantization

```c
weight[i] = qw[i] * sqrtf(sigma2 + xb[i]*xb[i]);
```

This weighting scheme:
- Prioritizes values with larger magnitude (they contribute more to output)
- Uses global variance (`sigma2`) as a baseline
- Accepts external weights (`qw`) for additional control (e.g., from activation statistics)

### 5. The IQ2_XS vs IQ2_XXS Difference

IQ2_XS uses a 512-entry grid (vs 256) and stores explicit per-group scales. Looking at `dequantize_row_iq2_xs`:

```c
for (int l = 0; l < 4; ++l) {
    const uint8_t * grid = (const uint8_t *)(iq2xs_grid + (x[i].qs[4*ib32 + l] & 511));
    const uint8_t signs = ksigns_iq2xs[x[i].qs[4*ib32 + l] >> 9];
```

Here, each 16-bit `qs` entry contains:
- Bits 0-8: grid index (512 possibilities)
- Bits 9-15: 7-bit sign pattern

The separate `scales` array stores the group scales explicitly rather than packing them into the data stream.

### 6. IQ2_S Uses Even Larger Grid + High Bits

```c
const uint8_t * grid = (const uint8_t *)(iq2s_grid + (qs[l] | (qh[ib32] << (8-2*l) & 0x300)));
```

IQ2_S uses a 1024-entry grid, requiring 10 bits per grid index. It stores:
- 8 low bits in `qs`
- 2 high bits in `qh` (packed, 4 groups share one byte)
- Signs separately from the grid index

---

## Summary: The Complete Picture

**What IQ2 achieves**: Near-2-bit quantization by constraining 8 weights to lie on a carefully chosen 256/512/1024-point codebook, with smart sign encoding that exploits parity.

**The quantization pipeline**:
1. Compute importance weights based on magnitude and variance
2. Make all values positive, record signs, enforce even parity (flip least important if needed)
3. Search for optimal scale by trying candidates around initial estimate
4. For each scale candidate, snap to nearest grid point (direct or via neighbor search)
5. Pick scale that minimizes weighted reconstruction error
6. Pack grid indices, signs (7 bits), and scales into the block structure

**The dequantization pipeline**:
1. Load block scale
2. For each group: compute local scale, look up grid values, apply signs, multiply by scale
3. Output float values

**Key insights**:
- Grid-based quantization beats independent quantization by exploiting weight structure
- Parity constraint on signs saves 12.5% storage
- Hierarchical scales (block + group) give fine-grained dynamic range
- Importance weighting ensures large weights are accurately represented
- Precomputed neighbor lists make non-grid-point handling efficient

## References:
1. datastructure: [ggml-common.h](https://github.com/ggml-org/llama.cpp/blob/master/ggml/src/ggml-common.h)
2. quantization: [ggml-quant.c](https://github.com/ggml-org/llama.cpp/blob/master/ggml/src/ggml-quants.c)
3. visual explanation: [Reverse-engineering GGUF | Post-Training Quantization](https://www.youtube.com/watch?v=vW30o4U9BFE)


================================================
FILE: include/bitsqueeze.h
================================================
#ifndef BITSQUEEZE_H
#define BITSQUEEZE_H

#include <stdint.h>
#include "float_quantization/bf16_impl.h"
#include "float_quantization/fp16_impl.h"
#include "float_quantization/fp8_impl.h"
#include "float_quantization/fp4_impl.h"
#include "float_quantization/mxfp8_impl.h"
#include "float_quantization/mxfp4_impl.h"
#include "float_quantization/nvfp4_impl.h"
#include "float_quantization/nf4_impl.h"
#include "float_quantization/nf4_dq_impl.h"
#include "int_quantization/q8_0_impl.h"
#include "int_quantization/q4_0_impl.h"
#include "int_quantization/q2_k_impl.h"
#include "int_quantization/iq2_xxs_impl.h"
#include "int_quantization/iq2_xs_impl.h"
#include "int_quantization/iq2_s_impl.h"
#include "sparsity/topk_impl.h"

#ifdef __cplusplus
extern "C" {
#endif

typedef enum {
    Q8_0 = 0,
    Q4_0 = 1,
    Q2_K = 2,
    TOPK = 3,
    BF16 = 4,
    FP16 = 5,
    FP8  = 6,
    FP4  = 7,
    MXFP8 = 8,
    MXFP4 = 9,
    NVFP4 = 10,
    NF4_DQ = 11,
    NF4 = 12,
    IQ2_XXS = 13,
    IQ2_XS = 14,
    IQ2_S = 15,
} bsq_method_t;

typedef struct {
    uint64_t num_elements;    /* for 1D formats */
    uint16_t num_tokens;      /* for 2D sparsity */
    uint16_t num_features;    /* for 2D sparsity */
    float    sparse_ratio;    /* only meaningful for TOPK */
} bsq_shape_t;

typedef struct bitsqueeze_buffer {
    bsq_method_t method;
    bsq_shape_t  shape;
    void        *payload;
} bitsqueeze_buffer_t;

int bsq_compress_1d(const float *src,
                    uint64_t num_elements,
                    bsq_method_t method,
                    bitsqueeze_buffer_t **out);

int bsq_compress_2d(const float *src,
                    uint16_t num_tokens,
                    uint16_t num_features,
                    float sparse_ratio,
                    bsq_method_t method,
                    bitsqueeze_buffer_t **out);

int bsq_decompress(const bitsqueeze_buffer_t *buf,
                   float *dst,
                   uint64_t dst_num_elements);

int64_t bsq_get_packed_size(const bitsqueeze_buffer_t *buf);

bitsqueeze_buffer_t *load_bsq_from_buffer(const void *buffer, int64_t buffer_size);

void bsq_free(bitsqueeze_buffer_t *buf);

#ifdef __cplusplus
}
#endif

#endif



================================================
FILE: include/datatype/bf16.h
================================================
#ifndef BF16_H_
#define BF16_H_

#include <stdint.h> // For uint16_t, uint32_t
#include <string.h> // For memcpy
#include <math.h>   // For isnan

// C++ compatibility
#ifdef __cplusplus
#include <cstdint>
#include <cstring>
#include <cmath>
#endif

// C++20 and later provides a dedicated, safe intrinsic
#if defined(__cplusplus) && __cplusplus >= 202002L
#include <bit>
#endif

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief Converts a 16-bit BF16 value to a 32-bit float.
 *
 * This function performs the bit-level conversion from BFloat16 to FP32.
 * It takes the 16-bit BF16, casts it to a 32-bit integer, and shifts it
 * left by 16 bits. This places the sign, exponent, and 7-bit mantissa
 * in the correct positions for an FP32, padding the new (lower) 16 bits
 * of the mantissa with zeros.
 *
 * @param b The 16-bit BFloat16 value.
 * @return The corresponding 32-bit float value.
 */
static inline float fp32_from_bf16_value(uint16_t b) {
    uint32_t u_b = (uint32_t)b << 16;
    float f;

#if defined(__cplusplus) && __cplusplus >= 202002L
    // C++20: Use std::bit_cast for safe, zero-cost type punning
    f = std::bit_cast<float>(u_b);
#else
    // C / C++11: Use memcpy, which compilers recognize and optimize
    // to a single instruction, while respecting aliasing rules.
    memcpy(&f, &u_b, sizeof(f));
#endif
    
    return f;
}

/**
 * @brief Converts a 32-bit float to a 16-bit BF16 value using
 * **Round-to-Nearest-Even (RNE)**.
 *
 * This is the numerically superior and standard method for conversion.
 * It rounds the float to the *closest* representable BF16 value.
 * In cases of a tie (exactly halfway), it rounds to the "even"
 * value (where the least significant bit is 0).
 * This method avoids the statistical bias of truncation.
 *
 * @param f The 32-bit float value.
 * @return The 16-bit BFloat16 value (rounded).
 */
static inline uint16_t bf16_from_fp32_value(float f) {
    uint32_t u_f;

#if defined(__cplusplus) && __cplusplus >= 202002L
    u_f = std::bit_cast<uint32_t>(f);
#else
    memcpy(&u_f, &f, sizeof(u_f));
#endif

    // Check for NaN (all exponent bits 1, mantissa non-zero)
    // (u_f & 0x7FFFFFFF) > 0x7F800000 is a portable way to check for NaN
    if ((u_f & 0x7F800000) == 0x7F800000 && (u_f & 0x007FFFFF) != 0) {
        // Preserve NaN payload. Set top bit of mantissa to make it a qNaN.
        return (uint16_t)(u_f >> 16) | 0x0040;
    }

    // Get the 16 bits that will be truncated
    uint32_t remainder = u_f & 0xFFFF;
    // Get the LSB of the 16 bits that will be *kept*
    uint32_t lsb = (u_f >> 16) & 1; 

    // Round up if:
    // 1. The remainder is greater than halfway (0x8000)
    // OR
    // 2. The remainder is *exactly* halfway (0x8000) AND the LSB is 1 (odd),
    //    so we round up to the nearest *even* number.
    if (remainder > 0x8000 || (remainder == 0x8000 && lsb == 1)) {
        u_f += 0x10000;
    }

    return (uint16_t)(u_f >> 16);
}

#ifdef __cplusplus
} // extern "C"
#endif

#endif // BF16_H_



================================================
FILE: include/datatype/fp16/bitcasts.h
================================================
#pragma once
#ifndef FP16_BITCASTS_H
#define FP16_BITCASTS_H

#if defined(__cplusplus) && (__cplusplus >= 201103L)
	#include <cstdint>
#elif !defined(__OPENCL_VERSION__)
	#include <stdint.h>
#endif

#if defined(__INTEL_COMPILER) || defined(_MSC_VER) && (_MSC_VER >= 1932) && (defined(_M_IX86) || defined(_M_X64))
	#include <immintrin.h>
#endif

#if defined(_MSC_VER) && !defined(__clang__) && (defined(_M_ARM) || defined(_M_ARM64))
	#include <intrin.h>
#endif

#if defined(__clang__) && (defined(_M_IX86) || defined(_M_X64))
   #include <x86intrin.h>
#endif


static inline float fp32_from_bits(uint32_t w) {
#if defined(__OPENCL_VERSION__)
	return as_float(w);
#elif defined(__CUDA_ARCH__)
	return __uint_as_float((unsigned int) w);
#elif defined(__INTEL_COMPILER) || defined(_MSC_VER) && (_MSC_VER >= 1932) && (defined(_M_IX86) || defined(_M_X64))
	return _castu32_f32(w);
#elif defined(_MSC_VER) && !defined(__clang__) && (defined(_M_ARM) || defined(_M_ARM64))
	return _CopyFloatFromInt32((__int32) w);
#else
	union {
		uint32_t as_bits;
		float as_value;
	} fp32 = { w };
	return fp32.as_value;
#endif
}

static inline uint32_t fp32_to_bits(float f) {
#if defined(__OPENCL_VERSION__)
	return as_uint(f);
#elif defined(__CUDA_ARCH__)
	return (uint32_t) __float_as_uint(f);
#elif defined(__INTEL_COMPILER) || defined(_MSC_VER) && (_MSC_VER >= 1932) && (defined(_M_IX86) || defined(_M_X64))
	return _castf32_u32(f);
#elif defined(_MSC_VER) && !defined(__clang__) && (defined(_M_ARM) || defined(_M_ARM64))
	return (uint32_t) _CopyInt32FromFloat(f);
#else
	union {
		float as_value;
		uint32_t as_bits;
	} fp32 = { f };
	return fp32.as_bits;
#endif
}

static inline double fp64_from_bits(uint64_t w) {
#if defined(__OPENCL_VERSION__)
	return as_double(w);
#elif defined(__CUDA_ARCH__)
	return __longlong_as_double((long long) w);
#elif defined(__INTEL_COMPILER) || defined(_MSC_VER) && (_MSC_VER >= 1932) && (defined(_M_IX86) || defined(_M_X64))
	return _castu64_f64(w);
#elif defined(_MSC_VER) && !defined(__clang__) && (defined(_M_ARM) || defined(_M_ARM64))
	return _CopyDoubleFromInt64((__int64) w);
#else
	union {
		uint64_t as_bits;
		double as_value;
	} fp64 = { w };
	return fp64.as_value;
#endif
}

static inline uint64_t fp64_to_bits(double f) {
#if defined(__OPENCL_VERSION__)
	return as_ulong(f);
#elif defined(__CUDA_ARCH__)
	return (uint64_t) __double_as_longlong(f);
#elif defined(__INTEL_COMPILER) || defined(_MSC_VER) && (_MSC_VER >= 1932) && (defined(_M_IX86) || defined(_M_X64))
	return _castf64_u64(f);
#elif defined(_MSC_VER) && !defined(__clang__) && (defined(_M_ARM) || defined(_M_ARM64))
	return (uint64_t) _CopyInt64FromDouble(f);
#else
	union {
		double as_value;
		uint64_t as_bits;
	} fp64 = { f };
	return fp64.as_bits;
#endif
}

#endif /* FP16_BITCASTS_H */



================================================
FILE: include/datatype/fp16/fp16.h
================================================
#pragma once
#ifndef FP16_FP16_H
#define FP16_FP16_H

#if defined(__cplusplus) && (__cplusplus >= 201103L)
	#include <cstdint>
	#include <cmath>
#elif !defined(__OPENCL_VERSION__)
	#include <stdint.h>
	#include <math.h>
#endif

#include <datatype/fp16/bitcasts.h>
#include <datatype/fp16/macros.h>

#if defined(_MSC_VER)
	#include <intrin.h>
#endif
#if defined(__F16C__) && FP16_USE_NATIVE_CONVERSION && !FP16_USE_FLOAT16_TYPE && !FP16_USE_FP16_TYPE
	#include <immintrin.h>
#endif
#if (defined(__aarch64__) || defined(_M_ARM64)) && FP16_USE_NATIVE_CONVERSION && !FP16_USE_FLOAT16_TYPE && !FP16_USE_FP16_TYPE
	#include <arm_neon.h>
#endif


/*
 * Convert a 16-bit floating-point number in IEEE half-precision format, in bit representation, to
 * a 32-bit floating-point number in IEEE single-precision format, in bit representation.
 *
 * @note The implementation doesn't use any floating-point operations.
 */
static inline uint32_t fp16_ieee_to_fp32_bits(uint16_t h) {
	/*
	 * Extend the half-precision floating-point number to 32 bits and shift to the upper part of the 32-bit word:
	 *      +---+-----+------------+-------------------+
	 *      | S |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  31  26-30    16-25            0-15
	 *
	 * S - sign bit, E - bits of the biased exponent, M - bits of the mantissa, 0 - zero bits.
	 */
	const uint32_t w = (uint32_t) h << 16;
	/*
	 * Extract the sign of the input number into the high bit of the 32-bit word:
	 *
	 *      +---+----------------------------------+
	 *      | S |0000000 00000000 00000000 00000000|
	 *      +---+----------------------------------+
	 * Bits  31                 0-31
	 */
	const uint32_t sign = w & UINT32_C(0x80000000);
	/*
	 * Extract mantissa and biased exponent of the input number into the bits 0-30 of the 32-bit word:
	 *
	 *      +---+-----+------------+-------------------+
	 *      | 0 |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  30  27-31     17-26            0-16
	 */
	const uint32_t nonsign = w & UINT32_C(0x7FFFFFFF);
	/*
	 * Renorm shift is the number of bits to shift mantissa left to make the half-precision number normalized.
	 * If the initial number is normalized, some of its high 6 bits (sign == 0 and 5-bit exponent) equals one.
	 * In this case renorm_shift == 0. If the number is denormalize, renorm_shift > 0. Note that if we shift
	 * denormalized nonsign by renorm_shift, the unit bit of mantissa will shift into exponent, turning the
	 * biased exponent into 1, and making mantissa normalized (i.e. without leading 1).
	 */
#ifdef _MSC_VER
	unsigned long nonsign_bsr;
	_BitScanReverse(&nonsign_bsr, (unsigned long) nonsign);
	uint32_t renorm_shift = (uint32_t) nonsign_bsr ^ 31;
#else
	uint32_t renorm_shift = __builtin_clz(nonsign);
#endif
	renorm_shift = renorm_shift > 5 ? renorm_shift - 5 : 0;
	/*
	 * Iff half-precision number has exponent of 15, the addition overflows it into bit 31,
	 * and the subsequent shift turns the high 9 bits into 1. Thus
	 *   inf_nan_mask ==
	 *                   0x7F800000 if the half-precision number had exponent of 15 (i.e. was NaN or infinity)
	 *                   0x00000000 otherwise
	 */
	const int32_t inf_nan_mask = ((int32_t) (nonsign + 0x04000000) >> 8) & INT32_C(0x7F800000);
	/*
	 * Iff nonsign is 0, it overflows into 0xFFFFFFFF, turning bit 31 into 1. Otherwise, bit 31 remains 0.
	 * The signed shift right by 31 broadcasts bit 31 into all bits of the zero_mask. Thus
	 *   zero_mask ==
	 *                0xFFFFFFFF if the half-precision number was zero (+0.0h or -0.0h)
	 *                0x00000000 otherwise
	 */
	const int32_t zero_mask = (int32_t) (nonsign - 1) >> 31;
	/*
	 * 1. Shift nonsign left by renorm_shift to normalize it (if the input was denormal)
	 * 2. Shift nonsign right by 3 so the exponent (5 bits originally) becomes an 8-bit field and 10-bit mantissa
	 *    shifts into the 10 high bits of the 23-bit mantissa of IEEE single-precision number.
	 * 3. Add 0x70 to the exponent (starting at bit 23) to compensate the different in exponent bias
	 *    (0x7F for single-precision number less 0xF for half-precision number).
	 * 4. Subtract renorm_shift from the exponent (starting at bit 23) to account for renormalization. As renorm_shift
	 *    is less than 0x70, this can be combined with step 3.
	 * 5. Binary OR with inf_nan_mask to turn the exponent into 0xFF if the input was NaN or infinity.
	 * 6. Binary ANDNOT with zero_mask to turn the mantissa and exponent into zero if the input was zero. 
	 * 7. Combine with the sign of the input number.
	 */
	return sign | ((((nonsign << renorm_shift >> 3) + ((0x70 - renorm_shift) << 23)) | inf_nan_mask) & ~zero_mask);
}

/*
 * Convert a 16-bit floating-point number in IEEE half-precision format, in bit representation, to
 * a 32-bit floating-point number in IEEE single-precision format.
 *
 * @note The implementation relies on IEEE-like (no assumption about rounding mode and no operations on denormals)
 * floating-point operations and bitcasts between integer and floating-point variables.
 */
static inline float fp16_ieee_to_fp32_value(uint16_t h) {
#if FP16_USE_NATIVE_CONVERSION
	#if FP16_USE_FLOAT16_TYPE
		union {
			uint16_t as_bits;
			_Float16 as_value;
		} fp16 = { h };
		return (float) fp16.as_value;
	#elif FP16_USE_FP16_TYPE
		union {
			uint16_t as_bits;
			__fp16 as_value;
		} fp16 = { h };
		return (float) fp16.as_value;
	#else
		#if (defined(__INTEL_COMPILER) || defined(__GNUC__)) && defined(__F16C__)
			return _cvtsh_ss((unsigned short) h);
		#elif defined(_MSC_VER) && (defined(_M_IX86) || defined(_M_X64)) && defined(__AVX2__)
			return _mm_cvtss_f32(_mm_cvtph_ps(_mm_cvtsi32_si128((int) (unsigned int) h)));
		#elif defined(_M_ARM64) || defined(__aarch64__)
			return vgetq_lane_f32(vcvt_f32_f16(vreinterpret_f16_u16(vdup_n_u16(h))), 0);
		#else
			#error "Archtecture- or compiler-specific implementation required"
		#endif
	#endif
#else
	/*
	 * Extend the half-precision floating-point number to 32 bits and shift to the upper part of the 32-bit word:
	 *      +---+-----+------------+-------------------+
	 *      | S |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  31  26-30    16-25            0-15
	 *
	 * S - sign bit, E - bits of the biased exponent, M - bits of the mantissa, 0 - zero bits.
	 */
	const uint32_t w = (uint32_t) h << 16;
	/*
	 * Extract the sign of the input number into the high bit of the 32-bit word:
	 *
	 *      +---+----------------------------------+
	 *      | S |0000000 00000000 00000000 00000000|
	 *      +---+----------------------------------+
	 * Bits  31                 0-31
	 */
	const uint32_t sign = w & UINT32_C(0x80000000);
	/*
	 * Extract mantissa and biased exponent of the input number into the high bits of the 32-bit word:
	 *
	 *      +-----+------------+---------------------+
	 *      |EEEEE|MM MMMM MMMM|0 0000 0000 0000 0000|
	 *      +-----+------------+---------------------+
	 * Bits  27-31    17-26            0-16
	 */
	const uint32_t two_w = w + w;

	/*
	 * Shift mantissa and exponent into bits 23-28 and bits 13-22 so they become mantissa and exponent
	 * of a single-precision floating-point number:
	 *
	 *       S|Exponent |          Mantissa
	 *      +-+---+-----+------------+----------------+
	 *      |0|000|EEEEE|MM MMMM MMMM|0 0000 0000 0000|
	 *      +-+---+-----+------------+----------------+
	 * Bits   | 23-31   |           0-22
	 *
	 * Next, there are some adjustments to the exponent:
	 * - The exponent needs to be corrected by the difference in exponent bias between single-precision and half-precision
	 *   formats (0x7F - 0xF = 0x70)
	 * - Inf and NaN values in the inputs should become Inf and NaN values after conversion to the single-precision number.
	 *   Therefore, if the biased exponent of the half-precision input was 0x1F (max possible value), the biased exponent
	 *   of the single-precision output must be 0xFF (max possible value). We do this correction in two steps:
	 *   - First, we adjust the exponent by (0xFF - 0x1F) = 0xE0 (see exp_offset below) rather than by 0x70 suggested
	 *     by the difference in the exponent bias (see above).
	 *   - Then we multiply the single-precision result of exponent adjustment by 2**(-112) to reverse the effect of
	 *     exponent adjustment by 0xE0 less the necessary exponent adjustment by 0x70 due to difference in exponent bias.
	 *     The floating-point multiplication hardware would ensure than Inf and NaN would retain their value on at least
	 *     partially IEEE754-compliant implementations.
	 *
	 * Note that the above operations do not handle denormal inputs (where biased exponent == 0). However, they also do not
	 * operate on denormal inputs, and do not produce denormal results.
	 */
	const uint32_t exp_offset = UINT32_C(0xE0) << 23;
#if defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L) || defined(__GNUC__) && !defined(__STRICT_ANSI__)
	const float exp_scale = 0x1.0p-112f;
#else
	const float exp_scale = fp32_from_bits(UINT32_C(0x7800000));
#endif
	const float normalized_value = fp32_from_bits((two_w >> 4) + exp_offset) * exp_scale;

	/*
	 * Convert denormalized half-precision inputs into single-precision results (always normalized).
	 * Zero inputs are also handled here.
	 *
	 * In a denormalized number the biased exponent is zero, and mantissa has on-zero bits.
	 * First, we shift mantissa into bits 0-9 of the 32-bit word.
	 *
	 *                  zeros           |  mantissa
	 *      +---------------------------+------------+
	 *      |0000 0000 0000 0000 0000 00|MM MMMM MMMM|
	 *      +---------------------------+------------+
	 * Bits             10-31                0-9
	 *
	 * Now, remember that denormalized half-precision numbers are represented as:
	 *    FP16 = mantissa * 2**(-24).
	 * The trick is to construct a normalized single-precision number with the same mantissa and thehalf-precision input
	 * and with an exponent which would scale the corresponding mantissa bits to 2**(-24).
	 * A normalized single-precision floating-point number is represented as:
	 *    FP32 = (1 + mantissa * 2**(-23)) * 2**(exponent - 127)
	 * Therefore, when the biased exponent is 126, a unit change in the mantissa of the input denormalized half-precision
	 * number causes a change of the constructud single-precision number by 2**(-24), i.e. the same ammount.
	 *
	 * The last step is to adjust the bias of the constructed single-precision number. When the input half-precision number
	 * is zero, the constructed single-precision number has the value of
	 *    FP32 = 1 * 2**(126 - 127) = 2**(-1) = 0.5
	 * Therefore, we need to subtract 0.5 from the constructed single-precision number to get the numerical equivalent of
	 * the input half-precision number.
	 */
	const uint32_t magic_mask = UINT32_C(126) << 23;
	const float magic_bias = 0.5f;
	const float denormalized_value = fp32_from_bits((two_w >> 17) | magic_mask) - magic_bias;

	/*
	 * - Choose either results of conversion of input as a normalized number, or as a denormalized number, depending on the
	 *   input exponent. The variable two_w contains input exponent in bits 27-31, therefore if its smaller than 2**27, the
	 *   input is either a denormal number, or zero.
	 * - Combine the result of conversion of exponent and mantissa with the sign of the input number.
	 */
	const uint32_t denormalized_cutoff = UINT32_C(1) << 27;
	const uint32_t result = sign |
		(two_w < denormalized_cutoff ? fp32_to_bits(denormalized_value) : fp32_to_bits(normalized_value));
	return fp32_from_bits(result);
#endif
}

/*
 * Convert a 32-bit floating-point number in IEEE single-precision format to a 16-bit floating-point number in
 * IEEE half-precision format, in bit representation.
 *
 * @note The implementation relies on IEEE-like (no assumption about rounding mode and no operations on denormals)
 * floating-point operations and bitcasts between integer and floating-point variables.
 */
static inline uint16_t fp16_ieee_from_fp32_value(float f) {
#if FP16_USE_NATIVE_CONVERSION
	#if FP16_USE_FLOAT16_TYPE
		union {
			_Float16 as_value;
			uint16_t as_bits;
		} fp16 = { (_Float16) f };
		return fp16.as_bits;
	#elif FP16_USE_FP16_TYPE
		union {
			__fp16 as_value;
			uint16_t as_bits;
		} fp16 = { (__fp16) f };
		return fp16.as_bits;
	#else
		#if (defined(__INTEL_COMPILER) || defined(__GNUC__)) && defined(__F16C__)
			return _cvtss_sh(f, _MM_FROUND_CUR_DIRECTION);
		#elif defined(_MSC_VER) && (defined(_M_IX86) || defined(_M_X64)) && defined(__AVX2__)
			return (uint16_t) _mm_cvtsi128_si32(_mm_cvtps_ph(_mm_set_ss(f), _MM_FROUND_CUR_DIRECTION));
		#elif defined(_M_ARM64) || defined(__aarch64__)
			return vget_lane_u16(vcvt_f16_f32(vdupq_n_f32(f)), 0);
		#else
			#error "Archtecture- or compiler-specific implementation required"
		#endif
	#endif
#else
#if defined(__STDC_VERSION__) && (__STDC_VERSION__ >= 199901L) || defined(__GNUC__) && !defined(__STRICT_ANSI__)
	const float scale_to_inf = 0x1.0p+112f;
	const float scale_to_zero = 0x1.0p-110f;
#else
	const float scale_to_inf = fp32_from_bits(UINT32_C(0x77800000));
	const float scale_to_zero = fp32_from_bits(UINT32_C(0x08800000));
#endif
#if defined(_MSC_VER) && defined(_M_IX86_FP) && (_M_IX86_FP == 0) || defined(__GNUC__) && defined(__FLT_EVAL_METHOD__) && (__FLT_EVAL_METHOD__ != 0)
	const volatile float saturated_f = fabsf(f) * scale_to_inf;
#else
	const float saturated_f = fabsf(f) * scale_to_inf;
#endif
	float base = saturated_f * scale_to_zero;

	const uint32_t w = fp32_to_bits(f);
	const uint32_t shl1_w = w + w;
	const uint32_t sign = w & UINT32_C(0x80000000);
	uint32_t bias = shl1_w & UINT32_C(0xFF000000);
	if (bias < UINT32_C(0x71000000)) {
		bias = UINT32_C(0x71000000);
	}

	base = fp32_from_bits((bias >> 1) + UINT32_C(0x07800000)) + base;
	const uint32_t bits = fp32_to_bits(base);
	const uint32_t exp_bits = (bits >> 13) & UINT32_C(0x00007C00);
	const uint32_t mantissa_bits = bits & UINT32_C(0x00000FFF);
	const uint32_t nonsign = exp_bits + mantissa_bits;
	return (sign >> 16) | (shl1_w > UINT32_C(0xFF000000) ? UINT16_C(0x7E00) : nonsign);
#endif
}

/*
 * Convert a 16-bit floating-point number in ARM alternative half-precision format, in bit representation, to
 * a 32-bit floating-point number in IEEE single-precision format, in bit representation.
 *
 * @note The implementation doesn't use any floating-point operations.
 */
static inline uint32_t fp16_alt_to_fp32_bits(uint16_t h) {
	/*
	 * Extend the half-precision floating-point number to 32 bits and shift to the upper part of the 32-bit word:
	 *      +---+-----+------------+-------------------+
	 *      | S |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  31  26-30    16-25            0-15
	 *
	 * S - sign bit, E - bits of the biased exponent, M - bits of the mantissa, 0 - zero bits.
	 */
	const uint32_t w = (uint32_t) h << 16;
	/*
	 * Extract the sign of the input number into the high bit of the 32-bit word:
	 *
	 *      +---+----------------------------------+
	 *      | S |0000000 00000000 00000000 00000000|
	 *      +---+----------------------------------+
	 * Bits  31                 0-31
	 */
	const uint32_t sign = w & UINT32_C(0x80000000);
	/*
	 * Extract mantissa and biased exponent of the input number into the bits 0-30 of the 32-bit word:
	 *
	 *      +---+-----+------------+-------------------+
	 *      | 0 |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  30  27-31     17-26            0-16
	 */
	const uint32_t nonsign = w & UINT32_C(0x7FFFFFFF);
	/*
	 * Renorm shift is the number of bits to shift mantissa left to make the half-precision number normalized.
	 * If the initial number is normalized, some of its high 6 bits (sign == 0 and 5-bit exponent) equals one.
	 * In this case renorm_shift == 0. If the number is denormalize, renorm_shift > 0. Note that if we shift
	 * denormalized nonsign by renorm_shift, the unit bit of mantissa will shift into exponent, turning the
	 * biased exponent into 1, and making mantissa normalized (i.e. without leading 1).
	 */
#ifdef _MSC_VER
	unsigned long nonsign_bsr;
	_BitScanReverse(&nonsign_bsr, (unsigned long) nonsign);
	uint32_t renorm_shift = (uint32_t) nonsign_bsr ^ 31;
#else
	uint32_t renorm_shift = __builtin_clz(nonsign);
#endif
	renorm_shift = renorm_shift > 5 ? renorm_shift - 5 : 0;
	/*
	 * Iff nonsign is 0, it overflows into 0xFFFFFFFF, turning bit 31 into 1. Otherwise, bit 31 remains 0.
	 * The signed shift right by 31 broadcasts bit 31 into all bits of the zero_mask. Thus
	 *   zero_mask ==
	 *                0xFFFFFFFF if the half-precision number was zero (+0.0h or -0.0h)
	 *                0x00000000 otherwise
	 */
	const int32_t zero_mask = (int32_t) (nonsign - 1) >> 31;
	/*
	 * 1. Shift nonsign left by renorm_shift to normalize it (if the input was denormal)
	 * 2. Shift nonsign right by 3 so the exponent (5 bits originally) becomes an 8-bit field and 10-bit mantissa
	 *    shifts into the 10 high bits of the 23-bit mantissa of IEEE single-precision number.
	 * 3. Add 0x70 to the exponent (starting at bit 23) to compensate the different in exponent bias
	 *    (0x7F for single-precision number less 0xF for half-precision number).
	 * 4. Subtract renorm_shift from the exponent (starting at bit 23) to account for renormalization. As renorm_shift
	 *    is less than 0x70, this can be combined with step 3.
	 * 5. Binary ANDNOT with zero_mask to turn the mantissa and exponent into zero if the input was zero. 
	 * 6. Combine with the sign of the input number.
	 */
	return sign | (((nonsign << renorm_shift >> 3) + ((0x70 - renorm_shift) << 23)) & ~zero_mask);
}

/*
 * Convert a 16-bit floating-point number in ARM alternative half-precision format, in bit representation, to
 * a 32-bit floating-point number in IEEE single-precision format.
 *
 * @note The implementation relies on IEEE-like (no assumption about rounding mode and no operations on denormals)
 * floating-point operations and bitcasts between integer and floating-point variables.
 */
static inline float fp16_alt_to_fp32_value(uint16_t h) {
	/*
	 * Extend the half-precision floating-point number to 32 bits and shift to the upper part of the 32-bit word:
	 *      +---+-----+------------+-------------------+
	 *      | S |EEEEE|MM MMMM MMMM|0000 0000 0000 0000|
	 *      +---+-----+------------+-------------------+
	 * Bits  31  26-30    16-25            0-15
	 *
	 * S - sign bit, E - bits of the biased exponent, M - bits of the mantissa, 0 - zero bits.
	 */
	const uint32_t w = (uint32_t) h << 16;
	/*
	 * Extract the sign of the input number into the high bit of the 32-bit word:
	 *
	 *      +---+----------------------------------+
	 *      | S |0000000 00000000 00000000 00000000|
	 *      +---+----------------------------------+
	 * Bits  31                 0-31
	 */
	const uint32_t sign = w & UINT32_C(0x80000000);
	/*
	 * Extract mantissa and biased exponent of the input number into the high bits of the 32-bit word:
	 *
	 *      +-----+------------+---------------------+
	 *      |EEEEE|MM MMMM MMMM|0 0000 0000 0000 0000|
	 *      +-----+------------+---------------------+
	 * Bits  27-31    17-26            0-16
	 */
	const uint32_t two_w = w + w;

	/*
	 * Shift mantissa and exponent into bits 23-28 and bits 13-22 so they become mantissa and exponent
	 * of a single-precision floating-point number:
	 *
	 *       S|Exponent |          Mantissa
	 *      +-+---+-----+------------+----------------+
	 *      |0|000|EEEEE|MM MMMM MMMM|0 0000 0000 0000|
	 *      +-+---+-----+------------+----------------+
	 * Bits   | 23-31   |           0-22
	 *
	 * Next, the exponent is adjusted for the difference in exponent bias between single-precision and half-precision
	 * formats (0x7F - 0xF = 0x70). This operation never overflows or generates non-finite values, as the largest
	 * half-precision exponent is 0x1F and after the adjustment is can not exceed 0x8F < 0xFE (largest single-precision
	 * exponent for non-finite values).
	 *
	 * Note that this operation does not handle denormal inputs (where biased exponent == 0). However, they also do not
	 * operate on denormal inputs, and do not produce denormal results.
	 */
	const uint32_t exp_offset = UINT32_C(0x70) << 23;
	const float normalized_value = fp32_from_bits((two_w >> 4) + exp_offset);

	/*
	 * Convert denormalized half-precision inputs into single-precision results (always normalized).
	 * Zero inputs are also handled here.
	 *
	 * In a denormalized number the biased exponent is zero, and mantissa has on-zero bits.
	 * First, we shift mantissa into bits 0-9 of the 32-bit word.
	 *
	 *                  zeros           |  mantissa
	 *      +---------------------------+------------+
	 *      |0000 0000 0000 0000 0000 00|MM MMMM MMMM|
	 *      +---------------------------+------------+
	 * Bits             10-31                0-9
	 *
	 * Now, remember that denormalized half-precision numbers are represented as:
	 *    FP16 = mantissa * 2**(-24).
	 * The trick is to construct a normalized single-precision number with the same mantissa and thehalf-precision input
	 * and with an exponent which would scale the corresponding mantissa bits to 2**(-24).
	 * A normalized single-precision floating-point number is represented as:
	 *    FP32 = (1 + mantissa * 2**(-23)) * 2**(exponent - 127)
	 * Therefore, when the biased exponent is 126, a unit change in the mantissa of the input denormalized half-precision
	 * number causes a change of the constructud single-precision number by 2**(-24), i.e. the same ammount.
	 *
	 * The last step is to adjust the bias of the constructed single-precision number. When the input half-precision number
	 * is zero, the constructed single-precision number has the value of
	 *    FP32 = 1 * 2**(126 - 127) = 2**(-1) = 0.5
	 * Therefore, we need to subtract 0.5 from the constructed single-precision number to get the numerical equivalent of
	 * the input half-precision number.
	 */
	const uint32_t magic_mask = UINT32_C(126) << 23;
	const float magic_bias = 0.5f;
	const float denormalized_value = fp32_from_bits((two_w >> 17) | magic_mask) - magic_bias;

	/*
	 * - Choose either results of conversion of input as a normalized number, or as a denormalized number, depending on the
	 *   input exponent. The variable two_w contains input exponent in bits 27-31, therefore if its smaller than 2**27, the
	 *   input is either a denormal number, or zero.
	 * - Combine the result of conversion of exponent and mantissa with the sign of the input number.
	 */
	const uint32_t denormalized_cutoff = UINT32_C(1) << 27;
	const uint32_t result = sign |
		(two_w < denormalized_cutoff ? fp32_to_bits(denormalized_value) : fp32_to_bits(normalized_value));
	return fp32_from_bits(result);
}

/*
 * Convert a 32-bit floating-point number in IEEE single-precision format to a 16-bit floating-point number in
 * ARM alternative half-precision format, in bit representation.
 *
 * @note The implementation relies on IEEE-like (no assumption about rounding mode and no operations on denormals)
 * floating-point operations and bitcasts between integer and floating-point variables.
 */
static inline uint16_t fp16_alt_from_fp32_value(float f) {
	const uint32_t w = fp32_to_bits(f);
	const uint32_t sign = w & UINT32_C(0x80000000);
	const uint32_t shl1_w = w + w;

	const uint32_t shl1_max_fp16_fp32 = UINT32_C(0x8FFFC000);
	const uint32_t shl1_base = shl1_w > shl1_max_fp16_fp32 ? shl1_max_fp16_fp32 : shl1_w;
	uint32_t shl1_bias = shl1_base & UINT32_C(0xFF000000);
	const uint32_t exp_difference = 23 - 10;
	const uint32_t shl1_bias_min = (127 - 1 - exp_difference) << 24;
	if (shl1_bias < shl1_bias_min) {
		shl1_bias = shl1_bias_min;
	}

	const float bias = fp32_from_bits((shl1_bias >> 1) + ((exp_difference + 2) << 23));
	const float base = fp32_from_bits((shl1_base >> 1) + (2 << 23)) + bias;

	const uint32_t exp_f = fp32_to_bits(base) >> 13;
	return (sign >> 16) | ((exp_f & UINT32_C(0x00007C00)) + (fp32_to_bits(base) & UINT32_C(0x00000FFF)));
}

#endif /* FP16_FP16_H */



================================================
FILE: include/datatype/fp16/macros.h
================================================
#pragma once
#ifndef FP16_MACROS_H
#define FP16_MACROS_H

#ifndef FP16_USE_NATIVE_CONVERSION
	#if (defined(__INTEL_COMPILER) || defined(__GNUC__)) && defined(__F16C__)
		#define FP16_USE_NATIVE_CONVERSION 1
	#elif defined(_MSC_VER) && (defined(_M_IX86) || defined(_M_X64)) && defined(__AVX2__)
		#define FP16_USE_NATIVE_CONVERSION 1
	#elif defined(_MSC_VER) && defined(_M_ARM64)
		#define FP16_USE_NATIVE_CONVERSION 1
	#elif defined(__GNUC__) && defined(__aarch64__)
		#define FP16_USE_NATIVE_CONVERSION 1
	#endif
	#if !defined(FP16_USE_NATIVE_CONVERSION)
		#define FP16_USE_NATIVE_CONVERSION 0
	#endif  // !defined(FP16_USE_NATIVE_CONVERSION)
#endif  // !define(FP16_USE_NATIVE_CONVERSION)

#ifndef FP16_USE_FLOAT16_TYPE
	#if !defined(__clang__) && !defined(__INTEL_COMPILER) && defined(__GNUC__) && (__GNUC__ >= 12)
		#if defined(__F16C__)
			#define FP16_USE_FLOAT16_TYPE 1
		#endif
	#endif
	#if !defined(FP16_USE_FLOAT16_TYPE)
		#define FP16_USE_FLOAT16_TYPE 0
	#endif  // !defined(FP16_USE_FLOAT16_TYPE)
#endif  // !defined(FP16_USE_FLOAT16_TYPE)

#ifndef FP16_USE_FP16_TYPE
	#if defined(__clang__)
		#if defined(__F16C__) || defined(__aarch64__)
			#define FP16_USE_FP16_TYPE 1
		#endif
	#elif defined(__GNUC__)
		#if defined(__aarch64__)
			#define FP16_USE_FP16_TYPE 1
		#endif
	#endif
	#if !defined(FP16_USE_FP16_TYPE)
		#define FP16_USE_FP16_TYPE 0
	#endif  // !defined(FP16_USE_FP16_TYPE)
#endif  // !defined(FP16_USE_FP16_TYPE)

#endif /* FP16_MACROS_H */



================================================
FILE: include/float_quantization/bf16_impl.h
================================================
#ifndef BF16_IMPL_H
#define BF16_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#include "datatype/bf16.h"

typedef struct {
    uint64_t  num_elements;
    uint16_t *data;         /* BF16 payload, length = num_elements */
} bf16_array_t;

bf16_array_t *allocate_bf16_array(uint64_t num_elements);

void free_bf16_array(bf16_array_t *bf16_array);

int64_t get_bf16_array_size(const bf16_array_t *bf16_array);

bf16_array_t *load_bf16_array_from_buffer(const void *buffer, int64_t buffer_size);

int bf16_compress(const float *float_array,
                  uint64_t num_elements,
                  bf16_array_t **bf16_array);

int bf16_decompress(const bf16_array_t *bf16_array,
                    float *float_array);

#endif



================================================
FILE: include/float_quantization/fp16_impl.h
================================================
#ifndef FP16_IMPL_H
#define FP16_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#include "datatype/fp16/fp16.h"

typedef struct {
    uint64_t  num_elements;
    uint16_t *data;         /* IEEE FP16 payload, length = num_elements */
} fp16_array_t;

fp16_array_t *allocate_fp16_array(uint64_t num_elements);

void free_fp16_array(fp16_array_t *fp16_array);

int64_t get_fp16_array_size(const fp16_array_t *fp16_array);

fp16_array_t *load_fp16_array_from_buffer(const void *buffer, int64_t buffer_size);

int fp16_compress(const float *float_array,
                  uint64_t num_elements,
                  fp16_array_t **fp16_array);

int fp16_decompress(const fp16_array_t *fp16_array,
                    float *float_array);

#endif



================================================
FILE: include/float_quantization/fp4_impl.h
================================================
#ifndef FP4_IMPL_H
#define FP4_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define FP4_MAX_NORM_VALUE 6.0f

typedef struct {
    uint64_t num_elements;
    float    scale;  /* FP32 tensor scale */
    uint8_t *data;   /* packed FP4 E2M1 payload, length = ceil(num_elements / 2) bytes */
} fp4_array_t;

fp4_array_t *allocate_fp4_array(uint64_t num_elements);

void free_fp4_array(fp4_array_t *fp4_array);

int64_t get_fp4_array_size(const fp4_array_t *fp4_array);

fp4_array_t *load_fp4_array_from_buffer(const void *buffer, int64_t buffer_size);

int fp4_compress(const float *float_array,
                 uint64_t num_elements,
                 fp4_array_t **fp4_array);

int fp4_decompress(const fp4_array_t *fp4_array,
                   float *float_array);

#endif



================================================
FILE: include/float_quantization/fp8_impl.h
================================================
#ifndef FP8_IMPL_H
#define FP8_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define FP8_MAX_NORM_VALUE 448.0f

typedef struct {
    uint64_t num_elements;
    float    scale;  /* FP32 tensor scale */
    uint8_t *data;   /* FP8 E4M3 payload, length = num_elements */
} fp8_array_t;

fp8_array_t *allocate_fp8_array(uint64_t num_elements);

void free_fp8_array(fp8_array_t *fp8_array);

int64_t get_fp8_array_size(const fp8_array_t *fp8_array);

fp8_array_t *load_fp8_array_from_buffer(const void *buffer, int64_t buffer_size);

int fp8_compress(const float *float_array,
                 uint64_t num_elements,
                 fp8_array_t **fp8_array);

int fp8_decompress(const fp8_array_t *fp8_array,
                   float *float_array);

#endif



================================================
FILE: include/float_quantization/mxfp4_impl.h
================================================
#ifndef MXFP4_IMPL_H
#define MXFP4_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_MXFP4_BLOCK_SIZE 32
#define MXFP4_MAX_NORM_VALUE     6.0f

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of 32-value blocks */
    uint64_t block_size;     /* elements per block (default = 32) */
    int8_t  *scales;         /* per-block scale exponent (power-of-two), length = num_blocks */
    uint8_t *data;           /* packed FP4 E2M1 payload, length = ceil(num_elements / 2) bytes */
} mxfp4_array_t;

mxfp4_array_t *allocate_mxfp4_array(uint64_t num_elements,
                                    uint64_t block_size);

void free_mxfp4_array(mxfp4_array_t *mxfp4_array);

int64_t get_mxfp4_array_size(const mxfp4_array_t *mxfp4_array);

mxfp4_array_t *load_mxfp4_array_from_buffer(const void *buffer, int64_t buffer_size);

int mxfp4_compress(const float *float_array,
                   uint64_t num_elements,
                   mxfp4_array_t **mxfp4_array);

int mxfp4_decompress(const mxfp4_array_t *mxfp4_array,
                     float *float_array);

#endif



================================================
FILE: include/float_quantization/mxfp8_impl.h
================================================
#ifndef MXFP8_IMPL_H
#define MXFP8_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_MXFP8_BLOCK_SIZE 32
#define MXFP8_MAX_NORM_VALUE     448.0f

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of 32-value blocks */
    uint64_t block_size;     /* elements per block (default = 32) */
    int8_t  *scales;         /* per-block scale exponent (power-of-two), length = num_blocks */
    uint8_t *data;           /* FP8 E4M3 payload, length = num_elements */
} mxfp8_array_t;

mxfp8_array_t *allocate_mxfp8_array(uint64_t num_elements,
                                    uint64_t block_size);

void free_mxfp8_array(mxfp8_array_t *mxfp8_array);

int64_t get_mxfp8_array_size(const mxfp8_array_t *mxfp8_array);

mxfp8_array_t *load_mxfp8_array_from_buffer(const void *buffer, int64_t buffer_size);

int mxfp8_compress(const float *float_array,
                   uint64_t num_elements,
                   mxfp8_array_t **mxfp8_array);

int mxfp8_decompress(const mxfp8_array_t *mxfp8_array,
                     float *float_array);

#endif



================================================
FILE: include/float_quantization/nf4_dq_impl.h
================================================
#ifndef NF4_DQ_IMPL_H
#define NF4_DQ_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_NF4_DQ_BLOCK_SIZE 64
#define NF4_DQ_FP8_MAX_NORM_VALUE 448.0f

/*
 * NF4_DQ (NormalFloat4 with double quantization) with block size 64:
 *  - data: 4-bit NF4_DQ codes packed 2 per byte
 *  - per-block scale (c2) quantized to FP8 E4M3 and stored in block_scales
 *  - a single FP32 scale (c1 = dq_scale) used to dequantize block_scales
 */
typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of 64-value blocks */
    uint64_t block_size;     /* elements per block (default = 64) */
    float    dq_scale;       /* FP32 scale to dequantize block_scales (c1) */
    uint8_t *block_scales;   /* FP8 E4M3 per-block scale codes, length = num_blocks */
    uint8_t *data;           /* packed NF4_DQ codes, length = ceil(num_elements / 2) bytes */
} nf4_dq_array_t;

nf4_dq_array_t *allocate_nf4_dq_array(uint64_t num_elements,
                                      uint64_t block_size);

void free_nf4_dq_array(nf4_dq_array_t *nf4_dq_array);

int64_t get_nf4_dq_array_size(const nf4_dq_array_t *nf4_dq_array);

nf4_dq_array_t *load_nf4_dq_array_from_buffer(const void *buffer, int64_t buffer_size);

int nf4_dq_compress(const float *float_array,
                    uint64_t num_elements,
                    nf4_dq_array_t **nf4_dq_array);

int nf4_dq_decompress(const nf4_dq_array_t *nf4_dq_array,
                      float *float_array);

#endif



================================================
FILE: include/float_quantization/nf4_impl.h
================================================
#ifndef NF4_IMPL_H
#define NF4_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_NF4_BLOCK_SIZE 64

/*
 * NF4 (NormalFloat4) without double quantization of block scales:
 *  - data: 4-bit NF4 codes packed 2 per byte
 *  - per-block FP32 scale stored directly in block_scales
 */
typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of block_size-sized blocks */
    uint64_t block_size;     /* elements per block (default = 64) */
    float   *block_scales;   /* FP32 per-block scales, length = num_blocks */
    uint8_t *data;           /* packed NF4 codes, length = ceil(num_elements / 2) bytes */
} nf4_array_t;

nf4_array_t *allocate_nf4_array(uint64_t num_elements,
                                uint64_t block_size);

void free_nf4_array(nf4_array_t *nf4_array);

int64_t get_nf4_array_size(const nf4_array_t *nf4_array);

nf4_array_t *load_nf4_array_from_buffer(const void *buffer, int64_t buffer_size);

int nf4_compress(const float *float_array,
                 uint64_t num_elements,
                 nf4_array_t **nf4_array);

int nf4_decompress(const nf4_array_t *nf4_array,
                   float *float_array);

#endif



================================================
FILE: include/float_quantization/nvfp4_impl.h
================================================
#ifndef NVFP4_IMPL_H
#define NVFP4_IMPL_H

#include <math.h>
#include <stdint.h>
#include <stdlib.h>
#include <string.h>

#define DEFAULT_NVFP4_BLOCK_SIZE 16
#define NVFP4_MAX_NORM_VALUE     6.0f
#define NVFP4_FP8_MAX_NORM       448.0f

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of 16-value blocks */
    uint64_t block_size;     /* elements per block (default = 16) */
    float    tensor_scale;   /* FP32 per-tensor scale */
    uint8_t *block_scales;   /* FP8 E4M3 per-block scale codes, length = num_blocks */
    uint8_t *data;           /* packed FP4 E2M1 payload, length = ceil(num_elements / 2) bytes */
} nvfp4_array_t;

nvfp4_array_t *allocate_nvfp4_array(uint64_t num_elements,
                                    uint64_t block_size);

void free_nvfp4_array(nvfp4_array_t *nvfp4_array);

int64_t get_nvfp4_array_size(const nvfp4_array_t *nvfp4_array);

nvfp4_array_t *load_nvfp4_array_from_buffer(const void *buffer, int64_t buffer_size);

int nvfp4_compress(const float *float_array,
                   uint64_t num_elements,
                   nvfp4_array_t **nvfp4_array);

int nvfp4_decompress(const nvfp4_array_t *nvfp4_array,
                     float *float_array);

#endif



================================================
FILE: include/int_quantization/iq2_s_impl.h
================================================
#ifndef IQ2_S_IMPL_H
#define IQ2_S_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <float.h>

#define IQ2_S_SUPER_BLOCK_SIZE 256

/**
 * @brief IQ2_S quantized array structure (2.5625 bpw)
 * 
 * Each super block of 256 values is encoded as:
 * - 2 bytes: fp16 block scale
 * - 64 bytes: qs (32 bytes grid low bits + 32 bytes sign patterns)
 * - 8 bytes: qh (high 2 bits of grid indices, packed)
 * - 8 bytes: group scales
 * 
 * Total: 82 bytes per 256 values = 2.5625 bpw
 */
typedef struct {
    uint64_t num_elements;
    uint64_t num_super_blocks;
    uint16_t *d;            /* fp16 block scales, length = num_super_blocks */
    uint8_t  *qs;           /* 64 bytes per super block (grid low + signs) */
    uint8_t  *qh;           /* 8 bytes per super block (grid high bits) */
    uint8_t  *scales;       /* 8 bytes per super block (group scales) */
} iq2_s_array_t;

/**
 * @brief Initialize IQ2_S quantization tables (must be called before quantization)
 */
void iq2_s_init(void);

/**
 * @brief Free IQ2_S quantization tables
 */
void iq2_s_free_tables(void);

iq2_s_array_t *allocate_iq2_s_array(uint64_t num_elements);

void free_iq2_s_array(iq2_s_array_t *arr);

int64_t get_iq2_s_array_size(const iq2_s_array_t *arr);

iq2_s_array_t *load_iq2_s_array_from_buffer(const void *buffer, int64_t buffer_size);

int iq2_s_compress(const float *float_array,
                   uint64_t num_elements,
                   iq2_s_array_t **out);

int iq2_s_decompress(const iq2_s_array_t *arr,
                     float *float_array);

#endif



================================================
FILE: include/int_quantization/iq2_xs_impl.h
================================================
#ifndef IQ2_XS_IMPL_H
#define IQ2_XS_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <float.h>

#define IQ2_XS_SUPER_BLOCK_SIZE 256

/**
 * @brief IQ2_XS quantized array structure (2.3125 bpw)
 * 
 * Each super block of 256 values is encoded as:
 * - 2 bytes: fp16 block scale
 * - 64 bytes: quantized data (32 × uint16_t, each with 9-bit grid index + 7-bit signs)
 * - 8 bytes: group scales (8 groups × 2 nibbles for 16 sub-scales)
 * 
 * Total: 74 bytes per 256 values = 2.3125 bpw
 */
typedef struct {
    uint64_t num_elements;
    uint64_t num_super_blocks;
    uint16_t *d;            /* fp16 block scales, length = num_super_blocks */
    uint16_t *qs;           /* 32 uint16_t per super block (grid index + signs) */
    uint8_t  *scales;       /* 8 bytes per super block (group scales) */
} iq2_xs_array_t;

/**
 * @brief Initialize IQ2_XS quantization tables (must be called before quantization)
 */
void iq2_xs_init(void);

/**
 * @brief Free IQ2_XS quantization tables
 */
void iq2_xs_free_tables(void);

iq2_xs_array_t *allocate_iq2_xs_array(uint64_t num_elements);

void free_iq2_xs_array(iq2_xs_array_t *arr);

int64_t get_iq2_xs_array_size(const iq2_xs_array_t *arr);

iq2_xs_array_t *load_iq2_xs_array_from_buffer(const void *buffer, int64_t buffer_size);

int iq2_xs_compress(const float *float_array,
                    uint64_t num_elements,
                    iq2_xs_array_t **out);

int iq2_xs_decompress(const iq2_xs_array_t *arr,
                      float *float_array);

#endif



================================================
FILE: include/int_quantization/iq2_xxs_impl.h
================================================
#ifndef IQ2_XXS_IMPL_H
#define IQ2_XXS_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include <float.h>
#include "datatype/fp16/fp16.h"

#define IQ2_XXS_SUPER_BLOCK_SIZE 256

/**
 * @brief IQ2_XXS quantized array structure
 * 
 * Each super block of 256 values is encoded as:
 * - 2 bytes: fp16 block scale
 * - 64 bytes: quantized data (8 groups × 8 bytes)
 * 
 * Per-group (32 values) encoding in 8 bytes:
 * - bytes 0-3: 4 grid indices (8 bits each, indexing 256-entry grid)
 * - bytes 4-7: 4×7-bit sign patterns (bits 0-27) + 4-bit group scale (bits 28-31)
 * 
 * Effective: 2.0625 bits per weight
 */
typedef struct {
    uint64_t num_elements;
    uint64_t num_super_blocks;
    uint16_t *scales;       /* fp16 block scales, length = num_super_blocks */
    uint8_t  *qs;           /* quantized data, 64 bytes per super block */
} iq2_xxs_array_t;

/**
 * @brief Initialize IQ2 quantization tables (must be called before quantization)
 */
void iq2_xxs_init(void);

/**
 * @brief Free IQ2 quantization tables
 */
void iq2_xxs_free_tables(void);

iq2_xxs_array_t *allocate_iq2_xxs_array(uint64_t num_elements);

void free_iq2_xxs_array(iq2_xxs_array_t *arr);

int64_t get_iq2_xxs_array_size(const iq2_xxs_array_t *arr);

iq2_xxs_array_t *load_iq2_xxs_array_from_buffer(const void *buffer, int64_t buffer_size);

int iq2_xxs_compress(const float *float_array,
                     uint64_t num_elements,
                     iq2_xxs_array_t **out);

int iq2_xxs_decompress(const iq2_xxs_array_t *arr,
                       float *float_array);

#endif



================================================
FILE: include/int_quantization/q2_k_impl.h
================================================
#ifndef Q2_K_IMPL_H
#define Q2_K_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>
#include "datatype/fp16/fp16.h"

// The setting is refer to https://github.com/ggml-org/llama.cpp/blob/master/ggml/src/ggml-common.h
// fp16 implementation is refer to https://github.com/Maratyszcza/FP16/tree/master/include/fp16
#define Q2_K_BLOCK_SIZE 16
#define Q2_K_SUPER_BLOCK_SIZE 16
#define WEIGHT_PER_SUPER_BLOCK (Q2_K_BLOCK_SIZE*Q2_K_SUPER_BLOCK_SIZE)

// Q2_K 2-bit quantization
// weight is represented as x = a * q + b
// 16 blocks of 16 elements each
// 2.625 bits per weight ((16 * 4 * 2) + (256 * 2) + (16 * 2)) / 256 = 2.625
typedef struct {
    uint16_t super_scale;  // super-block scale for quantized scales (fp16)
    uint16_t super_min;    // super-block min for quantized scales (fp16)
    uint8_t scales[Q2_K_SUPER_BLOCK_SIZE];  // scales and mins, quantized with 4 bits (length: Q2_K_SUPER_BLOCK_SIZE) 
    uint8_t data[WEIGHT_PER_SUPER_BLOCK / 4];   // quants with 2 bits (length: WEIGHT_PER_SUPER_BLOCK / 4)
} super_block_q2_k;

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_elements_aligned;   /* aligned (padding) total elements for SUPER_BLOCK ELEMENTS */
    uint32_t num_super_blocks;
    super_block_q2_k *super_blocks;
    
} q2_k_array_t;

q2_k_array_t *allocate_q2_k_array(uint64_t num_elements);

void free_q2_k_array(q2_k_array_t *q2_k_array);

int64_t get_q2_k_array_size(const q2_k_array_t *q2_k_array);

q2_k_array_t *load_q2_k_array_from_buffer(const void *buffer, int64_t buffer_size);

int q2_k_compress(const float *float_array, uint64_t num_elements, q2_k_array_t **q2_k_array);

int q2_k_decompress(const q2_k_array_t *q2_k_array, float *float_array);

#endif



================================================
FILE: include/int_quantization/q4_0_impl.h
================================================
#ifndef Q4_0_IMPL_H
#define Q4_0_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>

/* The setting is refer to https://huggingface.co/docs/hub/en/gguf */
#define DEFAULT_Q4_0_BLOCK_SIZE 32
#define DEFAULT_Q4_K_SUPER_BLOCK_SIZE 8

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of blocks (for block‑wised formats) */
    uint64_t block_size;     /* elements per block */
    float  *scales;          /* length = num_blocks (or num_superblocks for kquant formats) */
    int8_t *data;            /* for kquant, here need to contain quantized scale value + quantized value, otherwise it only need to store quantized value*/
} q4_0_array_t;

q4_0_array_t *allocate_q4_0_array(uint64_t num_elements,
                                       uint64_t block_size);                                       

void free_q4_0_array(q4_0_array_t *q4_0_array);

int64_t get_q4_0_array_size(const q4_0_array_t *q4_0_array);

q4_0_array_t *load_q4_0_array_from_buffer(const void *buffer, int64_t buffer_size);

int q4_0_compress(const float *float_array,
             uint64_t num_elements,
             uint8_t quantized_type,
             q4_0_array_t **q4_0_array);

int q4_0_decompress(const q4_0_array_t *q4_0_array,
               float *float_array);

#endif



================================================
FILE: include/int_quantization/q8_0_impl.h
================================================
#ifndef Q8_0_IMPL_H
#define Q8_0_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>

/* The setting is refer to https://huggingface.co/docs/hub/en/gguf */
#define DEFAULT_Q8_0_BLOCK_SIZE 32

typedef struct {
    uint64_t num_elements;   /* total elements in the original float array */
    uint64_t num_blocks;     /* number of blocks (for block‑wised formats) */
    uint64_t block_size;     /* elements per block */
    float  *scales;          /* length = num_blocks (or num_superblocks for kquant formats) */
    int8_t *data;            /* store quantized value*/
} q8_0_array_t;

q8_0_array_t *allocate_q8_0_array(uint64_t num_elements,
                                       uint64_t block_size);
                                    
void free_q8_0_array(q8_0_array_t *q8_0_array);

int64_t get_q8_0_array(const q8_0_array_t *q8_0_array);

q8_0_array_t *load_quantized_array_from_buffer(const void *buffer, int64_t buffer_size);

int q8_0_compress(const float *float_array,
             uint64_t num_elements,
             q8_0_array_t **q8_0_array);

int q8_0_decompress(const q8_0_array_t *q8_0_array,
               float *float_array);

#endif



================================================
FILE: include/sparsity/topk_impl.h
================================================
#ifndef TOPK_IMPL_H
#define TOPK_IMPL_H

#include <stdint.h>
#include <stdlib.h>
#include <string.h>
#include <math.h>

/**
 * @brief Represents a sparse array in zero-based COO format for 2D data with shape [num_tokens, num_features].
 *
 * Sparsity is applied along the features dimension. Since each token retains the same number of sparse features,
 * token indices are not stored explicitly. The structure holds the selected feature indices and corresponding values
 * for all tokens in a flattened manner.
 */
typedef struct {
    uint16_t num_tokens;                /* Number of tokens (rows in the 2D shape). */
    uint16_t num_features;              /* Number of features per token (columns in the 2D shape). */
    uint16_t num_sparse_features;       /* Number of retained sparse features per token (must be <= num_features). */
    uint16_t *sparse_indices;           /* Flattened array of selected feature indices; length is (num_tokens * num_sparse_features). */
    float *values;                      /* Flattened array of corresponding sparse values; length is (num_tokens * num_sparse_features). */
} sparse_array_t;

sparse_array_t *allocate_sparse_array(uint16_t num_tokens, uint16_t num_features, float sparse_ratio);                               

void free_sparse_array(sparse_array_t *sparse_array);

uint64_t get_sparse_array_size(const sparse_array_t *sparse_array);

sparse_array_t *load_sparse_array_from_buffer(const void *buffer, uint64_t buffer_size);

int topk_compress(const float *float_array, uint16_t num_tokens, uint16_t num_features,  float sparse_ratio, sparse_array_t **sparse_array);

int topk_decompress(const sparse_array_t *sparse_array, float *float_array);

#endif



================================================
FILE: include/utils/evaluation.h
================================================
#include <math.h>
#include <stdlib.h>
#include <time.h>

static double get_time_ms(void) {
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return (double)ts.tv_sec * 1000.0 + (double)ts.tv_nsec / 1000000.0;
}

static void measure_metrics(const float *orig, const float *deq, uint64_t N,
                            double *mae, double *mse, double *max_abs) {
    double m = 0.0, s = 0.0, mx = 0.0;
    for (uint64_t i = 0; i < N; ++i) {
        double e = (double)deq[i] - (double)orig[i];
        double ae = fabs(e);
        m    += ae;
        s    += e * e;
        if (ae > mx) mx = ae;
    }
    *mae     = m / (double)N;
    *mse     = s / (double)N;
    *max_abs = mx;
}



================================================
FILE: include/utils/random.h
================================================
#ifndef RANDOM_H
#define RANDOM_H

#include <stdint.h>
#include <stdlib.h>
#include <time.h>
#include <math.h>

float **gen_random_float_arrays(uint64_t count,
                                uint64_t N,
                                float minv,
                                float maxv,
                                unsigned int seed);

void free_random_float_arrays(float **arrs, uint64_t count);

#endif



================================================
FILE: src/bitsqueeze.c
================================================
#include "bitsqueeze.h"
#include <string.h>

static bitsqueeze_buffer_t *_allocate_bsq_buffer(size_t payload_size) {
    size_t total = sizeof(bitsqueeze_buffer_t) + payload_size;
    bitsqueeze_buffer_t *buf = (bitsqueeze_buffer_t *)calloc(1, total);
    if (!buf) return NULL;
    buf->payload = ((uint8_t *)buf) + sizeof(bitsqueeze_buffer_t);
    return buf;
}

static void _fixup_payload_pointers(bitsqueeze_buffer_t *buf) {
    if (!buf || !buf->payload) return;

    switch (buf->method) {
        case Q8_0: {
            q8_0_array_t *arr = (q8_0_array_t *)buf->payload;
            arr->scales = (float *)(arr + 1);
            arr->data = (int8_t *)(arr->scales + arr->num_blocks);
            break;
        }
        case Q4_0: {
            q4_0_array_t *arr = (q4_0_array_t *)buf->payload;
            const uint64_t packed_elems = (arr->num_elements + 1) / 2;
            arr->scales = (float *)(arr + 1);
            arr->data = (int8_t *)(arr->scales + arr->num_blocks);
            (void)packed_elems; /* silence unused warning in case of static analysis */
            break;
        }
        case Q2_K: {
            q2_k_array_t *arr = (q2_k_array_t *)buf->payload;
            arr->super_blocks = (super_block_q2_k *)(arr + 1);
            break;
        }
        case TOPK: {
            sparse_array_t *arr = (sparse_array_t *)buf->payload;
            uint32_t sparse_elements = (uint32_t)arr->num_tokens * arr->num_sparse_features;
            arr->sparse_indices = (uint16_t *)(arr + 1);
            arr->values = (float *)(arr->sparse_indices + sparse_elements);
            break;
        }
        case BF16: {
            bf16_array_t *arr = (bf16_array_t *)buf->payload;
            arr->data = (uint16_t *)(arr + 1);
            break;
        }
        case FP16: {
            fp16_array_t *arr = (fp16_array_t *)buf->payload;
            arr->data = (uint16_t *)(arr + 1);
            break;
        }
        case FP8: {
            fp8_array_t *arr = (fp8_array_t *)buf->payload;
            arr->data = (uint8_t *)(arr + 1);
            break;
        }
        case FP4: {
            fp4_array_t *arr = (fp4_array_t *)buf->payload;
            uint64_t packed = (arr->num_elements + 1) / 2;
            arr->data = (uint8_t *)(arr + 1);
            (void)packed;
            break;
        }
        case MXFP8: {
            mxfp8_array_t *arr = (mxfp8_array_t *)buf->payload;
            arr->scales = (int8_t *)(arr + 1);
            arr->data = (uint8_t *)(arr->scales + arr->num_blocks);
            break;
        }
        case MXFP4: {
            mxfp4_array_t *arr = (mxfp4_array_t *)buf->payload;
            arr->scales = (int8_t *)(arr + 1);
            uint64_t packed = (arr->num_elements + 1) / 2;
            arr->data = (uint8_t *)(arr->scales + arr->num_blocks);
            (void)packed;
            break;
        }
        case NVFP4: {
            nvfp4_array_t *arr = (nvfp4_array_t *)buf->payload;
            arr->block_scales = (uint8_t *)(arr + 1);
            uint64_t packed = (arr->num_elements + 1) / 2;
            arr->data = (uint8_t *)(arr->block_scales + arr->num_blocks);
            (void)packed;
            break;
        }
        case NF4: {
            nf4_array_t *arr = (nf4_array_t *)buf->payload;
            arr->block_scales = (float *)(arr + 1);
            uint64_t packed = (arr->num_elements + 1) / 2;
            arr->data = (uint8_t *)(arr->block_scales + arr->num_blocks);
            (void)packed;
            break;
        }
        case NF4_DQ: {
            nf4_dq_array_t *arr = (nf4_dq_array_t *)buf->payload;
            arr->block_scales = (uint8_t *)(arr + 1);
            uint64_t packed = (arr->num_elements + 1) / 2;
            arr->data = (uint8_t *)(arr->block_scales + arr->num_blocks);
            (void)packed;
            break;
        }
        case IQ2_XXS: {
            iq2_xxs_array_t *arr = (iq2_xxs_array_t *)buf->payload;
            arr->scales = (uint16_t *)(arr + 1);
            arr->qs = (uint8_t *)(arr->scales + arr->num_super_blocks);
            break;
        }
        case IQ2_XS: {
            iq2_xs_array_t *arr = (iq2_xs_array_t *)buf->payload;
            arr->d = (uint16_t *)(arr + 1);
            arr->qs = (uint16_t *)(arr->d + arr->num_super_blocks);
            arr->scales = (uint8_t *)(arr->qs + arr->num_super_blocks * 32);
            break;
        }
        case IQ2_S: {
            iq2_s_array_t *arr = (iq2_s_array_t *)buf->payload;
            arr->d = (uint16_t *)(arr + 1);
            arr->qs = (uint8_t *)(arr->d + arr->num_super_blocks);
            arr->qh = arr->qs + arr->num_super_blocks * 64;
            arr->scales = arr->qh + arr->num_super_blocks * 8;
            break;
        }
        default:
            break;
    }
}

static int64_t _get_payload_size(const bitsqueeze_buffer_t *buf) {
    if (!buf) return 0;
    switch (buf->method) {
        case Q8_0:
            return get_q8_0_array((const q8_0_array_t *)buf->payload);
        case Q4_0:
            return get_q4_0_array_size((const q4_0_array_t *)buf->payload);
        case Q2_K:
            return get_q2_k_array_size((const q2_k_array_t *)buf->payload);
        case TOPK:
            return (int64_t)get_sparse_array_size((const sparse_array_t *)buf->payload);
        case BF16:
            return get_bf16_array_size((const bf16_array_t *)buf->payload);
        case FP16:
            return get_fp16_array_size((const fp16_array_t *)buf->payload);
        case FP8:
            return get_fp8_array_size((const fp8_array_t *)buf->payload);
        case FP4:
            return get_fp4_array_size((const fp4_array_t *)buf->payload);
        case MXFP8:
            return get_mxfp8_array_size((const mxfp8_array_t *)buf->payload);
        case MXFP4:
            return get_mxfp4_array_size((const mxfp4_array_t *)buf->payload);
        case NVFP4:
            return get_nvfp4_array_size((const nvfp4_array_t *)buf->payload);
        case NF4:
            return get_nf4_array_size((const nf4_array_t *)buf->payload);
        case NF4_DQ:
            return get_nf4_dq_array_size((const nf4_dq_array_t *)buf->payload);
        case IQ2_XXS:
            return get_iq2_xxs_array_size((const iq2_xxs_array_t *)buf->payload);
        case IQ2_XS:
            return get_iq2_xs_array_size((const iq2_xs_array_t *)buf->payload);
        case IQ2_S:
            return get_iq2_s_array_size((const iq2_s_array_t *)buf->payload);
        default:
            return 0;
    }
}

int bsq_compress_1d(const float *src,
                    uint64_t num_elements,
                    bsq_method_t method,
                    bitsqueeze_buffer_t **out) {
    if (!src || num_elements == 0 || !out || *out) return 1;

    switch (method) {
        case Q8_0: {
            q8_0_array_t *arr = NULL;
            if (q8_0_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_q8_0_array(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_q8_0_array(arr);
                return 1;
            }

            buf->method = Q8_0;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_q8_0_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case Q4_0: {
            q4_0_array_t *arr = NULL;
            if (q4_0_compress(src, num_elements, 0, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_q4_0_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_q4_0_array(arr);
                return 1;
            }

            buf->method = Q4_0;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_q4_0_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case Q2_K: {
            q2_k_array_t *arr = NULL;
            if (q2_k_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_q2_k_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_q2_k_array(arr);
                return 1;
            }

            buf->method = Q2_K;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_q2_k_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case BF16: {
            bf16_array_t *arr = NULL;
            if (bf16_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_bf16_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_bf16_array(arr);
                return 1;
            }

            buf->method = BF16;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_bf16_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case FP16: {
            fp16_array_t *arr = NULL;
            if (fp16_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_fp16_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_fp16_array(arr);
                return 1;
            }

            buf->method = FP16;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_fp16_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case FP8: {
            fp8_array_t *arr = NULL;
            if (fp8_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_fp8_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_fp8_array(arr);
                return 1;
            }

            buf->method = FP8;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_fp8_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case FP4: {
            fp4_array_t *arr = NULL;
            if (fp4_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_fp4_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_fp4_array(arr);
                return 1;
            }

            buf->method = FP4;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_fp4_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case MXFP8: {
            mxfp8_array_t *arr = NULL;
            if (mxfp8_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_mxfp8_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_mxfp8_array(arr);
                return 1;
            }

            buf->method = MXFP8;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_mxfp8_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case MXFP4: {
            mxfp4_array_t *arr = NULL;
            if (mxfp4_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_mxfp4_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_mxfp4_array(arr);
                return 1;
            }

            buf->method = MXFP4;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_mxfp4_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case NVFP4: {
            nvfp4_array_t *arr = NULL;
            if (nvfp4_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_nvfp4_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_nvfp4_array(arr);
                return 1;
            }

            buf->method = NVFP4;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_nvfp4_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case NF4: {
            nf4_array_t *arr = NULL;
            if (nf4_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_nf4_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_nf4_array(arr);
                return 1;
            }

            buf->method = NF4;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_nf4_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case NF4_DQ: {
            nf4_dq_array_t *arr = NULL;
            if (nf4_dq_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_nf4_dq_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_nf4_dq_array(arr);
                return 1;
            }

            buf->method = NF4_DQ;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_nf4_dq_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case IQ2_XXS: {
            iq2_xxs_array_t *arr = NULL;
            if (iq2_xxs_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_iq2_xxs_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_iq2_xxs_array(arr);
                return 1;
            }

            buf->method = IQ2_XXS;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_iq2_xxs_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case IQ2_XS: {
            iq2_xs_array_t *arr = NULL;
            if (iq2_xs_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_iq2_xs_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_iq2_xs_array(arr);
                return 1;
            }

            buf->method = IQ2_XS;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_iq2_xs_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case IQ2_S: {
            iq2_s_array_t *arr = NULL;
            if (iq2_s_compress(src, num_elements, &arr) || !arr) return 1;
            const size_t payload_size = (size_t)get_iq2_s_array_size(arr);

            bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
            if (!buf) {
                free_iq2_s_array(arr);
                return 1;
            }

            buf->method = IQ2_S;
            buf->shape.num_elements = num_elements;
            memcpy(buf->payload, arr, payload_size);
            free_iq2_s_array(arr);
            _fixup_payload_pointers(buf);
            *out = buf;
            return 0;
        }
        case TOPK:
        default:
            return 1; /* invalid method for 1D compression */
    }
}

int bsq_compress_2d(const float *src,
                    uint16_t num_tokens,
                    uint16_t num_features,
                    float sparse_ratio,
                    bsq_method_t method,
                    bitsqueeze_buffer_t **out) {
    if (!src || !out || *out || num_tokens == 0 || num_features == 0) return 1;
    if (method != TOPK) return 1;

    sparse_array_t *arr = NULL;
    if (topk_compress(src, num_tokens, num_features, sparse_ratio, &arr) || !arr) return 1;

    const size_t payload_size = (size_t)get_sparse_array_size(arr);
    bitsqueeze_buffer_t *buf = _allocate_bsq_buffer(payload_size);
    if (!buf) {
        free_sparse_array(arr);
        return 1;
    }

    buf->method = TOPK;
    buf->shape.num_tokens = num_tokens;
    buf->shape.num_features = num_features;
    buf->shape.sparse_ratio = sparse_ratio;
    memcpy(buf->payload, arr, payload_size);
    free_sparse_array(arr);
    _fixup_payload_pointers(buf);
    *out = buf;
    return 0;
}

int bsq_decompress(const bitsqueeze_buffer_t *buf,
                   float *dst,
                   uint64_t dst_num_elements) {
    if (!buf || !dst || !buf->payload) return 1;

    switch (buf->method) {
        case Q8_0: {
            const q8_0_array_t *arr = (const q8_0_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return q8_0_decompress(arr, dst);
        }
        case Q4_0: {
            const q4_0_array_t *arr = (const q4_0_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return q4_0_decompress(arr, dst);
        }
        case Q2_K: {
            const q2_k_array_t *arr = (const q2_k_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return q2_k_decompress(arr, dst);
        }
        case BF16: {
            const bf16_array_t *arr = (const bf16_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return bf16_decompress(arr, dst);
        }
        case FP16: {
            const fp16_array_t *arr = (const fp16_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return fp16_decompress(arr, dst);
        }
        case FP8: {
            const fp8_array_t *arr = (const fp8_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return fp8_decompress(arr, dst);
        }
        case FP4: {
            const fp4_array_t *arr = (const fp4_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return fp4_decompress(arr, dst);
        }
        case TOPK: {
            const sparse_array_t *arr = (const sparse_array_t *)buf->payload;
            uint64_t expected = (uint64_t)arr->num_tokens * arr->num_features;
            if (dst_num_elements < expected) return 1;
            return topk_decompress(arr, dst);
        }
        case MXFP8: {
            const mxfp8_array_t *arr = (const mxfp8_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return mxfp8_decompress(arr, dst);
        }
        case MXFP4: {
            const mxfp4_array_t *arr = (const mxfp4_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return mxfp4_decompress(arr, dst);
        }
        case NVFP4: {
            const nvfp4_array_t *arr = (const nvfp4_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return nvfp4_decompress(arr, dst);
        }
        case NF4: {
            const nf4_array_t *arr = (const nf4_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return nf4_decompress(arr, dst);
        }
        case NF4_DQ: {
            const nf4_dq_array_t *arr = (const nf4_dq_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return nf4_dq_decompress(arr, dst);
        }
        case IQ2_XXS: {
            const iq2_xxs_array_t *arr = (const iq2_xxs_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return iq2_xxs_decompress(arr, dst);
        }
        case IQ2_XS: {
            const iq2_xs_array_t *arr = (const iq2_xs_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return iq2_xs_decompress(arr, dst);
        }
        case IQ2_S: {
            const iq2_s_array_t *arr = (const iq2_s_array_t *)buf->payload;
            if (dst_num_elements < arr->num_elements) return 1;
            return iq2_s_decompress(arr, dst);
        }
        default:
            return 1;
    }
}

int64_t bsq_get_packed_size(const bitsqueeze_buffer_t *buf) {
    if (!buf) return 0;
    int64_t payload = _get_payload_size(buf);
    if (payload <= 0) return 0;
    return (int64_t)sizeof(bitsqueeze_buffer_t) + payload;
}

bitsqueeze_buffer_t *load_bsq_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(bitsqueeze_buffer_t)) return NULL;

    bitsqueeze_buffer_t *buf = (bitsqueeze_buffer_t *)calloc(1, buffer_size);
    if (!buf) return NULL;

    memcpy(buf, buffer, buffer_size);
    buf->payload = ((uint8_t *)buf) + sizeof(bitsqueeze_buffer_t);

    const int64_t expected_size = bsq_get_packed_size(buf);
    if (expected_size == 0 || buffer_size < expected_size) {
        free(buf);
        return NULL;
    }

    _fixup_payload_pointers(buf);
    return buf;
}

void bsq_free(bitsqueeze_buffer_t *buf) {
    if (!buf) return;
    free(buf);
}



================================================
FILE: src/float_quantization/bf16_impl.c
================================================
#include "float_quantization/bf16_impl.h"

static int64_t _get_bf16_array_size(const bf16_array_t *bf16_array) {
    if (!bf16_array) return 0;
    return (int64_t)(sizeof(bf16_array_t) + bf16_array->num_elements * sizeof(uint16_t));
}

bf16_array_t *allocate_bf16_array(uint64_t num_elements) {
    if (!num_elements) return NULL;

    size_t total = sizeof(bf16_array_t) + num_elements * sizeof(uint16_t);
    bf16_array_t *arr = (bf16_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->data = (uint16_t *)(arr + 1);
    return arr;
}

void free_bf16_array(bf16_array_t *bf16_array) {
    if (!bf16_array) return;
    free(bf16_array);
}

int64_t get_bf16_array_size(const bf16_array_t *bf16_array) {
    return _get_bf16_array_size(bf16_array);
}

bf16_array_t *load_bf16_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(bf16_array_t)) return NULL;

    bf16_array_t *arr = (bf16_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_bf16_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->data = (uint16_t *)(arr + 1);
    return arr;
}

int bf16_compress(const float *float_array,
                  uint64_t num_elements,
                  bf16_array_t **bf16_array) {
    if (!float_array || num_elements == 0 || !bf16_array || *bf16_array) return 1;

    bf16_array_t *arr = allocate_bf16_array(num_elements);
    if (!arr) return 1;

    for (uint64_t i = 0; i < num_elements; ++i) {
        arr->data[i] = bf16_from_fp32_value(float_array[i]);
    }

    *bf16_array = arr;
    return 0;
}

int bf16_decompress(const bf16_array_t *bf16_array,
                    float *float_array) {
    if (!bf16_array || !float_array) return 1;

    for (uint64_t i = 0; i < bf16_array->num_elements; ++i) {
        float_array[i] = fp32_from_bf16_value(bf16_array->data[i]);
    }
    return 0;
}



================================================
FILE: src/float_quantization/fp16_impl.c
================================================
#include "float_quantization/fp16_impl.h"

static int64_t _get_fp16_array_size(const fp16_array_t *fp16_array) {
    if (!fp16_array) return 0;
    return (int64_t)(sizeof(fp16_array_t) + fp16_array->num_elements * sizeof(uint16_t));
}

fp16_array_t *allocate_fp16_array(uint64_t num_elements) {
    if (!num_elements) return NULL;

    size_t total = sizeof(fp16_array_t) + num_elements * sizeof(uint16_t);
    fp16_array_t *arr = (fp16_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->data = (uint16_t *)(arr + 1);
    return arr;
}

void free_fp16_array(fp16_array_t *fp16_array) {
    if (!fp16_array) return;
    free(fp16_array);
}

int64_t get_fp16_array_size(const fp16_array_t *fp16_array) {
    return _get_fp16_array_size(fp16_array);
}

fp16_array_t *load_fp16_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(fp16_array_t)) return NULL;

    fp16_array_t *arr = (fp16_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_fp16_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->data = (uint16_t *)(arr + 1);
    return arr;
}

int fp16_compress(const float *float_array,
                  uint64_t num_elements,
                  fp16_array_t **fp16_array) {
    if (!float_array || num_elements == 0 || !fp16_array || *fp16_array) return 1;

    fp16_array_t *arr = allocate_fp16_array(num_elements);
    if (!arr) return 1;

    for (uint64_t i = 0; i < num_elements; ++i) {
        arr->data[i] = fp16_ieee_from_fp32_value(float_array[i]);
    }

    *fp16_array = arr;
    return 0;
}

int fp16_decompress(const fp16_array_t *fp16_array,
                    float *float_array) {
    if (!fp16_array || !float_array) return 1;

    for (uint64_t i = 0; i < fp16_array->num_elements; ++i) {
        float_array[i] = fp16_ieee_to_fp32_value(fp16_array->data[i]);
    }
    return 0;
}



================================================
FILE: src/float_quantization/fp4_impl.c
================================================
#include "float_quantization/fp4_impl.h"

#define FP4_EXPONENT_BIAS 1
#define FP4_EXP_BITS      2
#define FP4_MANT_BITS     1

static int64_t _get_fp4_array_size(const fp4_array_t *fp4_array) {
    if (!fp4_array) return 0;
    const uint64_t packed_elems = (fp4_array->num_elements + 1) / 2;
    return sizeof(fp4_array_t)
         + packed_elems * sizeof(uint8_t);
}

fp4_array_t *allocate_fp4_array(uint64_t num_elements) {
    if (!num_elements) return NULL;

    uint64_t packed_elems = (num_elements + 1) / 2;
    size_t total = sizeof(fp4_array_t) + packed_elems * sizeof(uint8_t);

    fp4_array_t *arr = (fp4_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->data         = (uint8_t *)(arr + 1);
    arr->scale        = 1.0f;
    return arr;
}

void free_fp4_array(fp4_array_t *fp4_array) {
    if (!fp4_array) return;
    free(fp4_array);
}

int64_t get_fp4_array_size(const fp4_array_t *fp4_array) {
    return _get_fp4_array_size(fp4_array);
}

fp4_array_t *load_fp4_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(fp4_array_t)) return NULL;

    fp4_array_t *arr = (fp4_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_fp4_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->data = (uint8_t *)(arr + 1);
    return arr;
}

static void _build_fp4_levels(float levels[8]) {
    for (int exp_field = 0; exp_field < (1 << FP4_EXP_BITS); ++exp_field) {
        for (int mant_field = 0; mant_field < (1 << FP4_MANT_BITS); ++mant_field) {
            const int idx = (exp_field << FP4_MANT_BITS) | mant_field;
            float val;
            if (exp_field == 0) {
                val = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
            } else {
                float mant = 1.0f + ((float)mant_field / 2.0f);
                int exponent = exp_field - FP4_EXPONENT_BIAS;
                val = mant * ldexpf(1.0f, exponent);
            }
            levels[idx] = val;
        }
    }
    levels[0] = 0.0f;
}

static uint8_t fp32_to_e2m1(float x) {
    static float levels[8];
    static int initialized = 0;
    if (!initialized) {
        _build_fp4_levels(levels);
        initialized = 1;
    }

    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 3);
    if (!isfinite(ax)) ax = FP4_MAX_NORM_VALUE;
    if (ax > FP4_MAX_NORM_VALUE) ax = FP4_MAX_NORM_VALUE;

    int best_idx = 0;
    float best_err = fabsf(levels[0] - ax);
    for (int idx = 1; idx < 8; ++idx) {
        float err = fabsf(levels[idx] - ax);
        if (err < best_err) {
            best_err = err;
            best_idx = idx;
        }
    }
    return (uint8_t)((sign << 3) | (best_idx & 0x7));
}

static float e2m1_to_fp32(uint8_t v) {
    const int sign = (v >> 3) & 0x1;
    const int exp_field = (v >> 1) & 0x3;
    const int mant_field = v & 0x1;

    float result;
    if (exp_field == 0) {
        result = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
    } else {
        float mant = 1.0f + ((float)mant_field / 2.0f);
        int exponent = exp_field - FP4_EXPONENT_BIAS;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static float choose_scale(const float *arr, uint64_t n) {
    float abs_max = 0.0f;
    for (uint64_t i = 0; i < n; ++i) {
        float v = arr[i];
        if (!isfinite(v)) continue;
        float av = fabsf(v);
        if (av > abs_max) abs_max = av;
    }
    if (abs_max == 0.0f) return 1.0f;
    return abs_max / FP4_MAX_NORM_VALUE;
}

int fp4_compress(const float *float_array,
                 uint64_t num_elements,
                 fp4_array_t **fp4_array) {
    if (!float_array || num_elements == 0 || !fp4_array || *fp4_array) return 1;

    fp4_array_t *arr = allocate_fp4_array(num_elements);
    if (!arr) return 1;

    float scale = choose_scale(float_array, num_elements);
    if (scale == 0.0f) scale = 1.0f;
    arr->scale = scale;
    float inv_scale = 1.0f / scale;

    for (uint64_t i = 0; i < num_elements; ++i) {
        float v = float_array[i] * inv_scale;
        uint8_t code = fp32_to_e2m1(v) & 0xF;
        const uint64_t packed_idx = i / 2;
        if ((i % 2) == 0) {
            arr->data[packed_idx] = (uint8_t)(code << 4);
        } else {
            arr->data[packed_idx] |= code;
        }
    }

    *fp4_array = arr;
    return 0;
}

int fp4_decompress(const fp4_array_t *fp4_array,
                   float *float_array) {
    if (!fp4_array || !float_array) return 1;

    const float scale = fp4_array->scale;
    const uint8_t *src = fp4_array->data;

    for (uint64_t i = 0; i < fp4_array->num_elements; ++i) {
        const uint64_t packed_idx = i / 2;
        uint8_t packed = src[packed_idx];
        uint8_t code = (i % 2 == 0) ? (packed >> 4) : (packed & 0xF);
        float v = e2m1_to_fp32(code);
        float_array[i] = scale * v;
    }
    return 0;
}



================================================
FILE: src/float_quantization/fp8_impl.c
================================================
#include "float_quantization/fp8_impl.h"

#define FP8_EXPONENT_BIAS 7
#define FP8_EXP_BITS      4
#define FP8_MANT_BITS     3

static int64_t _get_fp8_array_size(const fp8_array_t *fp8_array) {
    if (!fp8_array) return 0;
    return sizeof(fp8_array_t)
         + fp8_array->num_elements * sizeof(uint8_t);
}

fp8_array_t *allocate_fp8_array(uint64_t num_elements) {
    if (!num_elements) return NULL;

    size_t total = sizeof(fp8_array_t) + num_elements * sizeof(uint8_t);
    fp8_array_t *arr = (fp8_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->data = (uint8_t *)(arr + 1);
    arr->scale = 1.0f;
    return arr;
}

void free_fp8_array(fp8_array_t *fp8_array) {
    if (!fp8_array) return;
    free(fp8_array);
}

int64_t get_fp8_array_size(const fp8_array_t *fp8_array) {
    return _get_fp8_array_size(fp8_array);
}

fp8_array_t *load_fp8_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(fp8_array_t)) return NULL;

    fp8_array_t *arr = (fp8_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_fp8_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->data = (uint8_t *)(arr + 1);
    return arr;
}

static uint8_t fp32_to_e4m3(float x) {
    if (!isfinite(x)) x = (x < 0.0f) ? -FP8_MAX_NORM_VALUE : FP8_MAX_NORM_VALUE;
    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 7);
    if (ax > FP8_MAX_NORM_VALUE) ax = FP8_MAX_NORM_VALUE;

    int exp2;
    float mant = frexpf(ax, &exp2);
    int exponent_field = exp2 - 1 + FP8_EXPONENT_BIAS;

    if (exponent_field <= 0) {
        int mant_field = (int)lrintf(ax * 512.0f);
        if (mant_field > 7) mant_field = 7;
        return (uint8_t)((sign << 7) | (mant_field & 0x7));
    }

    int mant_field = (int)lrintf(((mant * 2.0f) - 1.0f) * 8.0f);
    if (mant_field > 7) {
        mant_field = 0;
        exponent_field += 1;
    }

    if (exponent_field >= (1 << FP8_EXP_BITS)) {
        exponent_field = (1 << FP8_EXP_BITS) - 1;
        mant_field = 7;
    }

    return (uint8_t)((sign << 7) | ((exponent_field & 0xF) << 3) | (mant_field & 0x7));
}

static float e4m3_to_fp32(uint8_t v) {
    const int sign = (v >> 7) & 0x1;
    const int exponent_field = (v >> 3) & 0xF;
    const int mant_field = v & 0x7;

    float result;
    if (exponent_field == 0) {
        float mant = (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, 1 - FP8_EXPONENT_BIAS);
    } else {
        int exponent = exponent_field - FP8_EXPONENT_BIAS;
        float mant = 1.0f + (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static float choose_scale(const float *arr, uint64_t n) {
    float abs_max = 0.0f;
    for (uint64_t i = 0; i < n; ++i) {
        float v = arr[i];
        if (!isfinite(v)) continue;
        float av = fabsf(v);
        if (av > abs_max) abs_max = av;
    }
    if (abs_max == 0.0f) return 1.0f;
    return abs_max / FP8_MAX_NORM_VALUE;
}

int fp8_compress(const float *float_array,
                 uint64_t num_elements,
                 fp8_array_t **fp8_array) {
    if (!float_array || num_elements == 0 || !fp8_array || *fp8_array) return 1;

    fp8_array_t *arr = allocate_fp8_array(num_elements);
    if (!arr) return 1;

    float scale = choose_scale(float_array, num_elements);
    if (scale == 0.0f) scale = 1.0f;
    arr->scale = scale;
    float inv_scale = 1.0f / scale;

    for (uint64_t i = 0; i < num_elements; ++i) {
        float v = float_array[i] * inv_scale;
        arr->data[i] = fp32_to_e4m3(v);
    }

    *fp8_array = arr;
    return 0;
}

int fp8_decompress(const fp8_array_t *fp8_array,
                   float *float_array) {
    if (!fp8_array || !float_array) return 1;

    const float scale = fp8_array->scale;
    for (uint64_t i = 0; i < fp8_array->num_elements; ++i) {
        float v = e4m3_to_fp32(fp8_array->data[i]);
        float_array[i] = scale * v;
    }
    return 0;
}



================================================
FILE: src/float_quantization/mxfp4_impl.c
================================================
#include "float_quantization/mxfp4_impl.h"

#define FP4_EXPONENT_BIAS 1
#define FP4_EXP_BITS      2
#define FP4_MANT_BITS     1

static int64_t _get_mxfp4_array_size(const mxfp4_array_t *mxfp4_array) {
    if (!mxfp4_array) return 0;
    const uint64_t packed_elems = (mxfp4_array->num_elements + 1) / 2;
    return sizeof(mxfp4_array_t)
         + mxfp4_array->num_blocks * sizeof(int8_t)
         + packed_elems * sizeof(uint8_t);
}

mxfp4_array_t *allocate_mxfp4_array(uint64_t num_elements,
                                    uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    uint64_t packed_elems = (num_elements + 1) / 2;
    size_t total = sizeof(mxfp4_array_t)
                 + num_blocks * sizeof(int8_t)
                 + packed_elems * sizeof(uint8_t);

    mxfp4_array_t *arr = (mxfp4_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->num_blocks   = num_blocks;
    arr->block_size   = block_size;
    arr->scales       = (int8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->scales + num_blocks);
    return arr;
}

void free_mxfp4_array(mxfp4_array_t *mxfp4_array) {
    if (!mxfp4_array) return;
    free(mxfp4_array);
}

int64_t get_mxfp4_array_size(const mxfp4_array_t *mxfp4_array) {
    return _get_mxfp4_array_size(mxfp4_array);
}

mxfp4_array_t *load_mxfp4_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(mxfp4_array_t)) return NULL;

    mxfp4_array_t *arr = (mxfp4_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_mxfp4_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->scales = (int8_t *)(arr + 1);
    const uint64_t packed_elems = (arr->num_elements + 1) / 2;
    arr->data   = (uint8_t *)(arr->scales + arr->num_blocks);
    (void)packed_elems;
    return arr;
}

/* Precompute the 8 positive E2M1 values (exp 0-3, mant 0-1) */
static void _build_fp4_levels(float levels[8]) {
    for (int exp_field = 0; exp_field < (1 << FP4_EXP_BITS); ++exp_field) {
        for (int mant_field = 0; mant_field < (1 << FP4_MANT_BITS); ++mant_field) {
            const int idx = (exp_field << FP4_MANT_BITS) | mant_field;
            float val;
            if (exp_field == 0) {
                /* subnormal style: leading 0, exponent = 1 - bias */
                val = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
            } else {
                float mant = 1.0f + ((float)mant_field / 2.0f);
                int exponent = exp_field - FP4_EXPONENT_BIAS;
                val = mant * ldexpf(1.0f, exponent);
            }
            levels[idx] = val;
        }
    }
    levels[0] = 0.0f; /* ensure exact zero for exp=0, mant=0 */
}

static uint8_t fp32_to_e2m1(float x) {
    static float levels[8];
    static int initialized = 0;
    if (!initialized) {
        _build_fp4_levels(levels);
        initialized = 1;
    }

    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 3);
    if (!isfinite(ax)) ax = MXFP4_MAX_NORM_VALUE;
    if (ax > MXFP4_MAX_NORM_VALUE) ax = MXFP4_MAX_NORM_VALUE;

    /* Find nearest level */
    int best_idx = 0;
    float best_err = levels[0];
    best_err = fabsf(levels[0] - ax);

    for (int idx = 1; idx < 8; ++idx) {
        float err = fabsf(levels[idx] - ax);
        if (err < best_err) {
            best_err = err;
            best_idx = idx;
        }
    }

    /* best_idx encodes exp/mant: upper 2 bits exp, lower 1 bit mant */
    return (uint8_t)((sign << 3) | (best_idx & 0x7));
}

static float e2m1_to_fp32(uint8_t v) {
    const int sign = (v >> 3) & 0x1;
    const int exp_field = (v >> 1) & 0x3;
    const int mant_field = v & 0x1;

    float result;
    if (exp_field == 0) {
        result = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
    } else {
        float mant = 1.0f + ((float)mant_field / 2.0f);
        int exponent = exp_field - FP4_EXPONENT_BIAS;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static int8_t choose_scale_exponent(float abs_max) {
    if (abs_max <= 0.0f) return 0;
    float target = abs_max / MXFP4_MAX_NORM_VALUE;
    if (target <= 0.0f) return 0;
    return (int8_t)ceilf(log2f(target));
}

static int _quantize_mxfp4(const float *float_array, mxfp4_array_t *arr) {
    if (!float_array || !arr) return 1;

    const uint64_t block_size   = arr->block_size;
    const uint64_t num_blocks   = arr->num_blocks;
    const uint64_t num_elements = arr->num_elements;
    uint8_t *dst = arr->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i];
            if (!isfinite(v)) v = 0.0f;
            float av = fabsf(v);
            if (av > abs_max) abs_max = av;
        }

        int8_t scale_exp = choose_scale_exponent(abs_max);
        arr->scales[b] = scale_exp;
        float inv_scale = ldexpf(1.0f, -scale_exp);

        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i] * inv_scale;
            uint8_t code = fp32_to_e2m1(v) & 0xF;
            const uint64_t packed_idx = (start + i) / 2;
            if (((start + i) % 2) == 0) {
                dst[packed_idx] = (uint8_t)(code << 4);
            } else {
                dst[packed_idx] |= code;
            }
        }
    }
    return 0;
}

int mxfp4_compress(const float *float_array,
                   uint64_t num_elements,
                   mxfp4_array_t **mxfp4_array) {
    if (!float_array || num_elements == 0 || !mxfp4_array || *mxfp4_array) return 1;

    mxfp4_array_t *arr = allocate_mxfp4_array(num_elements, DEFAULT_MXFP4_BLOCK_SIZE);
    if (!arr) return 1;

    if (_quantize_mxfp4(float_array, arr)) {
        free_mxfp4_array(arr);
        return 1;
    }

    *mxfp4_array = arr;
    return 0;
}

int mxfp4_decompress(const mxfp4_array_t *mxfp4_array,
                     float *float_array) {
    if (!mxfp4_array || !float_array) return 1;

    const uint64_t block_size   = mxfp4_array->block_size;
    const uint64_t num_blocks   = mxfp4_array->num_blocks;
    const uint64_t num_elements = mxfp4_array->num_elements;
    const uint8_t *src = mxfp4_array->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);
        float scale = ldexpf(1.0f, mxfp4_array->scales[b]);

        for (uint64_t i = 0; i < remain; ++i) {
            const uint64_t packed_idx = (start + i) / 2;
            uint8_t packed = src[packed_idx];
            uint8_t code = ((start + i) % 2 == 0) ? (packed >> 4) : (packed & 0xF);
            float val = e2m1_to_fp32(code);
            float_array[start + i] = scale * val;
        }
    }
    return 0;
}



================================================
FILE: src/float_quantization/mxfp8_impl.c
================================================
#include "float_quantization/mxfp8_impl.h"

/* FP8 E4M3 parameters */
#define FP8_EXPONENT_BIAS 7
#define FP8_EXP_BITS      4
#define FP8_MANT_BITS     3

static int64_t _get_mxfp8_array_size(const mxfp8_array_t *mxfp8_array) {
    if (!mxfp8_array) return 0;
    return sizeof(mxfp8_array_t)
         + mxfp8_array->num_blocks * sizeof(int8_t)
         + mxfp8_array->num_elements * sizeof(uint8_t);
}

mxfp8_array_t *allocate_mxfp8_array(uint64_t num_elements,
                                    uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    size_t total = sizeof(mxfp8_array_t)
                 + num_blocks * sizeof(int8_t)
                 + num_elements * sizeof(uint8_t);

    mxfp8_array_t *arr = (mxfp8_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->num_blocks   = num_blocks;
    arr->block_size   = block_size;
    arr->scales       = (int8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->scales + num_blocks);
    return arr;
}

void free_mxfp8_array(mxfp8_array_t *mxfp8_array) {
    if (!mxfp8_array) return;
    free(mxfp8_array);
}

int64_t get_mxfp8_array_size(const mxfp8_array_t *mxfp8_array) {
    return _get_mxfp8_array_size(mxfp8_array);
}

mxfp8_array_t *load_mxfp8_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(mxfp8_array_t)) return NULL;

    mxfp8_array_t *arr = (mxfp8_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_mxfp8_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->scales = (int8_t *)(arr + 1);
    arr->data   = (uint8_t *)(arr->scales + arr->num_blocks);
    return arr;
}

static uint8_t fp32_to_e4m3(float x) {
    if (!isfinite(x)) x = (x < 0.0f) ? -MXFP8_MAX_NORM_VALUE : MXFP8_MAX_NORM_VALUE;
    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 7);

    /* Clamp to representable range before converting */
    if (ax > MXFP8_MAX_NORM_VALUE) ax = MXFP8_MAX_NORM_VALUE;

    int exp2;
    float mant = frexpf(ax, &exp2); /* ax = mant * 2^exp2, mant in [0.5, 1) */
    int exponent_field = exp2 - 1 + FP8_EXPONENT_BIAS; /* align to [1, max] for normalized */

    if (exponent_field <= 0) {
        /* Subnormal: exponent = 0, value = mant_field/8 * 2^(1 - bias) */
        int mant_field = (int)lrintf(ax * 512.0f); /* mant_field/8 * 2^-6 => mant_field / 512 */
        if (mant_field > 7) mant_field = 7;
        return (uint8_t)((sign << 7) | (mant_field & 0x7));
    }

    /* Normalized path */
    int mant_field = (int)lrintf(((mant * 2.0f) - 1.0f) * 8.0f);
    if (mant_field > 7) {
        mant_field = 0;
        exponent_field += 1;
    }

    if (exponent_field >= (1 << FP8_EXP_BITS)) {
        exponent_field = (1 << FP8_EXP_BITS) - 1;
        mant_field = 7;
    }

    return (uint8_t)((sign << 7) | ((exponent_field & 0xF) << 3) | (mant_field & 0x7));
}

static float e4m3_to_fp32(uint8_t v) {
    const int sign = (v >> 7) & 0x1;
    const int exponent_field = (v >> 3) & 0xF;
    const int mant_field = v & 0x7;

    float result;
    if (exponent_field == 0) {
        /* Subnormal (or zero) */
        float mant = (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, 1 - FP8_EXPONENT_BIAS); /* 2^-6 with bias=7 */
    } else {
        int exponent = exponent_field - FP8_EXPONENT_BIAS;
        float mant = 1.0f + (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static int8_t choose_scale_exponent(float abs_max) {
    if (abs_max <= 0.0f) return 0;
    float target = abs_max / MXFP8_MAX_NORM_VALUE;
    if (target <= 0.0f) return 0;
    int8_t exp2 = (int8_t)ceilf(log2f(target));
    return exp2;
}

static int _quantize_mxfp8(const float *float_array, mxfp8_array_t *arr) {
    if (!float_array || !arr) return 1;

    const uint64_t block_size   = arr->block_size;
    const uint64_t num_blocks   = arr->num_blocks;
    const uint64_t num_elements = arr->num_elements;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i];
            if (!isfinite(v)) v = 0.0f;
            float av = fabsf(v);
            if (av > abs_max) abs_max = av;
        }

        int8_t scale_exp = choose_scale_exponent(abs_max);
        arr->scales[b] = scale_exp;
        float scale = ldexpf(1.0f, scale_exp);

        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i] / scale;
            arr->data[start + i] = fp32_to_e4m3(v);
        }
    }
    return 0;
}

int mxfp8_compress(const float *float_array,
                   uint64_t num_elements,
                   mxfp8_array_t **mxfp8_array) {
    if (!float_array || num_elements == 0 || !mxfp8_array || *mxfp8_array) return 1;

    mxfp8_array_t *arr = allocate_mxfp8_array(num_elements, DEFAULT_MXFP8_BLOCK_SIZE);
    if (!arr) return 1;

    if (_quantize_mxfp8(float_array, arr)) {
        free_mxfp8_array(arr);
        return 1;
    }

    *mxfp8_array = arr;
    return 0;
}

int mxfp8_decompress(const mxfp8_array_t *mxfp8_array,
                     float *float_array) {
    if (!mxfp8_array || !float_array) return 1;

    const uint64_t block_size   = mxfp8_array->block_size;
    const uint64_t num_blocks   = mxfp8_array->num_blocks;
    const uint64_t num_elements = mxfp8_array->num_elements;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);
        float scale = ldexpf(1.0f, mxfp8_array->scales[b]);

        for (uint64_t i = 0; i < remain; ++i) {
            float val = e4m3_to_fp32(mxfp8_array->data[start + i]);
            float_array[start + i] = scale * val;
        }
    }
    return 0;
}



================================================
FILE: src/float_quantization/nf4_dq_impl.c
================================================
#include "float_quantization/nf4_dq_impl.h"

#define FP8_EXPONENT_BIAS 7
#define FP8_EXP_BITS      4
#define FP8_MANT_BITS     3

static const float NF4_DQ_LEVELS[16] = {
    -1.0f,
    -0.6961928009986877f,
    -0.5250730514526367f,
    -0.39491748809814453f,
    -0.28444138169288635f,
    -0.18477343022823334f,
    -0.09105003625154495f,
    0.0f,
    0.07958029955625534f,
    0.16093020141124725f,
    0.24611230194568634f,
    0.33791524171829224f,
    0.44070982933044434f,
    0.5626170039176941f,
    0.7229568362236023f,
    1.0f
};

static int64_t _get_nf4_dq_array_size(const nf4_dq_array_t *nf4_dq_array) {
    if (!nf4_dq_array) return 0;
    const uint64_t packed_elems = (nf4_dq_array->num_elements + 1) / 2;
    return sizeof(nf4_dq_array_t)
         + nf4_dq_array->num_blocks * sizeof(uint8_t)
         + packed_elems * sizeof(uint8_t);
}

nf4_dq_array_t *allocate_nf4_dq_array(uint64_t num_elements,
                                      uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    uint64_t packed_elems = (num_elements + 1) / 2;
    size_t total = sizeof(nf4_dq_array_t)
                 + num_blocks * sizeof(uint8_t)
                 + packed_elems * sizeof(uint8_t);

    nf4_dq_array_t *arr = (nf4_dq_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->num_blocks   = num_blocks;
    arr->block_size   = block_size;
    arr->dq_scale     = 1.0f;
    arr->block_scales = (uint8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + num_blocks);
    return arr;
}

void free_nf4_dq_array(nf4_dq_array_t *nf4_dq_array) {
    if (!nf4_dq_array) return;
    free(nf4_dq_array);
}

int64_t get_nf4_dq_array_size(const nf4_dq_array_t *nf4_dq_array) {
    return _get_nf4_dq_array_size(nf4_dq_array);
}

nf4_dq_array_t *load_nf4_dq_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(nf4_dq_array_t)) return NULL;

    nf4_dq_array_t *arr = (nf4_dq_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_nf4_dq_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->block_scales = (uint8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + arr->num_blocks);
    return arr;
}

static uint8_t fp32_to_e4m3(float x) {
    if (!isfinite(x)) x = (x < 0.0f) ? -NF4_DQ_FP8_MAX_NORM_VALUE : NF4_DQ_FP8_MAX_NORM_VALUE;
    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 7);
    if (ax > NF4_DQ_FP8_MAX_NORM_VALUE) ax = NF4_DQ_FP8_MAX_NORM_VALUE;

    int exp2;
    float mant = frexpf(ax, &exp2);
    int exponent_field = exp2 - 1 + FP8_EXPONENT_BIAS;

    if (exponent_field <= 0) {
        int mant_field = (int)lrintf(ax * 512.0f);
        if (mant_field > 7) mant_field = 7;
        return (uint8_t)((sign << 7) | (mant_field & 0x7));
    }

    int mant_field = (int)lrintf(((mant * 2.0f) - 1.0f) * 8.0f);
    if (mant_field > 7) {
        mant_field = 0;
        exponent_field += 1;
    }

    if (exponent_field >= (1 << FP8_EXP_BITS)) {
        exponent_field = (1 << FP8_EXP_BITS) - 1;
        mant_field = 7;
    }

    return (uint8_t)((sign << 7) | ((exponent_field & 0xF) << 3) | (mant_field & 0x7));
}

static float e4m3_to_fp32(uint8_t v) {
    const int sign = (v >> 7) & 0x1;
    const int exponent_field = (v >> 3) & 0xF;
    const int mant_field = v & 0x7;

    float result;
    if (exponent_field == 0) {
        float mant = (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, 1 - FP8_EXPONENT_BIAS);
    } else {
        int exponent = exponent_field - FP8_EXPONENT_BIAS;
        float mant = 1.0f + (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static uint8_t float_to_nf4_dq_code(float x) {
    if (!isfinite(x)) x = 0.0f;

    int best_idx = 0;
    float best_err = fabsf(x - NF4_DQ_LEVELS[0]);
    for (int i = 1; i < 16; ++i) {
        float err = fabsf(x - NF4_DQ_LEVELS[i]);
        if (err < best_err) {
            best_err = err;
            best_idx = i;
        }
    }
    return (uint8_t)best_idx;
}

static float nf4_dq_code_to_fp32(uint8_t code) {
    return NF4_DQ_LEVELS[code & 0xF];
}

static float choose_dq_scale(const float *block_scales, uint64_t num_blocks) {
    float abs_max = 0.0f;
    for (uint64_t i = 0; i < num_blocks; ++i) {
        float v = block_scales[i];
        if (!isfinite(v)) continue;
        float av = fabsf(v);
        if (av > abs_max) abs_max = av;
    }
    if (abs_max == 0.0f) return 1.0f;
    return abs_max / NF4_DQ_FP8_MAX_NORM_VALUE;
}

static int _quantize_nf4_dq(const float *float_array, nf4_dq_array_t *arr) {
    if (!float_array || !arr) return 1;

    const uint64_t block_size   = arr->block_size;
    const uint64_t num_blocks   = arr->num_blocks;
    const uint64_t num_elements = arr->num_elements;
    uint8_t *dst = arr->data;

    float *block_scales = (float *)malloc(num_blocks * sizeof(float));
    if (!block_scales) return 1;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i];
            if (!isfinite(v)) v = 0.0f;
            float av = fabsf(v);
            if (av > abs_max) abs_max = av;
        }
        block_scales[b] = (abs_max > 0.0f) ? abs_max : 1.0f;
    }

    float dq_scale = choose_dq_scale(block_scales, num_blocks);
    if (dq_scale == 0.0f) dq_scale = 1.0f;
    arr->dq_scale = dq_scale;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        uint8_t block_scale_code = fp32_to_e4m3(block_scales[b] / dq_scale);
        arr->block_scales[b] = block_scale_code;
        float block_scale = dq_scale * e4m3_to_fp32(block_scale_code);
        if (block_scale == 0.0f || !isfinite(block_scale)) block_scale = 1.0f;
        float inv_block_scale = 1.0f / block_scale;

        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i] * inv_block_scale;
            uint8_t code = float_to_nf4_dq_code(v) & 0xF;
            const uint64_t packed_idx = (start + i) / 2;
            if (((start + i) % 2) == 0) {
                dst[packed_idx] = (uint8_t)(code << 4);
            } else {
                dst[packed_idx] |= code;
            }
        }
    }

    free(block_scales);
    return 0;
}

int nf4_dq_compress(const float *float_array,
                    uint64_t num_elements,
                    nf4_dq_array_t **nf4_dq_array) {
    if (!float_array || num_elements == 0 || !nf4_dq_array || *nf4_dq_array) return 1;

    nf4_dq_array_t *arr = allocate_nf4_dq_array(num_elements, DEFAULT_NF4_DQ_BLOCK_SIZE);
    if (!arr) return 1;

    if (_quantize_nf4_dq(float_array, arr)) {
        free_nf4_dq_array(arr);
        return 1;
    }

    *nf4_dq_array = arr;
    return 0;
}

int nf4_dq_decompress(const nf4_dq_array_t *nf4_dq_array,
                      float *float_array) {
    if (!nf4_dq_array || !float_array) return 1;

    const uint64_t block_size   = nf4_dq_array->block_size;
    const uint64_t num_blocks   = nf4_dq_array->num_blocks;
    const uint64_t num_elements = nf4_dq_array->num_elements;
    const uint8_t *src = nf4_dq_array->data;
    const float dq_scale = nf4_dq_array->dq_scale;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float block_scale = dq_scale * e4m3_to_fp32(nf4_dq_array->block_scales[b]);
        if (block_scale == 0.0f || !isfinite(block_scale)) block_scale = 1.0f;

        for (uint64_t i = 0; i < remain; ++i) {
            const uint64_t packed_idx = (start + i) / 2;
            uint8_t packed = src[packed_idx];
            uint8_t code = ((start + i) % 2 == 0) ? (packed >> 4) : (packed & 0xF);
            float val = nf4_dq_code_to_fp32(code);
            float_array[start + i] = block_scale * val;
        }
    }
    return 0;
}



================================================
FILE: src/float_quantization/nf4_impl.c
================================================
#include "float_quantization/nf4_impl.h"

static const float NF4_LEVELS[16] = {
    -1.0f,
    -0.6961928009986877f,
    -0.5250730514526367f,
    -0.39491748809814453f,
    -0.28444138169288635f,
    -0.18477343022823334f,
    -0.09105003625154495f,
    0.0f,
    0.07958029955625534f,
    0.16093020141124725f,
    0.24611230194568634f,
    0.33791524171829224f,
    0.44070982933044434f,
    0.5626170039176941f,
    0.7229568362236023f,
    1.0f
};

static int64_t _get_nf4_array_size(const nf4_array_t *nf4_array) {
    if (!nf4_array) return 0;
    const uint64_t packed_elems = (nf4_array->num_elements + 1) / 2;
    return sizeof(nf4_array_t)
         + nf4_array->num_blocks * sizeof(float)
         + packed_elems * sizeof(uint8_t);
}

nf4_array_t *allocate_nf4_array(uint64_t num_elements,
                                uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    uint64_t packed_elems = (num_elements + 1) / 2;
    size_t total = sizeof(nf4_array_t)
                 + num_blocks * sizeof(float)
                 + packed_elems * sizeof(uint8_t);

    nf4_array_t *arr = (nf4_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->num_blocks   = num_blocks;
    arr->block_size   = block_size;
    arr->block_scales = (float *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + num_blocks);
    return arr;
}

void free_nf4_array(nf4_array_t *nf4_array) {
    if (!nf4_array) return;
    free(nf4_array);
}

int64_t get_nf4_array_size(const nf4_array_t *nf4_array) {
    return _get_nf4_array_size(nf4_array);
}

nf4_array_t *load_nf4_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(nf4_array_t)) return NULL;

    nf4_array_t *arr = (nf4_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_nf4_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->block_scales = (float *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + arr->num_blocks);
    return arr;
}

static uint8_t float_to_nf4_code(float x) {
    if (!isfinite(x)) x = 0.0f;

    int best_idx = 0;
    float best_err = fabsf(x - NF4_LEVELS[0]);
    for (int i = 1; i < 16; ++i) {
        float err = fabsf(x - NF4_LEVELS[i]);
        if (err < best_err) {
            best_err = err;
            best_idx = i;
        }
    }
    return (uint8_t)best_idx;
}

static float nf4_code_to_fp32(uint8_t code) {
    return NF4_LEVELS[code & 0xF];
}

int nf4_compress(const float *float_array,
                 uint64_t num_elements,
                 nf4_array_t **nf4_array) {
    if (!float_array || num_elements == 0 || !nf4_array || *nf4_array) return 1;

    nf4_array_t *arr = allocate_nf4_array(num_elements, DEFAULT_NF4_BLOCK_SIZE);
    if (!arr) return 1;

    const uint64_t block_size = arr->block_size;
    const uint64_t num_blocks = arr->num_blocks;
    const uint64_t total = arr->num_elements;
    uint8_t *dst = arr->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= total)
                                  ? block_size
                                  : (total - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i];
            if (!isfinite(v)) v = 0.0f;
            float av = fabsf(v);
            if (av > abs_max) abs_max = av;
        }
        float block_scale = (abs_max > 0.0f) ? abs_max : 1.0f;
        arr->block_scales[b] = block_scale;
        float inv_block_scale = 1.0f / block_scale;

        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i] * inv_block_scale;
            uint8_t code = float_to_nf4_code(v) & 0xF;
            const uint64_t packed_idx = (start + i) / 2;
            if (((start + i) % 2) == 0) {
                dst[packed_idx] = (uint8_t)(code << 4);
            } else {
                dst[packed_idx] |= code;
            }
        }
    }

    *nf4_array = arr;
    return 0;
}

int nf4_decompress(const nf4_array_t *nf4_array,
                   float *float_array) {
    if (!nf4_array || !float_array) return 1;

    const uint64_t block_size   = nf4_array->block_size;
    const uint64_t num_blocks   = nf4_array->num_blocks;
    const uint64_t num_elements = nf4_array->num_elements;
    const uint8_t *src = nf4_array->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float block_scale = nf4_array->block_scales[b];
        if (block_scale == 0.0f || !isfinite(block_scale)) block_scale = 1.0f;

        for (uint64_t i = 0; i < remain; ++i) {
            const uint64_t packed_idx = (start + i) / 2;
            uint8_t packed = src[packed_idx];
            uint8_t code = ((start + i) % 2 == 0) ? (packed >> 4) : (packed & 0xF);
            float val = nf4_code_to_fp32(code);
            float_array[start + i] = block_scale * val;
        }
    }
    return 0;
}



================================================
FILE: src/float_quantization/nvfp4_impl.c
================================================
#include "float_quantization/nvfp4_impl.h"

#define FP8_EXPONENT_BIAS 7
#define FP8_EXP_BITS      4
#define FP8_MANT_BITS     3

#define FP4_EXPONENT_BIAS 1
#define FP4_EXP_BITS      2
#define FP4_MANT_BITS     1

static int64_t _get_nvfp4_array_size(const nvfp4_array_t *nvfp4_array) {
    if (!nvfp4_array) return 0;
    const uint64_t packed_elems = (nvfp4_array->num_elements + 1) / 2;
    return sizeof(nvfp4_array_t)
         + nvfp4_array->num_blocks * sizeof(uint8_t)
         + packed_elems * sizeof(uint8_t);
}

nvfp4_array_t *allocate_nvfp4_array(uint64_t num_elements,
                                    uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    uint64_t packed_elems = (num_elements + 1) / 2;
    size_t total = sizeof(nvfp4_array_t)
                 + num_blocks * sizeof(uint8_t)
                 + packed_elems * sizeof(uint8_t);

    nvfp4_array_t *arr = (nvfp4_array_t *)calloc(1, total);
    if (!arr) return NULL;

    arr->num_elements = num_elements;
    arr->num_blocks   = num_blocks;
    arr->block_size   = block_size;
    arr->block_scales = (uint8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + num_blocks);
    arr->tensor_scale = 1.0f;
    return arr;
}

void free_nvfp4_array(nvfp4_array_t *nvfp4_array) {
    if (!nvfp4_array) return;
    free(nvfp4_array);
}

int64_t get_nvfp4_array_size(const nvfp4_array_t *nvfp4_array) {
    return _get_nvfp4_array_size(nvfp4_array);
}

nvfp4_array_t *load_nvfp4_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(nvfp4_array_t)) return NULL;

    nvfp4_array_t *arr = (nvfp4_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;

    memcpy(arr, buffer, buffer_size);
    const int64_t expected = _get_nvfp4_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }

    arr->block_scales = (uint8_t *)(arr + 1);
    arr->data         = (uint8_t *)(arr->block_scales + arr->num_blocks);
    return arr;
}

static uint8_t fp32_to_e4m3(float x) {
    if (!isfinite(x)) x = (x < 0.0f) ? -NVFP4_FP8_MAX_NORM : NVFP4_FP8_MAX_NORM;
    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 7);
    if (ax > NVFP4_FP8_MAX_NORM) ax = NVFP4_FP8_MAX_NORM;

    int exp2;
    float mant = frexpf(ax, &exp2);
    int exponent_field = exp2 - 1 + FP8_EXPONENT_BIAS;

    if (exponent_field <= 0) {
        int mant_field = (int)lrintf(ax * 512.0f);
        if (mant_field > 7) mant_field = 7;
        return (uint8_t)((sign << 7) | (mant_field & 0x7));
    }

    int mant_field = (int)lrintf(((mant * 2.0f) - 1.0f) * 8.0f);
    if (mant_field > 7) {
        mant_field = 0;
        exponent_field += 1;
    }

    if (exponent_field >= (1 << FP8_EXP_BITS)) {
        exponent_field = (1 << FP8_EXP_BITS) - 1;
        mant_field = 7;
    }

    return (uint8_t)((sign << 7) | ((exponent_field & 0xF) << 3) | (mant_field & 0x7));
}

static float e4m3_to_fp32(uint8_t v) {
    const int sign = (v >> 7) & 0x1;
    const int exponent_field = (v >> 3) & 0xF;
    const int mant_field = v & 0x7;

    float result;
    if (exponent_field == 0) {
        float mant = (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, 1 - FP8_EXPONENT_BIAS);
    } else {
        int exponent = exponent_field - FP8_EXPONENT_BIAS;
        float mant = 1.0f + (float)mant_field / 8.0f;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static void _build_fp4_levels(float levels[8]) {
    for (int exp_field = 0; exp_field < (1 << FP4_EXP_BITS); ++exp_field) {
        for (int mant_field = 0; mant_field < (1 << FP4_MANT_BITS); ++mant_field) {
            const int idx = (exp_field << FP4_MANT_BITS) | mant_field;
            float val;
            if (exp_field == 0) {
                val = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
            } else {
                float mant = 1.0f + ((float)mant_field / 2.0f);
                int exponent = exp_field - FP4_EXPONENT_BIAS;
                val = mant * ldexpf(1.0f, exponent);
            }
            levels[idx] = val;
        }
    }
    levels[0] = 0.0f;
}

static uint8_t fp32_to_e2m1(float x) {
    static float levels[8];
    static int initialized = 0;
    if (!initialized) {
        _build_fp4_levels(levels);
        initialized = 1;
    }

    const int sign = signbit(x) ? 1 : 0;
    float ax = fabsf(x);
    if (ax == 0.0f) return (uint8_t)(sign << 3);
    if (!isfinite(ax)) ax = NVFP4_MAX_NORM_VALUE;
    if (ax > NVFP4_MAX_NORM_VALUE) ax = NVFP4_MAX_NORM_VALUE;

    int best_idx = 0;
    float best_err = fabsf(levels[0] - ax);
    for (int idx = 1; idx < 8; ++idx) {
        float err = fabsf(levels[idx] - ax);
        if (err < best_err) {
            best_err = err;
            best_idx = idx;
        }
    }
    return (uint8_t)((sign << 3) | (best_idx & 0x7));
}

static float e2m1_to_fp32(uint8_t v) {
    const int sign = (v >> 3) & 0x1;
    const int exp_field = (v >> 1) & 0x3;
    const int mant_field = v & 0x1;

    float result;
    if (exp_field == 0) {
        result = ((float)mant_field / 2.0f) * ldexpf(1.0f, 1 - FP4_EXPONENT_BIAS);
    } else {
        float mant = 1.0f + ((float)mant_field / 2.0f);
        int exponent = exp_field - FP4_EXPONENT_BIAS;
        result = mant * ldexpf(1.0f, exponent);
    }
    return sign ? -result : result;
}

static float choose_tensor_scale(const float *arr, uint64_t n) {
    float abs_max = 0.0f;
    for (uint64_t i = 0; i < n; ++i) {
        float v = arr[i];
        if (!isfinite(v)) continue;
        float av = fabsf(v);
        if (av > abs_max) abs_max = av;
    }
    if (abs_max == 0.0f) return 1.0f;
    return abs_max / NVFP4_MAX_NORM_VALUE;
}

static uint8_t choose_block_scale_fp8(const float *arr, uint64_t start, uint64_t len, float tensor_scale) {
    float abs_max = 0.0f;
    for (uint64_t i = 0; i < len; ++i) {
        float v = arr[start + i] / tensor_scale;
        if (!isfinite(v)) v = 0.0f;
        float av = fabsf(v);
        if (av > abs_max) abs_max = av;
    }
    float target = abs_max / NVFP4_MAX_NORM_VALUE;
    float scale = (target > 0.0f) ? target : 1.0f;
    return fp32_to_e4m3(scale);
}

static int _quantize_nvfp4(const float *float_array, nvfp4_array_t *arr) {
    if (!float_array || !arr) return 1;

    const uint64_t block_size   = arr->block_size;
    const uint64_t num_blocks   = arr->num_blocks;
    const uint64_t num_elements = arr->num_elements;
    uint8_t *dst = arr->data;

    arr->tensor_scale = choose_tensor_scale(float_array, num_elements);
    float inv_tensor_scale = 1.0f / arr->tensor_scale;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        uint8_t block_scale_code = choose_block_scale_fp8(float_array, start, remain, arr->tensor_scale);
        arr->block_scales[b] = block_scale_code;
        float block_scale = e4m3_to_fp32(block_scale_code);
        float inv_block_scale = 1.0f / block_scale;

        for (uint64_t i = 0; i < remain; ++i) {
            float v = float_array[start + i] * inv_tensor_scale * inv_block_scale;
            uint8_t code = fp32_to_e2m1(v) & 0xF;
            const uint64_t packed_idx = (start + i) / 2;
            if (((start + i) % 2) == 0) {
                dst[packed_idx] = (uint8_t)(code << 4);
            } else {
                dst[packed_idx] |= code;
            }
        }
    }
    return 0;
}

int nvfp4_compress(const float *float_array,
                   uint64_t num_elements,
                   nvfp4_array_t **nvfp4_array) {
    if (!float_array || num_elements == 0 || !nvfp4_array || *nvfp4_array) return 1;

    nvfp4_array_t *arr = allocate_nvfp4_array(num_elements, DEFAULT_NVFP4_BLOCK_SIZE);
    if (!arr) return 1;

    if (_quantize_nvfp4(float_array, arr)) {
        free_nvfp4_array(arr);
        return 1;
    }

    *nvfp4_array = arr;
    return 0;
}

int nvfp4_decompress(const nvfp4_array_t *nvfp4_array,
                     float *float_array) {
    if (!nvfp4_array || !float_array) return 1;

    const uint64_t block_size   = nvfp4_array->block_size;
    const uint64_t num_blocks   = nvfp4_array->num_blocks;
    const uint64_t num_elements = nvfp4_array->num_elements;
    const uint8_t *src = nvfp4_array->data;
    const float tensor_scale = nvfp4_array->tensor_scale;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);
        float block_scale = e4m3_to_fp32(nvfp4_array->block_scales[b]);
        float scale = tensor_scale * block_scale;

        for (uint64_t i = 0; i < remain; ++i) {
            const uint64_t packed_idx = (start + i) / 2;
            uint8_t packed = src[packed_idx];
            uint8_t code = ((start + i) % 2 == 0) ? (packed >> 4) : (packed & 0xF);
            float val = e2m1_to_fp32(code);
            float_array[start + i] = scale * val;
        }
    }
    return 0;
}



================================================
FILE: src/int_quantization/iq2_s_impl.c
================================================
#include "int_quantization/iq2_s_impl.h"
#include "datatype/fp16/fp16.h"

/* ============================================================================
 * Lookup Tables
 * ============================================================================ */

static const uint8_t kmask_iq2xs[8] = {1, 2, 4, 8, 16, 32, 64, 128};

/* 1024-entry grid for IQ2_S
 * PLACEHOLDER - copy from ggml-common.h iq2s_grid table */
static const uint64_t iq2s_grid[1024] = {
    0x0808080808080808, 0x080808080808082b, 0x0808080808081919, 0x0808080808082b08,
    0x0808080808082b2b, 0x0808080808190819, 0x0808080808191908, 0x080808080819192b,
    0x0808080808192b19, 0x08080808082b0808, 0x08080808082b082b, 0x08080808082b1919,
    0x08080808082b2b08, 0x0808080819080819, 0x0808080819081908, 0x080808081908192b,
    0x0808080819082b19, 0x0808080819190808, 0x080808081919082b, 0x0808080819191919,
    0x0808080819192b08, 0x08080808192b0819, 0x08080808192b1908, 0x08080808192b192b,
    0x08080808192b2b19, 0x080808082b080808, 0x080808082b08082b, 0x080808082b081919,
    0x080808082b082b08, 0x080808082b190819, 0x080808082b191908, 0x080808082b2b0808,
    0x080808082b2b1919, 0x080808082b2b2b2b, 0x0808081908080819, 0x0808081908081908,
    0x080808190808192b, 0x0808081908082b19, 0x0808081908190808, 0x080808190819082b,
    0x0808081908191919, 0x0808081908192b08, 0x08080819082b0819, 0x08080819082b1908,
    0x0808081919080808, 0x080808191908082b, 0x0808081919081919, 0x0808081919082b08,
    0x0808081919190819, 0x0808081919191908, 0x080808191919192b, 0x0808081919192b19,
    0x08080819192b0808, 0x08080819192b1919, 0x08080819192b2b08, 0x080808192b080819,
    0x080808192b081908, 0x080808192b190808, 0x080808192b19082b, 0x080808192b191919,
    0x080808192b2b0819, 0x080808192b2b1908, 0x0808082b08080808, 0x0808082b0808082b,
    0x0808082b08081919, 0x0808082b08082b08, 0x0808082b08190819, 0x0808082b08191908,
    0x0808082b082b0808, 0x0808082b082b2b2b, 0x0808082b19080819, 0x0808082b19081908,
    0x0808082b1908192b, 0x0808082b19082b19, 0x0808082b19190808, 0x0808082b19191919,
    0x0808082b2b080808, 0x0808082b2b081919, 0x0808082b2b082b2b, 0x0808082b2b191908,
    0x0808082b2b2b082b, 0x0808190808080819, 0x0808190808081908, 0x080819080808192b,
    0x0808190808082b19, 0x0808190808190808, 0x080819080819082b, 0x0808190808191919,
    0x0808190808192b08, 0x08081908082b0819, 0x08081908082b1908, 0x08081908082b192b,
    0x08081908082b2b19, 0x0808190819080808, 0x080819081908082b, 0x0808190819081919,
    0x0808190819082b08, 0x0808190819082b2b, 0x0808190819190819, 0x0808190819191908,
    0x080819081919192b, 0x0808190819192b19, 0x08081908192b0808, 0x08081908192b082b,
    0x08081908192b1919, 0x080819082b080819, 0x080819082b081908, 0x080819082b08192b,
    0x080819082b082b19, 0x080819082b190808, 0x080819082b191919, 0x080819082b192b08,
    0x080819082b2b0819, 0x080819082b2b1908, 0x0808191908080808, 0x080819190808082b,
    0x0808191908081919, 0x0808191908082b08, 0x0808191908082b2b, 0x0808191908190819,
    0x0808191908191908, 0x080819190819192b, 0x0808191908192b19, 0x08081919082b0808,
    0x08081919082b1919, 0x08081919082b2b08, 0x0808191919080819, 0x0808191919081908,
    0x080819191908192b, 0x0808191919082b19, 0x0808191919190808, 0x080819191919082b,
    0x0808191919191919, 0x0808191919192b08, 0x08081919192b0819, 0x08081919192b1908,
    0x080819192b080808, 0x080819192b08082b, 0x080819192b081919, 0x080819192b082b08,
    0x080819192b190819, 0x080819192b191908, 0x080819192b2b0808, 0x0808192b08080819,
    0x0808192b08081908, 0x0808192b0808192b, 0x0808192b08082b19, 0x0808192b08190808,
    0x0808192b08191919, 0x0808192b19080808, 0x0808192b19081919, 0x0808192b19082b08,
    0x0808192b19190819, 0x0808192b19191908, 0x0808192b192b0808, 0x0808192b2b080819,
    0x0808192b2b081908, 0x0808192b2b190808, 0x08082b0808080808, 0x08082b080808082b,
    0x08082b0808081919, 0x08082b0808082b08, 0x08082b0808190819, 0x08082b0808191908,
    0x08082b080819192b, 0x08082b0808192b19, 0x08082b08082b0808, 0x08082b08082b1919,
    0x08082b08082b2b2b, 0x08082b0819080819, 0x08082b0819081908, 0x08082b081908192b,
    0x08082b0819082b19, 0x08082b0819190808, 0x08082b081919082b, 0x08082b0819191919,
    0x08082b0819192b08, 0x08082b08192b0819, 0x08082b08192b1908, 0x08082b082b080808,
    0x08082b082b081919, 0x08082b082b191908, 0x08082b082b2b2b2b, 0x08082b1908080819,
    0x08082b1908081908, 0x08082b1908190808, 0x08082b190819082b, 0x08082b1908191919,
    0x08082b1908192b08, 0x08082b19082b0819, 0x08082b1919080808, 0x08082b1919081919,
    0x08082b1919082b08, 0x08082b1919190819, 0x08082b1919191908, 0x08082b19192b0808,
    0x08082b192b080819, 0x08082b192b190808, 0x08082b2b08080808, 0x08082b2b08190819,
    0x08082b2b08191908, 0x08082b2b082b082b, 0x08082b2b082b2b08, 0x08082b2b082b2b2b,
    0x08082b2b19190808, 0x08082b2b2b192b19, 0x0819080808080819, 0x0819080808081908,
    0x081908080808192b, 0x0819080808082b19, 0x0819080808190808, 0x081908080819082b,
    0x0819080808191919, 0x0819080808192b08, 0x08190808082b0819, 0x08190808082b1908,
    0x08190808082b192b, 0x0819080819080808, 0x081908081908082b, 0x0819080819081919,
    0x0819080819082b08, 0x0819080819190819, 0x0819080819191908, 0x081908081919192b,
    0x0819080819192b19, 0x08190808192b0808, 0x08190808192b082b, 0x08190808192b1919,
    0x08190808192b2b08, 0x081908082b080819, 0x081908082b081908, 0x081908082b08192b,
    0x081908082b190808, 0x081908082b191919, 0x081908082b192b08, 0x081908082b2b0819,
    0x081908082b2b1908, 0x0819081908080808, 0x081908190808082b, 0x0819081908081919,
    0x0819081908082b08, 0x0819081908082b2b, 0x0819081908190819, 0x0819081908191908,
    0x081908190819192b, 0x0819081908192b19, 0x08190819082b0808, 0x08190819082b082b,
    0x08190819082b1919, 0x08190819082b2b08, 0x0819081919080819, 0x0819081919081908,
    0x081908191908192b, 0x0819081919082b19, 0x0819081919190808, 0x081908191919082b,
    0x0819081919191919, 0x0819081919192b08, 0x08190819192b0819, 0x08190819192b1908,
    0x081908192b080808, 0x081908192b08082b, 0x081908192b081919, 0x081908192b082b08,
    0x081908192b190819, 0x081908192b191908, 0x0819082b08080819, 0x0819082b08081908,
    0x0819082b08082b19, 0x0819082b08190808, 0x0819082b08191919, 0x0819082b082b0819,
    0x0819082b082b1908, 0x0819082b19080808, 0x0819082b19081919, 0x0819082b19190819,
    0x0819082b19191908, 0x0819082b2b080819, 0x0819082b2b081908, 0x0819082b2b190808,
    0x0819190808080808, 0x081919080808082b, 0x0819190808081919, 0x0819190808082b08,
    0x0819190808190819, 0x0819190808191908, 0x081919080819192b, 0x0819190808192b19,
    0x08191908082b0808, 0x08191908082b1919, 0x08191908082b2b08, 0x0819190819080819,
    0x0819190819081908, 0x081919081908192b, 0x0819190819082b19, 0x0819190819190808,
    0x081919081919082b, 0x0819190819191919, 0x0819190819192b08, 0x08191908192b0819,
    0x08191908192b1908, 0x081919082b080808, 0x081919082b08082b, 0x081919082b081919,
    0x081919082b082b08, 0x081919082b190819, 0x081919082b191908, 0x081919082b2b0808,
    0x0819191908080819, 0x0819191908081908, 0x081919190808192b, 0x0819191908082b19,
    0x0819191908190808, 0x081919190819082b, 0x0819191908191919, 0x0819191908192b08,
    0x08191919082b0819, 0x08191919082b1908, 0x0819191919080808, 0x081919191908082b,
    0x0819191919081919, 0x0819191919082b08, 0x0819191919190819, 0x0819191919191908,
    0x08191919192b0808, 0x081919192b080819, 0x081919192b081908, 0x081919192b190808,
    0x0819192b08080808, 0x0819192b08081919, 0x0819192b08082b08, 0x0819192b08190819,
    0x0819192b08191908, 0x0819192b082b0808, 0x0819192b19080819, 0x0819192b19081908,
    0x0819192b19190808, 0x0819192b2b080808, 0x0819192b2b2b2b2b, 0x08192b0808080819,
    0x08192b0808081908, 0x08192b080808192b, 0x08192b0808082b19, 0x08192b0808190808,
    0x08192b0808191919, 0x08192b0808192b08, 0x08192b08082b0819, 0x08192b0819080808,
    0x08192b081908082b, 0x08192b0819081919, 0x08192b0819082b08, 0x08192b0819190819,
    0x08192b0819191908, 0x08192b08192b0808, 0x08192b082b080819, 0x08192b082b081908,
    0x08192b1908080808, 0x08192b190808082b, 0x08192b1908081919, 0x08192b1908082b08,
    0x08192b1908190819, 0x08192b1908191908, 0x08192b19082b0808, 0x08192b1919080819,
    0x08192b1919081908, 0x08192b1919190808, 0x08192b19192b2b19, 0x08192b192b2b082b,
    0x08192b2b08081908, 0x08192b2b08190808, 0x08192b2b19080808, 0x08192b2b1919192b,
    0x082b080808080808, 0x082b08080808082b, 0x082b080808081919, 0x082b080808082b08,
    0x082b080808190819, 0x082b080808191908, 0x082b08080819192b, 0x082b080808192b19,
    0x082b0808082b0808, 0x082b0808082b1919, 0x082b0808082b2b2b, 0x082b080819080819,
    0x082b080819081908, 0x082b080819190808, 0x082b08081919082b, 0x082b080819191919,
    0x082b0808192b1908, 0x082b08082b080808, 0x082b08082b082b2b, 0x082b08082b191908,
    0x082b08082b2b2b2b, 0x082b081908080819, 0x082b081908081908, 0x082b081908190808,
    0x082b08190819082b, 0x082b081908191919, 0x082b0819082b0819, 0x082b081919080808,
    0x082b08191908082b, 0x082b081919081919, 0x082b081919190819, 0x082b081919191908,
    0x082b0819192b0808, 0x082b08192b080819, 0x082b08192b081908, 0x082b08192b190808,
    0x082b082b08080808, 0x082b082b08082b2b, 0x082b082b082b082b, 0x082b082b082b2b08,
    0x082b082b082b2b2b, 0x082b082b19081908, 0x082b082b19190808, 0x082b082b2b082b08,
    0x082b082b2b082b2b, 0x082b082b2b2b2b08, 0x082b190808080819, 0x082b190808081908,
    0x082b19080808192b, 0x082b190808082b19, 0x082b190808190808, 0x082b190808191919,
    0x082b190808192b08, 0x082b1908082b0819, 0x082b1908082b1908, 0x082b190819080808,
    0x082b19081908082b, 0x082b190819081919, 0x082b190819082b08, 0x082b190819190819,
    0x082b190819191908, 0x082b1908192b0808, 0x082b19082b080819, 0x082b19082b081908,
    0x082b19082b190808, 0x082b191908080808, 0x082b191908081919, 0x082b191908082b08,
    0x082b191908190819, 0x082b191908191908, 0x082b1919082b0808, 0x082b191919080819,
    0x082b191919081908, 0x082b191919190808, 0x082b1919192b192b, 0x082b19192b080808,
    0x082b192b08080819, 0x082b192b08081908, 0x082b192b08190808, 0x082b192b19080808,
    0x082b192b19192b19, 0x082b2b0808080808, 0x082b2b0808081919, 0x082b2b0808190819,
    0x082b2b0808191908, 0x082b2b0819080819, 0x082b2b0819081908, 0x082b2b0819190808,
    0x082b2b082b082b2b, 0x082b2b082b2b2b2b, 0x082b2b1908080819, 0x082b2b1908081908,
    0x082b2b1908190808, 0x082b2b192b191919, 0x082b2b2b08082b2b, 0x082b2b2b082b082b,
    0x082b2b2b192b1908, 0x082b2b2b2b082b08, 0x082b2b2b2b082b2b, 0x1908080808080819,
    0x1908080808081908, 0x190808080808192b, 0x1908080808082b19, 0x1908080808190808,
    0x190808080819082b, 0x1908080808191919, 0x1908080808192b08, 0x1908080808192b2b,
    0x19080808082b0819, 0x19080808082b1908, 0x19080808082b192b, 0x1908080819080808,
    0x190808081908082b, 0x1908080819081919, 0x1908080819082b08, 0x1908080819082b2b,
    0x1908080819190819, 0x1908080819191908, 0x190808081919192b, 0x1908080819192b19,
    0x19080808192b0808, 0x19080808192b082b, 0x19080808192b1919, 0x190808082b080819,
    0x190808082b081908, 0x190808082b190808, 0x190808082b191919, 0x190808082b192b08,
    0x190808082b2b0819, 0x190808082b2b1908, 0x1908081908080808, 0x190808190808082b,
    0x1908081908081919, 0x1908081908082b08, 0x1908081908190819, 0x1908081908191908,
    0x190808190819192b, 0x1908081908192b19, 0x19080819082b0808, 0x19080819082b082b,
    0x19080819082b1919, 0x1908081919080819, 0x1908081919081908, 0x190808191908192b,
    0x1908081919082b19, 0x1908081919190808, 0x190808191919082b, 0x1908081919191919,
    0x1908081919192b08, 0x19080819192b0819, 0x19080819192b1908, 0x190808192b080808,
    0x190808192b08082b, 0x190808192b081919, 0x190808192b082b08, 0x190808192b190819,
    0x190808192b191908, 0x190808192b2b0808, 0x1908082b08080819, 0x1908082b08081908,
    0x1908082b08190808, 0x1908082b0819082b, 0x1908082b08191919, 0x1908082b08192b08,
    0x1908082b082b1908, 0x1908082b19080808, 0x1908082b19081919, 0x1908082b19082b08,
    0x1908082b19190819, 0x1908082b19191908, 0x1908082b192b0808, 0x1908082b2b080819,
    0x1908082b2b081908, 0x1908190808080808, 0x190819080808082b, 0x1908190808081919,
    0x1908190808082b08, 0x1908190808082b2b, 0x1908190808190819, 0x1908190808191908,
    0x190819080819192b, 0x1908190808192b19, 0x19081908082b0808, 0x19081908082b082b,
    0x19081908082b1919, 0x19081908082b2b08, 0x1908190819080819, 0x1908190819081908,
    0x190819081908192b, 0x1908190819082b19, 0x1908190819190808, 0x190819081919082b,
    0x1908190819191919, 0x1908190819192b08, 0x19081908192b0819, 0x19081908192b1908,
    0x190819082b080808, 0x190819082b08082b, 0x190819082b081919, 0x190819082b082b08,
    0x190819082b190819, 0x190819082b191908, 0x190819082b2b0808, 0x1908191908080819,
    0x1908191908081908, 0x190819190808192b, 0x1908191908082b19, 0x1908191908190808,
    0x190819190819082b, 0x1908191908191919, 0x1908191908192b08, 0x19081919082b0819,
    0x19081919082b1908, 0x1908191919080808, 0x190819191908082b, 0x1908191919081919,
    0x1908191919082b08, 0x1908191919190819, 0x1908191919191908, 0x19081919192b0808,
    0x19081919192b2b2b, 0x190819192b080819, 0x190819192b081908, 0x190819192b190808,
    0x1908192b08080808, 0x1908192b0808082b, 0x1908192b08081919, 0x1908192b08082b08,
    0x1908192b08190819, 0x1908192b08191908, 0x1908192b082b0808, 0x1908192b19080819,
    0x1908192b19081908, 0x1908192b19190808, 0x1908192b2b080808, 0x1908192b2b2b1919,
    0x19082b0808080819, 0x19082b0808081908, 0x19082b0808082b19, 0x19082b0808190808,
    0x19082b080819082b, 0x19082b0808191919, 0x19082b0808192b08, 0x19082b08082b0819,
    0x19082b08082b1908, 0x19082b0819080808, 0x19082b081908082b, 0x19082b0819081919,
    0x19082b0819082b08, 0x19082b0819190819, 0x19082b0819191908, 0x19082b08192b0808,
    0x19082b082b081908, 0x19082b082b190808, 0x19082b1908080808, 0x19082b190808082b,
    0x19082b1908081919, 0x19082b1908082b08, 0x19082b1908190819, 0x19082b1908191908,
    0x19082b19082b0808, 0x19082b1919080819, 0x19082b1919081908, 0x19082b1919190808,
    0x19082b192b080808, 0x19082b192b19192b, 0x19082b2b08080819, 0x19082b2b08081908,
    0x19082b2b08190808, 0x19082b2b19080808, 0x1919080808080808, 0x191908080808082b,
    0x1919080808081919, 0x1919080808082b08, 0x1919080808190819, 0x1919080808191908,
    0x191908080819192b, 0x1919080808192b19, 0x19190808082b0808, 0x19190808082b082b,
    0x19190808082b1919, 0x19190808082b2b08, 0x1919080819080819, 0x1919080819081908,
    0x191908081908192b, 0x1919080819082b19, 0x1919080819190808, 0x191908081919082b,
    0x1919080819191919, 0x1919080819192b08, 0x19190808192b0819, 0x19190808192b1908,
    0x191908082b080808, 0x191908082b08082b, 0x191908082b081919, 0x191908082b082b08,
    0x191908082b190819, 0x191908082b191908, 0x1919081908080819, 0x1919081908081908,
    0x191908190808192b, 0x1919081908082b19, 0x1919081908190808, 0x191908190819082b,
    0x1919081908191919, 0x1919081908192b08, 0x19190819082b0819, 0x19190819082b1908,
    0x1919081919080808, 0x191908191908082b, 0x1919081919081919, 0x1919081919082b08,
    0x1919081919190819, 0x1919081919191908, 0x19190819192b0808, 0x191908192b080819,
    0x191908192b081908, 0x191908192b190808, 0x1919082b08080808, 0x1919082b08081919,
    0x1919082b08082b08, 0x1919082b08190819, 0x1919082b08191908, 0x1919082b082b0808,
    0x1919082b19080819, 0x1919082b19081908, 0x1919082b19190808, 0x1919082b192b2b19,
    0x1919082b2b080808, 0x1919190808080819, 0x1919190808081908, 0x191919080808192b,
    0x1919190808082b19, 0x1919190808190808, 0x191919080819082b, 0x1919190808191919,
    0x1919190808192b08, 0x19191908082b0819, 0x19191908082b1908, 0x1919190819080808,
    0x191919081908082b, 0x1919190819081919, 0x1919190819082b08, 0x1919190819190819,
    0x1919190819191908, 0x19191908192b0808, 0x191919082b080819, 0x191919082b081908,
    0x191919082b190808, 0x1919191908080808, 0x191919190808082b, 0x1919191908081919,
    0x1919191908082b08, 0x1919191908190819, 0x1919191908191908, 0x19191919082b0808,
    0x1919191919080819, 0x1919191919081908, 0x1919191919190808, 0x191919192b080808,
    0x1919192b08080819, 0x1919192b08081908, 0x1919192b08190808, 0x1919192b082b192b,
    0x1919192b19080808, 0x19192b0808080808, 0x19192b080808082b, 0x19192b0808081919,
    0x19192b0808082b08, 0x19192b0808190819, 0x19192b0808191908, 0x19192b08082b0808,
    0x19192b0819080819, 0x19192b0819081908, 0x19192b0819190808, 0x19192b0819192b2b,
    0x19192b082b080808, 0x19192b1908080819, 0x19192b1908081908, 0x19192b1908190808,
    0x19192b1919080808, 0x19192b2b08080808, 0x19192b2b08192b19, 0x19192b2b2b081919,
    0x19192b2b2b2b2b08, 0x192b080808080819, 0x192b080808081908, 0x192b08080808192b,
    0x192b080808190808, 0x192b08080819082b, 0x192b080808191919, 0x192b080808192b08,
    0x192b0808082b0819, 0x192b0808082b1908, 0x192b080819080808, 0x192b080819081919,
    0x192b080819082b08, 0x192b080819190819, 0x192b080819191908, 0x192b0808192b0808,
    0x192b08082b081908, 0x192b08082b190808, 0x192b081908080808, 0x192b08190808082b,
    0x192b081908081919, 0x192b081908082b08, 0x192b081908190819, 0x192b081908191908,
    0x192b0819082b0808, 0x192b081919080819, 0x192b081919081908, 0x192b081919190808,
    0x192b08192b080808, 0x192b08192b192b19, 0x192b082b08081908, 0x192b082b08190808,
    0x192b082b19080808, 0x192b082b1919192b, 0x192b082b2b2b0819, 0x192b190808080808,
    0x192b190808081919, 0x192b190808082b08, 0x192b190808190819, 0x192b190808191908,
    0x192b1908082b0808, 0x192b190819080819, 0x192b190819081908, 0x192b190819190808,
    0x192b19082b080808, 0x192b191908080819, 0x192b191908081908, 0x192b191908190808,
    0x192b191919080808, 0x192b191919082b2b, 0x192b1919192b2b08, 0x192b19192b19082b,
    0x192b192b08080808, 0x192b192b2b191908, 0x192b2b0808080819, 0x192b2b0808081908,
    0x192b2b0808190808, 0x192b2b08192b1919, 0x192b2b082b192b08, 0x192b2b1908080808,
    0x192b2b19082b2b2b, 0x192b2b2b1908082b, 0x192b2b2b2b2b0819, 0x2b08080808080808,
    0x2b0808080808082b, 0x2b08080808081919, 0x2b08080808082b08, 0x2b08080808190819,
    0x2b08080808191908, 0x2b08080808192b19, 0x2b080808082b0808, 0x2b080808082b1919,
    0x2b08080819080819, 0x2b08080819081908, 0x2b08080819190808, 0x2b0808081919082b,
    0x2b08080819191919, 0x2b08080819192b08, 0x2b080808192b0819, 0x2b0808082b080808,
    0x2b0808082b081919, 0x2b0808082b190819, 0x2b0808082b191908, 0x2b08081908080819,
    0x2b08081908081908, 0x2b08081908082b19, 0x2b08081908190808, 0x2b0808190819082b,
    0x2b08081908191919, 0x2b08081908192b08, 0x2b080819082b0819, 0x2b080819082b1908,
    0x2b08081919080808, 0x2b0808191908082b, 0x2b08081919081919, 0x2b08081919082b08,
    0x2b08081919190819, 0x2b08081919191908, 0x2b0808192b080819, 0x2b0808192b081908,
    0x2b0808192b190808, 0x2b0808192b2b2b19, 0x2b08082b08080808, 0x2b08082b08081919,
    0x2b08082b08082b2b, 0x2b08082b08190819, 0x2b08082b08191908, 0x2b08082b19080819,
    0x2b08082b19081908, 0x2b08082b19190808, 0x2b08190808080819, 0x2b08190808081908,
    0x2b0819080808192b, 0x2b08190808082b19, 0x2b08190808190808, 0x2b0819080819082b,
    0x2b08190808191919, 0x2b08190808192b08, 0x2b081908082b0819, 0x2b08190819080808,
    0x2b0819081908082b, 0x2b08190819081919, 0x2b08190819082b08, 0x2b08190819190819,
    0x2b08190819191908, 0x2b081908192b0808, 0x2b0819082b080819, 0x2b0819082b081908,
    0x2b0819082b190808, 0x2b08191908080808, 0x2b0819190808082b, 0x2b08191908081919,
    0x2b08191908082b08, 0x2b08191908190819, 0x2b08191908191908, 0x2b081919082b0808,
    0x2b08191919080819, 0x2b08191919081908, 0x2b08191919190808, 0x2b0819192b080808,
    0x2b0819192b082b2b, 0x2b08192b08080819, 0x2b08192b08081908, 0x2b08192b08190808,
    0x2b08192b082b2b19, 0x2b08192b19080808, 0x2b082b0808080808, 0x2b082b0808081919,
    0x2b082b0808190819, 0x2b082b0808191908, 0x2b082b0819080819, 0x2b082b0819081908,
    0x2b082b0819190808, 0x2b082b082b2b082b, 0x2b082b1908080819, 0x2b082b1908081908,
    0x2b082b1919080808, 0x2b082b19192b1919, 0x2b082b2b082b082b, 0x2b082b2b19192b08,
    0x2b082b2b19192b2b, 0x2b082b2b2b08082b, 0x2b082b2b2b2b082b, 0x2b19080808080819,
    0x2b19080808081908, 0x2b19080808082b19, 0x2b19080808190808, 0x2b1908080819082b,
    0x2b19080808191919, 0x2b19080808192b08, 0x2b190808082b1908, 0x2b19080819080808,
    0x2b1908081908082b, 0x2b19080819081919, 0x2b19080819082b08, 0x2b19080819190819,
    0x2b19080819191908, 0x2b190808192b0808, 0x2b1908082b080819, 0x2b1908082b081908,
    0x2b1908082b190808, 0x2b19081908080808, 0x2b19081908081919, 0x2b19081908190819,
    0x2b19081908191908, 0x2b19081919080819, 0x2b19081919081908, 0x2b19081919190808,
    0x2b19081919192b2b, 0x2b19082b08080819, 0x2b19082b08081908, 0x2b19082b08190808,
    0x2b19082b19080808, 0x2b19082b2b2b192b, 0x2b19190808080808, 0x2b1919080808082b,
    0x2b19190808081919, 0x2b19190808082b08, 0x2b19190808190819, 0x2b19190808191908,
    0x2b191908082b0808, 0x2b19190819080819, 0x2b19190819081908, 0x2b19190819190808,
    0x2b1919082b080808, 0x2b1919082b19192b, 0x2b19191908080819, 0x2b19191908081908,
    0x2b19191908190808, 0x2b19191919080808, 0x2b1919192b192b08, 0x2b1919192b2b0819,
    0x2b19192b08080808, 0x2b19192b1908192b, 0x2b19192b192b1908, 0x2b192b0808080819,
    0x2b192b0808081908, 0x2b192b0808190808, 0x2b192b08082b192b, 0x2b192b0819080808,
    0x2b192b082b2b2b19, 0x2b192b1908080808, 0x2b192b1919082b19, 0x2b192b191919082b,
    0x2b192b2b2b190808, 0x2b2b080808080808, 0x2b2b080808081919, 0x2b2b080808082b2b,
    0x2b2b080808191908, 0x2b2b0808082b082b, 0x2b2b0808082b2b2b, 0x2b2b080819080819,
    0x2b2b080819081908, 0x2b2b080819190808, 0x2b2b08082b2b082b, 0x2b2b08082b2b2b2b,
    0x2b2b081919080808, 0x2b2b0819192b1919, 0x2b2b082b0808082b, 0x2b2b082b08082b2b,
    0x2b2b082b082b082b, 0x2b2b082b082b2b08, 0x2b2b082b082b2b2b, 0x2b2b082b2b08082b,
    0x2b2b082b2b082b08, 0x2b2b082b2b082b2b, 0x2b2b082b2b2b2b08, 0x2b2b190808080819,
    0x2b2b190808081908, 0x2b2b190808190808, 0x2b2b190819080808, 0x2b2b19082b082b19,
    0x2b2b19082b2b1908, 0x2b2b191908080808, 0x2b2b191908192b19, 0x2b2b192b19190819,
    0x2b2b2b0808082b2b, 0x2b2b2b08082b2b08, 0x2b2b2b082b2b082b, 0x2b2b2b1919191908,
    0x2b2b2b192b08192b, 0x2b2b2b2b08082b08, 0x2b2b2b2b08082b2b, 0x2b2b2b2b082b0808,
    0x2b2b2b2b082b082b, 0x2b2b2b2b082b2b08, 0x2b2b2b2b2b082b08, 0x2b2b2b2b2b2b2b2b,
};

/* ============================================================================
 * Quantization helper tables (built at runtime)
 * ============================================================================ */

static uint64_t *kgrid_q2s = NULL;
static int      *kmap_q2s = NULL;
static uint16_t *kneighbors_q2s = NULL;
static int       iq2_s_initialized = 0;

#define KMAP_SIZE 43692

static int iq2_compare_func(const void *a, const void *b) {
    const int *l = (const int *)a;
    const int *r = (const int *)b;
    return l[0] < r[0] ? -1 : l[0] > r[0] ? 1 : l[1] < r[1] ? -1 : l[1] > r[1] ? 1 : 0;
}

void iq2_s_init(void) {
    if (iq2_s_initialized) return;
    
    const int grid_size = 1024;
    const int nwant = 1;  /* IQ2_S uses only 1 neighbor level */
    
    kgrid_q2s = (uint64_t *)malloc(grid_size * sizeof(uint64_t));
    if (!kgrid_q2s) return;
    
    // for (int k = 0; k < grid_size; ++k) {
    //     kgrid_q2s[k] = iq2s_grid[k];
    // }
    // Replace this loop in iq2_s_init:
    // for (int k = 0; k < grid_size; ++k) {
    //     kgrid_q2s[k] = iq2s_grid[k];
    // }

    // With this corrected loop:
    for (int k = 0; k < grid_size; ++k) {
        uint64_t packed = iq2s_grid[k];
        uint64_t normalized = 0;
        
        for (int i = 0; i < 8; ++i) {
            // Extract the byte (e.g., 0x08, 0x19, 0x2b...)
            uint8_t val = (packed >> (i * 8)) & 0xFF;
            uint8_t q_val;

            // Map dequant values back to normalized grid coordinates (1, 3, 5, 7)
            // Values in table are approx: 8, 25, 43, 60
            if      (val < 15) q_val = 1;
            else if (val < 35) q_val = 3;
            else if (val < 55) q_val = 5;
            else               q_val = 7;

            normalized |= ((uint64_t)q_val << (i * 8));
        }
        kgrid_q2s[k] = normalized;
    }
    
    kmap_q2s = (int *)malloc(KMAP_SIZE * sizeof(int));
    if (!kmap_q2s) {
        free(kgrid_q2s); kgrid_q2s = NULL;
        return;
    }
    
    for (int i = 0; i < KMAP_SIZE; ++i) kmap_q2s[i] = -1;
    
    for (int i = 0; i < grid_size; ++i) {
        const uint8_t *aux8 = (const uint8_t *)&kgrid_q2s[i];
        uint16_t index = 0;
        for (int k = 0; k < 8; ++k) {
            uint16_t q = (aux8[k] - 1) / 2;
            index |= (q << (2 * k));
        }
        kmap_q2s[index] = i;
    }
    
    int8_t pos[8];
    int *dist2 = (int *)malloc(2 * grid_size * sizeof(int));
    if (!dist2) {
        free(kgrid_q2s); kgrid_q2s = NULL;
        free(kmap_q2s);  kmap_q2s = NULL;
        return;
    }
    
    int num_neighbors = 0, num_not_in_map = 0;
    
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2s[i] >= 0) continue;
        ++num_not_in_map;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2s + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        int n = 0, d2_prev = dist2[0], nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            ++n;
        }
        num_neighbors += n;
    }
    
    kneighbors_q2s = (uint16_t *)malloc((num_neighbors + num_not_in_map) * sizeof(uint16_t));
    if (!kneighbors_q2s) {
        free(kgrid_q2s); kgrid_q2s = NULL;
        free(kmap_q2s);  kmap_q2s = NULL;
        free(dist2);
        return;
    }
    
    int counter = 0;
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2s[i] >= 0) continue;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2s + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        kmap_q2s[i] = -(counter + 1);
        
        int d2_prev = dist2[0];
        uint16_t *start = &kneighbors_q2s[counter++];
        int n = 0, nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            kneighbors_q2s[counter++] = dist2[2*j+1];
            ++n;
        }
        *start = n;
    }
    
    free(dist2);
    iq2_s_initialized = 1;
}

void iq2_s_free_tables(void) {
    if (kgrid_q2s) { free(kgrid_q2s); kgrid_q2s = NULL; }
    if (kmap_q2s)  { free(kmap_q2s);  kmap_q2s = NULL; }
    if (kneighbors_q2s) { free(kneighbors_q2s); kneighbors_q2s = NULL; }
    iq2_s_initialized = 0;
}

/* ============================================================================
 * Array allocation and management
 * ============================================================================ */

static int64_t _get_iq2_s_array_size(const iq2_s_array_t *arr) {
    if (!arr) return 0;
    /* Header + d (2) + qs (64) + qh (8) + scales (8) per super block */
    return (int64_t)(sizeof(iq2_s_array_t) 
                   + arr->num_super_blocks * sizeof(uint16_t)  /* d */
                   + arr->num_super_blocks * 64                /* qs */
                   + arr->num_super_blocks * 8                 /* qh */
                   + arr->num_super_blocks * 8);               /* scales */
}

iq2_s_array_t *allocate_iq2_s_array(uint64_t num_elements) {
    if (!num_elements) return NULL;
    
    uint64_t num_super_blocks = (num_elements + IQ2_S_SUPER_BLOCK_SIZE - 1) / IQ2_S_SUPER_BLOCK_SIZE;
    
    size_t total = sizeof(iq2_s_array_t)
                 + num_super_blocks * sizeof(uint16_t)  /* d */
                 + num_super_blocks * 64                /* qs */
                 + num_super_blocks * 8                 /* qh */
                 + num_super_blocks * 8;                /* scales */
    
    iq2_s_array_t *arr = (iq2_s_array_t *)calloc(1, total);
    if (!arr) return NULL;
    
    arr->num_elements = num_elements;
    arr->num_super_blocks = num_super_blocks;
    arr->d = (uint16_t *)(arr + 1);
    arr->qs = (uint8_t *)(arr->d + num_super_blocks);
    arr->qh = arr->qs + num_super_blocks * 64;
    arr->scales = arr->qh + num_super_blocks * 8;
    
    return arr;
}

void free_iq2_s_array(iq2_s_array_t *arr) {
    if (arr) free(arr);
}

int64_t get_iq2_s_array_size(const iq2_s_array_t *arr) {
    return _get_iq2_s_array_size(arr);
}

iq2_s_array_t *load_iq2_s_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(iq2_s_array_t)) return NULL;
    
    iq2_s_array_t *arr = (iq2_s_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;
    
    memcpy(arr, buffer, buffer_size);
    
    const int64_t expected = _get_iq2_s_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }
    
    arr->d = (uint16_t *)(arr + 1);
    arr->qs = (uint8_t *)(arr->d + arr->num_super_blocks);
    arr->qh = arr->qs + arr->num_super_blocks * 64;
    arr->scales = arr->qh + arr->num_super_blocks * 8;
    
    return arr;
}

/* ============================================================================
 * Dequantization
 * ============================================================================ */

int iq2_s_decompress(const iq2_s_array_t *arr, float *float_array) {
    if (!arr || !float_array) return 1;
    
    const uint64_t num_super_blocks = arr->num_super_blocks;
    const uint64_t num_elements = arr->num_elements;
    
    uint64_t out_idx = 0;
    
    for (uint64_t sb = 0; sb < num_super_blocks; ++sb) {
        const float d = fp16_ieee_to_fp32_value(arr->d[sb]);
        const uint8_t *qs = arr->qs + sb * 64;
        const uint8_t *qh = arr->qh + sb * 8;
        const uint8_t *signs = qs + 32;  /* Signs stored in second half of qs */
        const uint8_t *scales_block = arr->scales + sb * 8;
        
        /* Process 8 groups of 32 values */
        for (int ib32 = 0; ib32 < 8; ++ib32) {
            float db[2];
            db[0] = d * (0.5f + (float)(scales_block[ib32] & 0xf)) * 0.25f;
            db[1] = d * (0.5f + (float)(scales_block[ib32] >> 4)) * 0.25f;
            
            /* Process 4 sub-groups of 8 values */
            for (int l = 0; l < 4; ++l) {
                const float dl = db[l / 2];
                
                /* Grid index: 8 bits from qs, 2 high bits from qh */
                uint16_t grid_idx = qs[l] | ((qh[ib32] << (8 - 2*l)) & 0x300);
                const uint8_t *grid = (const uint8_t *)(iq2s_grid + grid_idx);
                uint8_t sign_byte = signs[l];
                
                for (int j = 0; j < 8; ++j) {
                    if (out_idx < num_elements) {
                        float val = dl * (float)grid[j];
                        float_array[out_idx++] = (sign_byte & kmask_iq2xs[j]) ? -val : val;
                    }
                }
            }
            qs += 4;
            signs += 4;
        }
    }
    
    return 0;
}

/* ============================================================================
 * Quantization helpers
 * ============================================================================ */

static inline int nearest_int(float f) {
    return (int)(f + 0.5f - (f < 0));
}

static int iq2_find_best_neighbour(const uint16_t *neighbours, const uint64_t *grid,
                                   const float *xval, const float *weight, 
                                   float scale, int8_t *L) {
    int num_neighbors = neighbours[0];
    if (num_neighbors <= 0) return -1;
    
    float best_d2 = FLT_MAX;
    int grid_index = -1;
    
    for (int j = 1; j <= num_neighbors; ++j) {
        const int8_t *pg = (const int8_t *)(grid + neighbours[j]);
        float d2 = 0;
        for (int i = 0; i < 8; ++i) {
            float q = (float)pg[i];
            float diff = scale * q - xval[i];
            d2 += weight[i] * diff * diff;
        }
        if (d2 < best_d2) {
            best_d2 = d2;
            grid_index = neighbours[j];
        }
    }
    
    if (grid_index >= 0) {
        const int8_t *pg = (const int8_t *)(grid + grid_index);
        for (int i = 0; i < 8; ++i) {
            L[i] = (pg[i] - 1) / 2;
        }
    }
    
    return grid_index;
}

/* ============================================================================
 * Quantization
 * ============================================================================ */

int iq2_s_compress(const float *float_array, uint64_t num_elements, iq2_s_array_t **out) {
    if (!float_array || num_elements == 0 || !out || *out) return 1;
    
    if (!iq2_s_initialized) {
        iq2_s_init();
        if (!iq2_s_initialized) return 1;
    }
    
    iq2_s_array_t *arr = allocate_iq2_s_array(num_elements);
    if (!arr) return 1;
    
    const int kMaxQ = 3;
    const float GROUP_MAX_EPS = 1e-8f;
    
    float weight[16];
    float xval[16];
    float waux[16];
    int8_t L[16];
    int8_t Laux[16];
    uint8_t block_signs[2];
    
    /* Temporary storage for one super block */
    uint8_t qs_tmp[64];      /* 32 grid low + 32 signs */
    uint8_t qh_tmp[8];       /* grid high bits */
    uint8_t scales_tmp[8];
    float scales_f[16];
    
    for (uint64_t sb = 0; sb < arr->num_super_blocks; ++sb) {
        memset(qs_tmp, 0, sizeof(qs_tmp));
        memset(qh_tmp, 0, sizeof(qh_tmp));
        memset(scales_tmp, 0, sizeof(scales_tmp));
        
        uint64_t block_start = sb * IQ2_S_SUPER_BLOCK_SIZE;
        uint64_t block_end = block_start + IQ2_S_SUPER_BLOCK_SIZE;
        if (block_end > num_elements) block_end = num_elements;
        
        float sumx2 = 0;
        for (uint64_t i = block_start; i < block_end; ++i) {
            sumx2 += float_array[i] * float_array[i];
        }
        float sigma2 = sumx2 / (float)IQ2_S_SUPER_BLOCK_SIZE;
        
        float max_scale = 0;
        int grid_indices[32];  /* Store grid indices for all 32 sub-groups */
        uint8_t sign_patterns[32];
        
        /* Process 16 sub-groups of 16 values */
        for (int ib = 0; ib < 16; ++ib) {
            uint64_t group_start = block_start + ib * 16;
            
            for (int i = 0; i < 16; ++i) {
                uint64_t idx = group_start + i;
                float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                weight[i] = sqrtf(sigma2 + v * v);
                waux[i] = sqrtf(weight[i]);
            }
            
            /* Handle signs - NO parity constraint for IQ2_S (full 8-bit signs) */
            for (int k = 0; k < 2; ++k) {
                uint8_t s = 0;
                for (int i = 0; i < 8; ++i) {
                    uint64_t idx = group_start + 8 * k + i;
                    float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                    
                    if (v >= 0) {
                        xval[8*k + i] = v;
                    } else {
                        xval[8*k + i] = -v;
                        s |= (1 << i);
                    }
                }
                block_signs[k] = s;
            }
            
            float max = xval[0];
            for (int i = 1; i < 16; ++i) {
                if (xval[i] > max) max = xval[i];
            }
            
            if (max < GROUP_MAX_EPS) {
                scales_f[ib] = 0;
                memset(L, 0, 16);
                grid_indices[2*ib + 0] = 0;
                grid_indices[2*ib + 1] = 0;
            } else {
                float best = 0;
                float scale = max / (2 * kMaxQ - 1);
                
                for (int is = -9; is <= 9; ++is) {
                    float id = (2 * kMaxQ - 1 + is * 0.1f) / max;
                    float this_scale = 1.0f / id;
                    
                    for (int k = 0; k < 2; ++k) {
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            Laux[8*k + i] = (int8_t)l;
                        }
                        
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            u |= (Laux[8*k+i] << (2*i));
                        }
                        
                        int grid_index = kmap_q2s[u];
                        if (grid_index < 0) {
                            const uint16_t *neighbours = kneighbors_q2s - kmap_q2s[u] - 1;
                            iq2_find_best_neighbour(neighbours, kgrid_q2s, 
                                                   xval + 8*k, waux + 8*k, 
                                                   this_scale, Laux + 8*k);
                        }
                    }
                    
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 16; ++i) {
                        float w = weight[i];
                        float q = 2 * Laux[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    
                    if (sumq2 > 0 && sumqx * sumqx > best * sumq2) {
                        scale = sumqx / sumq2;
                        best = scale * sumqx;
                        memcpy(L, Laux, 16);
                    }
                }
                
                /* Final pass to get grid indices */
                if (scale > 0) {
                    float id = 1.0f / scale;
                    for (int k = 0; k < 2; ++k) {
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            u |= (l << (2*i));
                        }
                        
                        int grid_index = kmap_q2s[u];
                        if (grid_index < 0) {
                            const uint16_t *neighbours = kneighbors_q2s - kmap_q2s[u] - 1;
                            grid_index = iq2_find_best_neighbour(neighbours, kgrid_q2s, 
                                                                xval + 8*k, waux + 8*k, 
                                                                scale, L + 8*k);
                        }
                        grid_indices[2*ib + k] = (grid_index >= 0) ? grid_index : 0;
                    }
                    
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 16; ++i) {
                        float w = weight[i];
                        float q = 2 * L[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    if (sumq2 > 0) scale = sumqx / sumq2;
                } else {
                    grid_indices[2*ib + 0] = 0;
                    grid_indices[2*ib + 1] = 0;
                }
                
                scales_f[ib] = (scale >= 0) ? scale : -scale;
                if (scales_f[ib] > max_scale) max_scale = scales_f[ib];
            }
            
            sign_patterns[2*ib + 0] = block_signs[0];
            sign_patterns[2*ib + 1] = block_signs[1];
        }
        
        /* Encode block scale and pack data */
        if (max_scale == 0) {
            arr->d[sb] = 0;
            memset(arr->qs + sb * 64, 0, 64);
            memset(arr->qh + sb * 8, 0, 8);
            memset(arr->scales + sb * 8, 0, 8);
        } else {
            float d = max_scale / 31.0f;
            arr->d[sb] = fp16_ieee_from_fp32_value(d);
            float id = 1.0f / d;
            
            /* Pack grid indices and signs */
            uint8_t *qs_out = arr->qs + sb * 64;
            uint8_t *qh_out = arr->qh + sb * 8;
            
            for (int ib32 = 0; ib32 < 8; ++ib32) {
                /* Encode scales: 2 × 4-bit per byte */
                int l0 = nearest_int(0.5f * (id * scales_f[2*ib32 + 0] - 1));
                int l1 = nearest_int(0.5f * (id * scales_f[2*ib32 + 1] - 1));
                if (l0 < 0) l0 = 0; if (l0 > 15) l0 = 15;
                if (l1 < 0) l1 = 0; if (l1 > 15) l1 = 15;
                arr->scales[sb * 8 + ib32] = (uint8_t)(l0 | (l1 << 4));
                
                /* Pack grid indices: low 8 bits in qs, high 2 bits in qh */
                uint8_t qh_byte = 0;
                for (int l = 0; l < 4; ++l) {
                    int sub_idx = ib32 * 4 + l;  /* 0..31 */
                    int gi = grid_indices[sub_idx];
                    
                    qs_out[l] = (uint8_t)(gi & 0xFF);          /* low 8 bits */
                    qh_byte |= ((gi >> 8) & 0x3) << (2 * l);   /* high 2 bits */
                    
                    /* Signs in second half */
                    qs_out[32 + l] = sign_patterns[sub_idx];
                }
                qh_out[ib32] = qh_byte;
                qs_out += 4;
            }
        }
    }
    
    *out = arr;
    return 0;
}



================================================
FILE: src/int_quantization/iq2_xs_impl.c
================================================
#include "int_quantization/iq2_xs_impl.h"
#include "datatype/fp16/fp16.h"

/* ============================================================================
 * Lookup Tables
 * ============================================================================ */

static const uint8_t kmask_iq2xs[8] = {1, 2, 4, 8, 16, 32, 64, 128};

static const uint8_t ksigns_iq2xs[128] = {
      0, 129, 130,   3, 132,   5,   6, 135, 136,   9,  10, 139,  12, 141, 142,  15,
    144,  17,  18, 147,  20, 149, 150,  23,  24, 153, 154,  27, 156,  29,  30, 159,
    160,  33,  34, 163,  36, 165, 166,  39,  40, 169, 170,  43, 172,  45,  46, 175,
     48, 177, 178,  51, 180,  53,  54, 183, 184,  57,  58, 187,  60, 189, 190,  63,
    192,  65,  66, 195,  68, 197, 198,  71,  72, 201, 202,  75, 204,  77,  78, 207,
     80, 209, 210,  83, 212,  85,  86, 215, 216,  89,  90, 219,  92, 221, 222,  95,
     96, 225, 226,  99, 228, 101, 102, 231, 232, 105, 106, 235, 108, 237, 238, 111,
    240, 113, 114, 243, 116, 245, 246, 119, 120, 249, 250, 123, 252, 125, 126, 255,
};

/* 512-entry grid for IQ2_XS
 * PLACEHOLDER - copy from ggml-common.h iq2xs_grid table */
static const uint64_t iq2xs_grid[512] = {
    0x0808080808080808, 0x080808080808082b, 0x0808080808081919, 0x0808080808082b08,
    0x0808080808082b2b, 0x0808080808190819, 0x0808080808191908, 0x080808080819192b,
    0x0808080808192b19, 0x08080808082b0808, 0x08080808082b082b, 0x08080808082b1919,
    0x08080808082b2b08, 0x0808080819080819, 0x0808080819081908, 0x080808081908192b,
    0x0808080819082b19, 0x0808080819190808, 0x080808081919082b, 0x0808080819191919,
    0x0808080819192b08, 0x08080808192b0819, 0x08080808192b1908, 0x080808082b080808,
    0x080808082b08082b, 0x080808082b081919, 0x080808082b082b08, 0x080808082b190819,
    0x080808082b191908, 0x080808082b192b19, 0x080808082b2b0808, 0x0808081908080819,
    0x0808081908081908, 0x080808190808192b, 0x0808081908082b19, 0x0808081908190808,
    0x080808190819082b, 0x0808081908191919, 0x0808081908192b08, 0x0808081908192b2b,
    0x08080819082b0819, 0x08080819082b1908, 0x0808081919080808, 0x080808191908082b,
    0x0808081919081919, 0x0808081919082b08, 0x0808081919190819, 0x0808081919191908,
    0x08080819192b0808, 0x08080819192b2b08, 0x080808192b080819, 0x080808192b081908,
    0x080808192b190808, 0x0808082b08080808, 0x0808082b0808082b, 0x0808082b08081919,
    0x0808082b08082b08, 0x0808082b08190819, 0x0808082b08191908, 0x0808082b082b0808,
    0x0808082b19080819, 0x0808082b19081908, 0x0808082b19190808, 0x0808082b19191919,
    0x0808082b2b080808, 0x0808082b2b082b2b, 0x0808190808080819, 0x0808190808081908,
    0x080819080808192b, 0x0808190808082b19, 0x0808190808190808, 0x080819080819082b,
    0x0808190808191919, 0x0808190808192b08, 0x08081908082b0819, 0x08081908082b1908,
    0x0808190819080808, 0x080819081908082b, 0x0808190819081919, 0x0808190819082b08,
    0x0808190819190819, 0x0808190819191908, 0x080819081919192b, 0x08081908192b0808,
    0x080819082b080819, 0x080819082b081908, 0x080819082b190808, 0x0808191908080808,
    0x080819190808082b, 0x0808191908081919, 0x0808191908082b08, 0x0808191908190819,
    0x0808191908191908, 0x08081919082b0808, 0x0808191919080819, 0x0808191919081908,
    0x0808191919190808, 0x08081919192b0819, 0x080819192b080808, 0x0808192b08080819,
    0x0808192b08081908, 0x0808192b08190808, 0x0808192b082b192b, 0x0808192b19080808,
    0x0808192b1908082b, 0x0808192b2b081908, 0x08082b0808080808, 0x08082b080808082b,
    0x08082b0808081919, 0x08082b0808082b08, 0x08082b0808082b2b, 0x08082b0808190819,
    0x08082b0808191908, 0x08082b08082b0808, 0x08082b08082b1919, 0x08082b0819080819,
    0x08082b0819081908, 0x08082b0819190808, 0x08082b0819192b08, 0x08082b082b080808,
    0x08082b082b2b0808, 0x08082b082b2b2b2b, 0x08082b1908080819, 0x08082b1908081908,
    0x08082b1908190808, 0x08082b1919080808, 0x08082b192b080819, 0x08082b192b082b19,
    0x08082b2b08080808, 0x08082b2b082b0808, 0x08082b2b082b2b08, 0x08082b2b2b19192b,
    0x08082b2b2b2b0808, 0x0819080808080819, 0x0819080808081908, 0x081908080808192b,
    0x0819080808082b19, 0x0819080808190808, 0x081908080819082b, 0x0819080808191919,
    0x0819080808192b08, 0x08190808082b0819, 0x08190808082b1908, 0x0819080819080808,
    0x081908081908082b, 0x0819080819081919, 0x0819080819082b08, 0x0819080819190819,
    0x0819080819191908, 0x08190808192b0808, 0x08190808192b2b2b, 0x081908082b080819,
    0x081908082b081908, 0x081908082b190808, 0x0819081908080808, 0x081908190808082b,
    0x0819081908081919, 0x0819081908082b08, 0x0819081908190819, 0x0819081908191908,
    0x08190819082b0808, 0x0819081919080819, 0x0819081919081908, 0x0819081919190808,
    0x081908192b080808, 0x081908192b191908, 0x081908192b19192b, 0x0819082b08080819,
    0x0819082b08081908, 0x0819082b0808192b, 0x0819082b08190808, 0x0819082b19080808,
    0x0819082b192b0808, 0x0819190808080808, 0x081919080808082b, 0x0819190808081919,
    0x0819190808082b08, 0x0819190808190819, 0x0819190808191908, 0x08191908082b0808,
    0x0819190819080819, 0x0819190819081908, 0x0819190819082b19, 0x0819190819190808,
    0x08191908192b1908, 0x081919082b080808, 0x0819191908080819, 0x0819191908081908,
    0x0819191908190808, 0x0819191919080808, 0x0819192b08080808, 0x0819192b08191908,
    0x0819192b19082b19, 0x08192b0808080819, 0x08192b0808081908, 0x08192b0808190808,
    0x08192b080819082b, 0x08192b0819080808, 0x08192b0819191908, 0x08192b082b08192b,
    0x08192b1908080808, 0x08192b1908081919, 0x08192b19192b192b, 0x08192b2b19190819,
    0x08192b2b2b2b2b19, 0x082b080808080808, 0x082b08080808082b, 0x082b080808081919,
    0x082b080808082b08, 0x082b080808082b2b, 0x082b080808190819, 0x082b080808191908,
    0x082b0808082b0808, 0x082b080819080819, 0x082b080819081908, 0x082b080819190808,
    0x082b08082b080808, 0x082b08082b2b0808, 0x082b081908080819, 0x082b081908081908,
    0x082b081908190808, 0x082b081919080808, 0x082b081919082b08, 0x082b0819192b1919,
    0x082b082b08080808, 0x082b082b082b082b, 0x082b082b2b080808, 0x082b082b2b2b2b08,
    0x082b190808080819, 0x082b190808081908, 0x082b190808190808, 0x082b1908082b2b19,
    0x082b190819080808, 0x082b191908080808, 0x082b191919080819, 0x082b19191919082b,
    0x082b19192b192b19, 0x082b192b08080819, 0x082b192b08192b2b, 0x082b192b2b2b192b,
    0x082b2b0808080808, 0x082b2b0808082b08, 0x082b2b0808082b2b, 0x082b2b08082b0808,
    0x082b2b0819191919, 0x082b2b082b082b08, 0x082b2b082b2b082b, 0x082b2b19192b2b08,
    0x082b2b192b190808, 0x082b2b2b08082b08, 0x082b2b2b082b0808, 0x082b2b2b2b08082b,
    0x082b2b2b2b082b08, 0x082b2b2b2b082b2b, 0x1908080808080819, 0x1908080808081908,
    0x190808080808192b, 0x1908080808082b19, 0x1908080808190808, 0x190808080819082b,
    0x1908080808191919, 0x1908080808192b08, 0x19080808082b0819, 0x19080808082b1908,
    0x1908080819080808, 0x190808081908082b, 0x1908080819081919, 0x1908080819082b08,
    0x1908080819082b2b, 0x1908080819190819, 0x1908080819191908, 0x19080808192b0808,
    0x19080808192b1919, 0x190808082b080819, 0x190808082b081908, 0x190808082b190808,
    0x1908081908080808, 0x190808190808082b, 0x1908081908081919, 0x1908081908082b08,
    0x1908081908190819, 0x1908081908191908, 0x19080819082b0808, 0x1908081919080819,
    0x1908081919081908, 0x1908081919190808, 0x190808192b080808, 0x190808192b081919,
    0x190808192b2b082b, 0x1908082b08080819, 0x1908082b08081908, 0x1908082b08190808,
    0x1908082b0819082b, 0x1908082b082b2b19, 0x1908082b19080808, 0x1908190808080808,
    0x190819080808082b, 0x1908190808081919, 0x1908190808082b08, 0x1908190808190819,
    0x1908190808191908, 0x1908190808192b19, 0x19081908082b0808, 0x1908190819080819,
    0x1908190819081908, 0x1908190819190808, 0x190819082b080808, 0x190819082b191908,
    0x1908191908080819, 0x1908191908081908, 0x1908191908190808, 0x19081919082b1908,
    0x1908191919080808, 0x190819192b192b2b, 0x1908192b08080808, 0x1908192b08082b2b,
    0x1908192b19081908, 0x1908192b19190808, 0x19082b0808080819, 0x19082b0808081908,
    0x19082b0808190808, 0x19082b0819080808, 0x19082b0819081919, 0x19082b0819191908,
    0x19082b08192b082b, 0x19082b1908080808, 0x19082b1908190819, 0x19082b1919081908,
    0x19082b1919190808, 0x19082b19192b2b19, 0x19082b2b08081908, 0x1919080808080808,
    0x191908080808082b, 0x1919080808081919, 0x1919080808082b08, 0x1919080808190819,
    0x1919080808191908, 0x19190808082b0808, 0x19190808082b2b08, 0x1919080819080819,
    0x1919080819081908, 0x1919080819190808, 0x191908082b080808, 0x1919081908080819,
    0x1919081908081908, 0x1919081908190808, 0x1919081908191919, 0x1919081919080808,
    0x191908191908082b, 0x1919082b08080808, 0x1919082b19081908, 0x1919082b2b2b2b2b,
    0x1919190808080819, 0x1919190808081908, 0x1919190808190808, 0x19191908082b0819,
    0x1919190819080808, 0x19191908192b0808, 0x191919082b080819, 0x191919082b2b0819,
    0x1919191908080808, 0x1919191908082b08, 0x191919192b080808, 0x191919192b082b08,
    0x1919192b082b0819, 0x1919192b192b2b08, 0x1919192b2b2b0819, 0x19192b0808080808,
    0x19192b0808191908, 0x19192b0819080819, 0x19192b0819190808, 0x19192b082b192b19,
    0x19192b1908192b2b, 0x19192b1919080808, 0x19192b191908082b, 0x19192b2b2b081919,
    0x192b080808080819, 0x192b080808081908, 0x192b080808190808, 0x192b080819080808,
    0x192b080819191908, 0x192b0808192b082b, 0x192b08082b08192b, 0x192b08082b2b2b19,
    0x192b081908080808, 0x192b082b082b1908, 0x192b082b19082b2b, 0x192b082b2b19082b,
    0x192b190808080808, 0x192b19080819192b, 0x192b191908190808, 0x192b191919080808,
    0x192b191919081919, 0x192b19192b2b1908, 0x192b2b0808080819, 0x192b2b08192b2b2b,
    0x192b2b19082b1919, 0x192b2b2b0808192b, 0x192b2b2b19191908, 0x192b2b2b192b082b,
    0x2b08080808080808, 0x2b0808080808082b, 0x2b08080808081919, 0x2b08080808082b08,
    0x2b08080808190819, 0x2b08080808191908, 0x2b080808082b0808, 0x2b080808082b2b2b,
    0x2b08080819080819, 0x2b08080819081908, 0x2b08080819190808, 0x2b0808082b080808,
    0x2b0808082b08082b, 0x2b0808082b2b2b08, 0x2b0808082b2b2b2b, 0x2b08081908080819,
    0x2b08081908081908, 0x2b0808190808192b, 0x2b08081908190808, 0x2b08081919080808,
    0x2b08081919190819, 0x2b08081919192b19, 0x2b08082b08080808, 0x2b08082b082b0808,
    0x2b08082b2b080808, 0x2b08082b2b08082b, 0x2b08082b2b2b0808, 0x2b08082b2b2b2b08,
    0x2b08190808080819, 0x2b08190808081908, 0x2b08190808190808, 0x2b0819080819082b,
    0x2b08190808191919, 0x2b08190819080808, 0x2b081908192b0808, 0x2b0819082b082b19,
    0x2b08191908080808, 0x2b08191919081908, 0x2b0819192b2b1919, 0x2b08192b08192b08,
    0x2b08192b192b2b2b, 0x2b082b0808080808, 0x2b082b0808082b08, 0x2b082b08082b1919,
    0x2b082b0819192b2b, 0x2b082b082b080808, 0x2b082b082b08082b, 0x2b082b082b2b2b08,
    0x2b082b190808192b, 0x2b082b2b082b082b, 0x2b082b2b2b080808, 0x2b082b2b2b082b08,
    0x2b082b2b2b19192b, 0x2b082b2b2b2b2b08, 0x2b19080808080819, 0x2b19080808081908,
    0x2b19080808190808, 0x2b19080819080808, 0x2b1908081919192b, 0x2b1908082b081908,
    0x2b19081908080808, 0x2b190819082b082b, 0x2b190819192b1908, 0x2b19082b1919192b,
    0x2b19082b2b082b19, 0x2b19190808080808, 0x2b19190808081919, 0x2b19190819081908,
    0x2b19190819190808, 0x2b19190819192b08, 0x2b191919082b2b19, 0x2b1919192b190808,
    0x2b1919192b19082b, 0x2b19192b19080819, 0x2b192b0819190819, 0x2b192b082b2b192b,
    0x2b192b1919082b19, 0x2b192b2b08191919, 0x2b192b2b192b0808, 0x2b2b080808080808,
    0x2b2b08080808082b, 0x2b2b080808082b08, 0x2b2b080808082b2b, 0x2b2b0808082b0808,
    0x2b2b0808082b2b2b, 0x2b2b08082b2b0808, 0x2b2b081919190819, 0x2b2b081919192b19,
    0x2b2b08192b2b192b, 0x2b2b082b08080808, 0x2b2b082b0808082b, 0x2b2b082b08082b08,
    0x2b2b082b082b2b2b, 0x2b2b082b2b080808, 0x2b2b082b2b2b0808, 0x2b2b190819080808,
    0x2b2b19082b191919, 0x2b2b192b192b1919, 0x2b2b192b2b192b08, 0x2b2b2b0808082b2b,
    0x2b2b2b08082b0808, 0x2b2b2b08082b082b, 0x2b2b2b08082b2b08, 0x2b2b2b082b2b0808,
    0x2b2b2b082b2b2b08, 0x2b2b2b1908081908, 0x2b2b2b192b081908, 0x2b2b2b192b08192b,
    0x2b2b2b2b082b2b08, 0x2b2b2b2b082b2b2b, 0x2b2b2b2b2b190819, 0x2b2b2b2b2b2b2b2b,
};

/* ============================================================================
 * Quantization helper tables (built at runtime)
 * ============================================================================ */

static uint64_t *kgrid_q2xs = NULL;
static int      *kmap_q2xs = NULL;
static uint16_t *kneighbors_q2xs = NULL;
static int       iq2_xs_initialized = 0;

#define KMAP_SIZE 43692

static int iq2_compare_func(const void *a, const void *b) {
    const int *l = (const int *)a;
    const int *r = (const int *)b;
    return l[0] < r[0] ? -1 : l[0] > r[0] ? 1 : l[1] < r[1] ? -1 : l[1] > r[1] ? 1 : 0;
}

void iq2_xs_init(void) {
    if (iq2_xs_initialized) return;
    
    const int grid_size = 512;
    const int nwant = 2;
    
    kgrid_q2xs = (uint64_t *)malloc(grid_size * sizeof(uint64_t));
    if (!kgrid_q2xs) return;
    
    // for (int k = 0; k < grid_size; ++k) {
    //     kgrid_q2xs[k] = iq2xs_grid[k];
    // }
    for (int k = 0; k < grid_size; ++k) {
        uint64_t packed = iq2xs_grid[k];
        uint64_t normalized = 0;
        
        for (int i = 0; i < 8; ++i) {
            // Extract the byte (e.g., 0x08, 0x19, 0x2b...)
            uint8_t val = (packed >> (i * 8)) & 0xFF;
            uint8_t q_val;

            // Map dequant values back to normalized grid coordinates (1, 3, 5, 7)
            // Values in table are approx: 8, 25, 43, 60
            if      (val < 15) q_val = 1;
            else if (val < 35) q_val = 3;
            else if (val < 55) q_val = 5;
            else               q_val = 7;

            normalized |= ((uint64_t)q_val << (i * 8));
        }
        kgrid_q2xs[k] = normalized;
    }
    
    kmap_q2xs = (int *)malloc(KMAP_SIZE * sizeof(int));
    if (!kmap_q2xs) {
        free(kgrid_q2xs); kgrid_q2xs = NULL;
        return;
    }
    
    for (int i = 0; i < KMAP_SIZE; ++i) kmap_q2xs[i] = -1;
    
    for (int i = 0; i < grid_size; ++i) {
        const uint8_t *aux8 = (const uint8_t *)&kgrid_q2xs[i];
        uint16_t index = 0;
        for (int k = 0; k < 8; ++k) {
            uint16_t q = (aux8[k] - 1) / 2;
            index |= (q << (2 * k));
        }
        kmap_q2xs[index] = i;
    }
    
    int8_t pos[8];
    int *dist2 = (int *)malloc(2 * grid_size * sizeof(int));
    if (!dist2) {
        free(kgrid_q2xs); kgrid_q2xs = NULL;
        free(kmap_q2xs);  kmap_q2xs = NULL;
        return;
    }
    
    int num_neighbors = 0, num_not_in_map = 0;
    
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2xs[i] >= 0) continue;
        ++num_not_in_map;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2xs + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        int n = 0, d2_prev = dist2[0], nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            ++n;
        }
        num_neighbors += n;
    }
    
    kneighbors_q2xs = (uint16_t *)malloc((num_neighbors + num_not_in_map) * sizeof(uint16_t));
    if (!kneighbors_q2xs) {
        free(kgrid_q2xs); kgrid_q2xs = NULL;
        free(kmap_q2xs);  kmap_q2xs = NULL;
        free(dist2);
        return;
    }
    
    int counter = 0;
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2xs[i] >= 0) continue;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2xs + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        kmap_q2xs[i] = -(counter + 1);
        
        int d2_prev = dist2[0];
        uint16_t *start = &kneighbors_q2xs[counter++];
        int n = 0, nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            kneighbors_q2xs[counter++] = dist2[2*j+1];
            ++n;
        }
        *start = n;
    }
    
    free(dist2);
    iq2_xs_initialized = 1;
}

void iq2_xs_free_tables(void) {
    if (kgrid_q2xs) { free(kgrid_q2xs); kgrid_q2xs = NULL; }
    if (kmap_q2xs)  { free(kmap_q2xs);  kmap_q2xs = NULL; }
    if (kneighbors_q2xs) { free(kneighbors_q2xs); kneighbors_q2xs = NULL; }
    iq2_xs_initialized = 0;
}

/* ============================================================================
 * Array allocation and management
 * ============================================================================ */

static int64_t _get_iq2_xs_array_size(const iq2_xs_array_t *arr) {
    if (!arr) return 0;
    /* Header + d (2 bytes) + qs (64 bytes) + scales (8 bytes) per super block */
    return (int64_t)(sizeof(iq2_xs_array_t) 
                   + arr->num_super_blocks * sizeof(uint16_t)      /* d */
                   + arr->num_super_blocks * 32 * sizeof(uint16_t) /* qs */
                   + arr->num_super_blocks * 8);                   /* scales */
}

iq2_xs_array_t *allocate_iq2_xs_array(uint64_t num_elements) {
    if (!num_elements) return NULL;
    
    uint64_t num_super_blocks = (num_elements + IQ2_XS_SUPER_BLOCK_SIZE - 1) / IQ2_XS_SUPER_BLOCK_SIZE;
    
    size_t total = sizeof(iq2_xs_array_t)
                 + num_super_blocks * sizeof(uint16_t)      /* d */
                 + num_super_blocks * 32 * sizeof(uint16_t) /* qs */
                 + num_super_blocks * 8;                    /* scales */
    
    iq2_xs_array_t *arr = (iq2_xs_array_t *)calloc(1, total);
    if (!arr) return NULL;
    
    arr->num_elements = num_elements;
    arr->num_super_blocks = num_super_blocks;
    arr->d = (uint16_t *)(arr + 1);
    arr->qs = (uint16_t *)(arr->d + num_super_blocks);
    arr->scales = (uint8_t *)(arr->qs + num_super_blocks * 32);
    
    return arr;
}

void free_iq2_xs_array(iq2_xs_array_t *arr) {
    if (arr) free(arr);
}

int64_t get_iq2_xs_array_size(const iq2_xs_array_t *arr) {
    return _get_iq2_xs_array_size(arr);
}

iq2_xs_array_t *load_iq2_xs_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(iq2_xs_array_t)) return NULL;
    
    iq2_xs_array_t *arr = (iq2_xs_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;
    
    memcpy(arr, buffer, buffer_size);
    
    const int64_t expected = _get_iq2_xs_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }
    
    arr->d = (uint16_t *)(arr + 1);
    arr->qs = (uint16_t *)(arr->d + arr->num_super_blocks);
    arr->scales = (uint8_t *)(arr->qs + arr->num_super_blocks * 32);
    
    return arr;
}

/* ============================================================================
 * Dequantization
 * ============================================================================ */

int iq2_xs_decompress(const iq2_xs_array_t *arr, float *float_array) {
    if (!arr || !float_array) return 1;
    
    const uint64_t num_super_blocks = arr->num_super_blocks;
    const uint64_t num_elements = arr->num_elements;
    
    uint64_t out_idx = 0;
    
    for (uint64_t sb = 0; sb < num_super_blocks; ++sb) {
        const float d = fp16_ieee_to_fp32_value(arr->d[sb]);
        const uint16_t *qs_block = arr->qs + sb * 32;
        const uint8_t *scales_block = arr->scales + sb * 8;
        
        /* Process 8 groups of 32 values */
        for (int ib32 = 0; ib32 < 8; ++ib32) {
            /* Two 4-bit scales per group (for 16 values each) */
            float db[2];
            db[0] = d * (0.5f + (float)(scales_block[ib32] & 0xf)) * 0.25f;
            db[1] = d * (0.5f + (float)(scales_block[ib32] >> 4)) * 0.25f;
            
            /* Process 4 sub-groups of 8 values */
            for (int l = 0; l < 4; ++l) {
                uint16_t qs_val = qs_block[4 * ib32 + l];
                uint16_t grid_idx = qs_val & 511;  /* 9 bits */
                uint8_t sign_idx = qs_val >> 9;    /* 7 bits */
                
                const uint8_t *grid = (const uint8_t *)(iq2xs_grid + grid_idx);
                const uint8_t signs = ksigns_iq2xs[sign_idx];
                
                const float dl = db[l / 2];
                
                for (int j = 0; j < 8; ++j) {
                    if (out_idx < num_elements) {
                        float val = dl * (float)grid[j];
                        float_array[out_idx++] = (signs & kmask_iq2xs[j]) ? -val : val;
                    }
                }
            }
        }
    }
    
    return 0;
}

/* ============================================================================
 * Quantization helpers
 * ============================================================================ */

static inline int nearest_int(float f) {
    return (int)(f + 0.5f - (f < 0));
}

static int iq2_find_best_neighbour(const uint16_t *neighbours, const uint64_t *grid,
                                   const float *xval, const float *weight, 
                                   float scale, int8_t *L) {
    int num_neighbors = neighbours[0];
    if (num_neighbors <= 0) return -1;
    
    float best_d2 = FLT_MAX;
    int grid_index = -1;
    
    for (int j = 1; j <= num_neighbors; ++j) {
        const int8_t *pg = (const int8_t *)(grid + neighbours[j]);
        float d2 = 0;
        for (int i = 0; i < 8; ++i) {
            float q = (float)pg[i];
            float diff = scale * q - xval[i];
            d2 += weight[i] * diff * diff;
        }
        if (d2 < best_d2) {
            best_d2 = d2;
            grid_index = neighbours[j];
        }
    }
    
    if (grid_index >= 0) {
        const int8_t *pg = (const int8_t *)(grid + grid_index);
        for (int i = 0; i < 8; ++i) {
            L[i] = (pg[i] - 1) / 2;
        }
    }
    
    return grid_index;
}

/* ============================================================================
 * Quantization
 * ============================================================================ */

int iq2_xs_compress(const float *float_array, uint64_t num_elements, iq2_xs_array_t **out) {
    if (!float_array || num_elements == 0 || !out || *out) return 1;
    
    if (!iq2_xs_initialized) {
        iq2_xs_init();
        if (!iq2_xs_initialized) return 1;
    }
    
    iq2_xs_array_t *arr = allocate_iq2_xs_array(num_elements);
    if (!arr) return 1;
    
    const int kMaxQ = 3;
    const float GROUP_MAX_EPS = 1e-8f;
    
    float weight[16];
    float xval[16];
    float waux[16];
    int8_t L[16];
    int8_t Laux[16];
    uint8_t block_signs[2];
    uint16_t q2[32];
    float scales[16];  /* 16 sub-group scales per super block */
    
    for (uint64_t sb = 0; sb < arr->num_super_blocks; ++sb) {
        memset(q2, 0, sizeof(q2));
        
        uint64_t block_start = sb * IQ2_XS_SUPER_BLOCK_SIZE;
        uint64_t block_end = block_start + IQ2_XS_SUPER_BLOCK_SIZE;
        if (block_end > num_elements) block_end = num_elements;
        
        float sumx2 = 0;
        for (uint64_t i = block_start; i < block_end; ++i) {
            sumx2 += float_array[i] * float_array[i];
        }
        float sigma2 = sumx2 / (float)IQ2_XS_SUPER_BLOCK_SIZE;
        
        float max_scale = 0;
        
        /* Process 16 sub-groups of 16 values (8 groups × 2 halves) */
        for (int ib = 0; ib < 16; ++ib) {
            uint64_t group_start = block_start + ib * 16;
            
            for (int i = 0; i < 16; ++i) {
                uint64_t idx = group_start + i;
                float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                weight[i] = sqrtf(sigma2 + v * v);
                waux[i] = sqrtf(weight[i]);
            }
            
            /* Handle signs with parity constraint for 2 sub-groups of 8 */
            for (int k = 0; k < 2; ++k) {
                int nflip = 0;
                uint8_t s = 0;
                
                for (int i = 0; i < 8; ++i) {
                    uint64_t idx = group_start + 8 * k + i;
                    float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                    
                    if (v >= 0) {
                        xval[8*k + i] = v;
                    } else {
                        xval[8*k + i] = -v;
                        ++nflip;
                        s |= (1 << i);
                    }
                }
                
                if (nflip % 2) {
                    int imin = 0;
                    float min = weight[8*k] * xval[8*k] * xval[8*k];
                    for (int i = 1; i < 8; ++i) {
                        float ax = weight[8*k+i] * xval[8*k+i] * xval[8*k+i];
                        if (ax < min) { min = ax; imin = i; }
                    }
                    xval[8*k + imin] = -xval[8*k + imin];
                    s ^= (1 << imin);
                }
                block_signs[k] = s & 127;
            }
            
            float max = xval[0];
            for (int i = 1; i < 16; ++i) {
                if (xval[i] > max) max = xval[i];
            }
            
            if (max < GROUP_MAX_EPS) {
                scales[ib] = 0;
                memset(L, 0, 16);
            } else {
                float best = 0;
                float scale = max / (2 * kMaxQ - 1);
                int is_on_grid[2] = {1, 1};
                
                for (int is = -9; is <= 9; ++is) {
                    float id = (2 * kMaxQ - 1 + is * 0.1f) / max;
                    float this_scale = 1.0f / id;
                    int is_on_grid_aux[2] = {1, 1};
                    
                    for (int k = 0; k < 2; ++k) {
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            Laux[8*k + i] = (int8_t)l;
                        }
                        
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            u |= (Laux[8*k+i] << (2*i));
                        }
                        
                        int grid_index = kmap_q2xs[u];
                        if (grid_index < 0) {
                            is_on_grid_aux[k] = 0;
                            const uint16_t *neighbours = kneighbors_q2xs - kmap_q2xs[u] - 1;
                            iq2_find_best_neighbour(neighbours, kgrid_q2xs, 
                                                   xval + 8*k, waux + 8*k, 
                                                   this_scale, Laux + 8*k);
                        }
                    }
                    
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 16; ++i) {
                        float w = weight[i];
                        float q = 2 * Laux[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    
                    if (sumq2 > 0 && sumqx * sumqx > best * sumq2) {
                        scale = sumqx / sumq2;
                        best = scale * sumqx;
                        memcpy(L, Laux, 16);
                        is_on_grid[0] = is_on_grid_aux[0];
                        is_on_grid[1] = is_on_grid_aux[1];
                    }
                }
                
                /* Refinement for off-grid points */
                int n_not_ongrid = (is_on_grid[0] ? 0 : 1) + (is_on_grid[1] ? 0 : 1);
                if (n_not_ongrid > 0 && scale > 0) {
                    float id = 1.0f / scale;
                    for (int k = 0; k < 2; ++k) {
                        if (is_on_grid[k]) continue;
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            u |= (l << (2*i));
                            L[8*k + i] = l;
                        }
                        int grid_index = kmap_q2xs[u];
                        if (grid_index < 0) {
                            const uint16_t *neighbours = kneighbors_q2xs - kmap_q2xs[u] - 1;
                            iq2_find_best_neighbour(neighbours, kgrid_q2xs, 
                                                   xval + 8*k, waux + 8*k, 
                                                   scale, L + 8*k);
                        }
                    }
                    
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 16; ++i) {
                        float w = weight[i];
                        float q = 2 * L[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    if (sumq2 > 0) scale = sumqx / sumq2;
                }
                
                if (scale < 0) {
                    scale = -scale;
                    for (int k = 0; k < 2; ++k) {
                        block_signs[k] = (~block_signs[k]) & 127;
                    }
                }
                
                scales[ib] = scale;
                if (scale > max_scale) max_scale = scale;
            }
            
            /* Pack into q2: grid index (9 bits) | sign pattern (7 bits) */
            for (int k = 0; k < 2; ++k) {
                uint16_t u = 0;
                for (int i = 0; i < 8; ++i) {
                    u |= (L[8*k+i] << (2*i));
                }
                int grid_index = kmap_q2xs[u];
                if (grid_index < 0) grid_index = 0;
                
                q2[2 * ib + k] = (uint16_t)grid_index | ((uint16_t)block_signs[k] << 9);
            }
        }
        
        /* Encode block scale */
        if (max_scale == 0) {
            arr->d[sb] = 0;
            memset(arr->qs + sb * 32, 0, 64);
            memset(arr->scales + sb * 8, 0, 8);
        } else {
            float d = max_scale / 31.0f;
            arr->d[sb] = fp16_ieee_from_fp32_value(d);
            float id = 1.0f / d;
            
            /* Encode group scales: 2 × 4-bit scales per byte */
            for (int ib32 = 0; ib32 < 8; ++ib32) {
                int l0 = nearest_int(0.5f * (id * scales[2*ib32 + 0] - 1));
                int l1 = nearest_int(0.5f * (id * scales[2*ib32 + 1] - 1));
                if (l0 < 0) l0 = 0; if (l0 > 15) l0 = 15;
                if (l1 < 0) l1 = 0; if (l1 > 15) l1 = 15;
                arr->scales[sb * 8 + ib32] = (uint8_t)(l0 | (l1 << 4));
            }
            
            memcpy(arr->qs + sb * 32, q2, 64);
        }
    }
    
    *out = arr;
    return 0;
}



================================================
FILE: src/int_quantization/iq2_xxs_impl.c
================================================
#include "int_quantization/iq2_xxs_impl.h"

/* ============================================================================
 * Lookup Tables
 * ============================================================================ */

/* Sign mask for each of 8 positions */
static const uint8_t kmask_iq2xs[8] = {1, 2, 4, 8, 16, 32, 64, 128};

/* 7-bit sign index -> 8-bit sign pattern (with even parity) */
static const uint8_t ksigns_iq2xs[128] = {
      0, 129, 130,   3, 132,   5,   6, 135, 136,   9,  10, 139,  12, 141, 142,  15,
    144,  17,  18, 147,  20, 149, 150,  23,  24, 153, 154,  27, 156,  29,  30, 159,
    160,  33,  34, 163,  36, 165, 166,  39,  40, 169, 170,  43, 172,  45,  46, 175,
     48, 177, 178,  51, 180,  53,  54, 183, 184,  57,  58, 187,  60, 189, 190,  63,
    192,  65,  66, 195,  68, 197, 198,  71,  72, 201, 202,  75, 204,  77,  78, 207,
     80, 209, 210,  83, 212,  85,  86, 215, 216,  89,  90, 219,  92, 221, 222,  95,
     96, 225, 226,  99, 228, 101, 102, 231, 232, 105, 106, 235, 108, 237, 238, 111,
    240, 113, 114, 243, 116, 245, 246, 119, 120, 249, 250, 123, 252, 125, 126, 255,
};

/* 256-entry grid: each uint64_t contains 8 dequantized values (odd: 1,3,5,7)
 * PLACEHOLDER - copy from ggml-common.h iq2xxs_grid table */
static const uint64_t iq2xxs_grid[256] = {
    0x0808080808080808, 0x080808080808082b, 0x0808080808081919, 0x0808080808082b08,
    0x0808080808082b2b, 0x0808080808190819, 0x0808080808191908, 0x08080808082b0808,
    0x08080808082b082b, 0x08080808082b2b08, 0x08080808082b2b2b, 0x0808080819080819,
    0x0808080819081908, 0x0808080819190808, 0x0808080819192b08, 0x08080808192b0819,
    0x08080808192b1908, 0x080808082b080808, 0x080808082b08082b, 0x080808082b082b2b,
    0x080808082b2b082b, 0x0808081908080819, 0x0808081908081908, 0x0808081908190808,
    0x0808081908191919, 0x0808081919080808, 0x080808192b081908, 0x080808192b192b08,
    0x0808082b08080808, 0x0808082b0808082b, 0x0808082b082b082b, 0x0808082b2b08082b,
    0x0808190808080819, 0x0808190808081908, 0x0808190808190808, 0x08081908082b0819,
    0x08081908082b1908, 0x0808190819080808, 0x080819081908082b, 0x0808190819082b08,
    0x08081908192b0808, 0x080819082b080819, 0x080819082b081908, 0x080819082b190808,
    0x080819082b2b1908, 0x0808191908080808, 0x080819190808082b, 0x0808191908082b08,
    0x08081919082b0808, 0x080819191908192b, 0x08081919192b2b19, 0x080819192b080808,
    0x080819192b190819, 0x0808192b08082b19, 0x0808192b08190808, 0x0808192b19080808,
    0x0808192b2b081908, 0x0808192b2b2b1908, 0x08082b0808080808, 0x08082b0808081919,
    0x08082b0808082b08, 0x08082b0808191908, 0x08082b08082b2b08, 0x08082b0819080819,
    0x08082b0819081908, 0x08082b0819190808, 0x08082b081919082b, 0x08082b082b082b08,
    0x08082b1908081908, 0x08082b1919080808, 0x08082b2b0808082b, 0x08082b2b08191908,
    0x0819080808080819, 0x0819080808081908, 0x0819080808190808, 0x08190808082b0819,
    0x0819080819080808, 0x08190808192b0808, 0x081908082b081908, 0x081908082b190808,
    0x081908082b191919, 0x0819081908080808, 0x0819081908082b08, 0x08190819082b0808,
    0x0819081919190808, 0x0819081919192b2b, 0x081908192b080808, 0x0819082b082b1908,
    0x0819082b19081919, 0x0819190808080808, 0x0819190808082b08, 0x08191908082b0808,
    0x08191908082b1919, 0x0819190819082b19, 0x081919082b080808, 0x0819191908192b08,
    0x08191919192b082b, 0x0819192b08080808, 0x0819192b0819192b, 0x08192b0808080819,
    0x08192b0808081908, 0x08192b0808190808, 0x08192b0819080808, 0x08192b082b080819,
    0x08192b1908080808, 0x08192b1908081919, 0x08192b192b2b0808, 0x08192b2b19190819,
    0x082b080808080808, 0x082b08080808082b, 0x082b080808082b2b, 0x082b080819081908,
    0x082b0808192b0819, 0x082b08082b080808, 0x082b08082b08082b, 0x082b0819082b2b19,
    0x082b081919082b08, 0x082b082b08080808, 0x082b082b0808082b, 0x082b190808080819,
    0x082b190808081908, 0x082b190808190808, 0x082b190819080808, 0x082b19081919192b,
    0x082b191908080808, 0x082b191919080819, 0x082b1919192b1908, 0x082b192b2b190808,
    0x082b2b0808082b08, 0x082b2b08082b0808, 0x082b2b082b191908, 0x082b2b2b19081908,
    0x1908080808080819, 0x1908080808081908, 0x1908080808190808, 0x1908080808192b08,
    0x19080808082b0819, 0x19080808082b1908, 0x1908080819080808, 0x1908080819082b08,
    0x190808081919192b, 0x19080808192b0808, 0x190808082b080819, 0x190808082b081908,
    0x190808082b190808, 0x1908081908080808, 0x19080819082b0808, 0x19080819192b0819,
    0x190808192b080808, 0x190808192b081919, 0x1908082b08080819, 0x1908082b08190808,
    0x1908082b19082b08, 0x1908082b1919192b, 0x1908082b192b2b08, 0x1908190808080808,
    0x1908190808082b08, 0x19081908082b0808, 0x190819082b080808, 0x190819082b192b19,
    0x190819190819082b, 0x19081919082b1908, 0x1908192b08080808, 0x19082b0808080819,
    0x19082b0808081908, 0x19082b0808190808, 0x19082b0819080808, 0x19082b0819081919,
    0x19082b1908080808, 0x19082b1919192b08, 0x19082b19192b0819, 0x19082b192b08082b,
    0x19082b2b19081919, 0x19082b2b2b190808, 0x1919080808080808, 0x1919080808082b08,
    0x1919080808190819, 0x1919080808192b19, 0x19190808082b0808, 0x191908082b080808,
    0x191908082b082b08, 0x1919081908081908, 0x191908191908082b, 0x191908192b2b1908,
    0x1919082b2b190819, 0x191919082b190808, 0x191919082b19082b, 0x1919191908082b2b,
    0x1919192b08080819, 0x1919192b19191908, 0x19192b0808080808, 0x19192b0808190819,
    0x19192b0808192b19, 0x19192b08192b1908, 0x19192b1919080808, 0x19192b2b08082b08,
    0x192b080808081908, 0x192b080808190808, 0x192b080819080808, 0x192b0808192b2b08,
    0x192b081908080808, 0x192b081919191919, 0x192b082b08192b08, 0x192b082b192b0808,
    0x192b190808080808, 0x192b190808081919, 0x192b191908190808, 0x192b19190819082b,
    0x192b19192b081908, 0x192b2b081908082b, 0x2b08080808080808, 0x2b0808080808082b,
    0x2b08080808082b2b, 0x2b08080819080819, 0x2b0808082b08082b, 0x2b08081908081908,
    0x2b08081908192b08, 0x2b08081919080808, 0x2b08082b08190819, 0x2b08190808080819,
    0x2b08190808081908, 0x2b08190808190808, 0x2b08190808191919, 0x2b08190819080808,
    0x2b081908192b0808, 0x2b08191908080808, 0x2b0819191908192b, 0x2b0819192b191908,
    0x2b08192b08082b19, 0x2b08192b19080808, 0x2b08192b192b0808, 0x2b082b080808082b,
    0x2b082b1908081908, 0x2b082b2b08190819, 0x2b19080808081908, 0x2b19080808190808,
    0x2b190808082b1908, 0x2b19080819080808, 0x2b1908082b2b0819, 0x2b1908190819192b,
    0x2b1908192b080808, 0x2b19082b19081919, 0x2b19190808080808, 0x2b191908082b082b,
    0x2b19190819081908, 0x2b19191919190819, 0x2b192b082b080819, 0x2b192b19082b0808,
    0x2b2b08080808082b, 0x2b2b080819190808, 0x2b2b08082b081919, 0x2b2b081908082b19,
    0x2b2b082b08080808, 0x2b2b190808192b08, 0x2b2b2b0819190808, 0x2b2b2b1908081908,
};

/* ============================================================================
 * Quantization helper tables (built at runtime)
 * ============================================================================ */

static uint64_t *kgrid_q2xs = NULL;      /* Decoded grid values */
static int      *kmap_q2xs = NULL;       /* Maps 16-bit pattern -> grid index (or negative for neighbor lookup) */
static uint16_t *kneighbors_q2xs = NULL; /* Neighbor lists for off-grid points */
static int       iq2_xxs_initialized = 0;

#define KMAP_SIZE 43692  /* 4^8 rounded up for lookup + some slack */

static int iq2_compare_func(const void *a, const void *b) {
    const int *l = (const int *)a;
    const int *r = (const int *)b;
    return l[0] < r[0] ? -1 : l[0] > r[0] ? 1 : l[1] < r[1] ? -1 : l[1] > r[1] ? 1 : 0;
}

void iq2_xxs_init(void) {
    if (iq2_xxs_initialized) return;
    
    const int grid_size = 256;
    const int nwant = 2;  /* Number of neighbor distance levels to keep */
    
    /* Build decoded grid */
    kgrid_q2xs = (uint64_t *)malloc(grid_size * sizeof(uint64_t));
    if (!kgrid_q2xs) return;
    
    // for (int k = 0; k < grid_size; ++k) {
    //     kgrid_q2xs[k] = iq2xxs_grid[k];
    // }
    for (int k = 0; k < grid_size; ++k) {
        uint64_t packed = iq2xxs_grid[k];
        uint64_t normalized = 0;
        
        for (int i = 0; i < 8; ++i) {
            // Extract the byte (e.g., 0x08, 0x19, 0x2b...)
            uint8_t val = (packed >> (i * 8)) & 0xFF;
            uint8_t q_val;

            // Map dequant values back to normalized grid coordinates (1, 3, 5, 7)
            // Values in table are approx: 8, 25, 43, 60
            if      (val < 15) q_val = 1;
            else if (val < 35) q_val = 3;
            else if (val < 55) q_val = 5;
            else               q_val = 7;

            normalized |= ((uint64_t)q_val << (i * 8));
        }
        kgrid_q2xs[k] = normalized;
    }
    
    /* Build map from 16-bit patterns to grid indices */
    kmap_q2xs = (int *)malloc(KMAP_SIZE * sizeof(int));
    if (!kmap_q2xs) {
        free(kgrid_q2xs);
        kgrid_q2xs = NULL;
        return;
    }
    
    for (int i = 0; i < KMAP_SIZE; ++i) kmap_q2xs[i] = -1;
    
    /* Populate direct mappings for grid points */
    for (int i = 0; i < grid_size; ++i) {
        const uint8_t *aux8 = (const uint8_t *)&kgrid_q2xs[i];
        uint16_t index = 0;
        for (int k = 0; k < 8; ++k) {
            uint16_t q = (aux8[k] - 1) / 2;  /* Map {1,3,5,7} back to {0,1,2,3} */
            index |= (q << (2 * k));
        }
        kmap_q2xs[index] = i;
    }
    
    /* Build neighbor lists for off-grid points */
    int8_t pos[8];
    int *dist2 = (int *)malloc(2 * grid_size * sizeof(int));
    if (!dist2) {
        free(kgrid_q2xs); kgrid_q2xs = NULL;
        free(kmap_q2xs);  kmap_q2xs = NULL;
        return;
    }
    
    int num_neighbors = 0, num_not_in_map = 0;
    
    /* First pass: count neighbors needed */
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2xs[i] >= 0) continue;
        ++num_not_in_map;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2xs + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        int n = 0, d2_prev = dist2[0], nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            ++n;
        }
        num_neighbors += n;
    }
    
    /* Allocate neighbor storage */
    kneighbors_q2xs = (uint16_t *)malloc((num_neighbors + num_not_in_map) * sizeof(uint16_t));
    if (!kneighbors_q2xs) {
        free(kgrid_q2xs); kgrid_q2xs = NULL;
        free(kmap_q2xs);  kmap_q2xs = NULL;
        free(dist2);
        return;
    }
    
    /* Second pass: populate neighbor lists */
    int counter = 0;
    for (int i = 0; i < KMAP_SIZE; ++i) {
        if (kmap_q2xs[i] >= 0) continue;
        
        for (int k = 0; k < 8; ++k) {
            int l = (i >> (2 * k)) & 0x3;
            pos[k] = 2 * l + 1;
        }
        
        for (int j = 0; j < grid_size; ++j) {
            const int8_t *pg = (const int8_t *)(kgrid_q2xs + j);
            int d2 = 0;
            for (int k = 0; k < 8; ++k) {
                d2 += (pg[k] - pos[k]) * (pg[k] - pos[k]);
            }
            dist2[2*j+0] = d2;
            dist2[2*j+1] = j;
        }
        qsort(dist2, grid_size, 2 * sizeof(int), iq2_compare_func);
        
        kmap_q2xs[i] = -(counter + 1);  /* Negative = offset into neighbor list */
        
        int d2_prev = dist2[0];
        uint16_t *start = &kneighbors_q2xs[counter++];
        int n = 0, nhave = 1;
        for (int j = 0; j < grid_size; ++j) {
            if (dist2[2*j] > d2_prev) {
                if (nhave == nwant) break;
                d2_prev = dist2[2*j];
                ++nhave;
            }
            kneighbors_q2xs[counter++] = dist2[2*j+1];
            ++n;
        }
        *start = n;  /* Store count at beginning of neighbor list */
    }
    
    free(dist2);
    iq2_xxs_initialized = 1;
}

void iq2_xxs_free_tables(void) {
    if (kgrid_q2xs) { free(kgrid_q2xs); kgrid_q2xs = NULL; }
    if (kmap_q2xs)  { free(kmap_q2xs);  kmap_q2xs = NULL; }
    if (kneighbors_q2xs) { free(kneighbors_q2xs); kneighbors_q2xs = NULL; }
    iq2_xxs_initialized = 0;
}

/* ============================================================================
 * Array allocation and management
 * ============================================================================ */

static int64_t _get_iq2_xxs_array_size(const iq2_xxs_array_t *arr) {
    if (!arr) return 0;
    /* Header + scales (2 bytes each) + qs (64 bytes per super block) */
    return (int64_t)(sizeof(iq2_xxs_array_t) 
                   + arr->num_super_blocks * sizeof(uint16_t)
                   + arr->num_super_blocks * 64);
}

iq2_xxs_array_t *allocate_iq2_xxs_array(uint64_t num_elements) {
    if (!num_elements) return NULL;
    
    uint64_t num_super_blocks = (num_elements + IQ2_XXS_SUPER_BLOCK_SIZE - 1) / IQ2_XXS_SUPER_BLOCK_SIZE;
    
    size_t total = sizeof(iq2_xxs_array_t)
                 + num_super_blocks * sizeof(uint16_t)   /* scales */
                 + num_super_blocks * 64;                /* qs data */
    
    iq2_xxs_array_t *arr = (iq2_xxs_array_t *)calloc(1, total);
    if (!arr) return NULL;
    
    arr->num_elements = num_elements;
    arr->num_super_blocks = num_super_blocks;
    arr->scales = (uint16_t *)(arr + 1);
    arr->qs = (uint8_t *)(arr->scales + num_super_blocks);
    
    return arr;
}

void free_iq2_xxs_array(iq2_xxs_array_t *arr) {
    if (arr) free(arr);
}

int64_t get_iq2_xxs_array_size(const iq2_xxs_array_t *arr) {
    return _get_iq2_xxs_array_size(arr);
}

iq2_xxs_array_t *load_iq2_xxs_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(iq2_xxs_array_t)) return NULL;
    
    iq2_xxs_array_t *arr = (iq2_xxs_array_t *)calloc(1, buffer_size);
    if (!arr) return NULL;
    
    memcpy(arr, buffer, buffer_size);
    
    const int64_t expected = _get_iq2_xxs_array_size(arr);
    if (expected == 0 || buffer_size < expected) {
        free(arr);
        return NULL;
    }
    
    arr->scales = (uint16_t *)(arr + 1);
    arr->qs = (uint8_t *)(arr->scales + arr->num_super_blocks);
    
    return arr;
}

/* ============================================================================
 * Dequantization (the simpler direction)
 * ============================================================================ */

int iq2_xxs_decompress(const iq2_xxs_array_t *arr, float *float_array) {
    if (!arr || !float_array) return 1;
    
    const uint64_t num_super_blocks = arr->num_super_blocks;
    const uint64_t num_elements = arr->num_elements;
    
    uint64_t out_idx = 0;
    
    for (uint64_t sb = 0; sb < num_super_blocks; ++sb) {
        const float d = fp16_ieee_to_fp32_value(arr->scales[sb]);
        const uint8_t *qs_block = arr->qs + sb * 64;
        
        /* Process 8 groups of 32 values each */
        for (int ib32 = 0; ib32 < 8; ++ib32) {
            uint32_t aux32[2];
            memcpy(aux32, qs_block + ib32 * 8, 8);
            
            const uint8_t *aux8 = (const uint8_t *)aux32;
            
            /* Group scale: upper 4 bits of aux32[1] give value 0-15 */
            const float db = d * (0.5f + (float)(aux32[1] >> 28)) * 0.25f;
            
            /* Process 4 sub-groups of 8 values each */
            for (int l = 0; l < 4; ++l) {
                const uint8_t grid_idx = aux8[l];
                const uint8_t *grid = (const uint8_t *)(iq2xxs_grid + grid_idx);
                const uint8_t signs = ksigns_iq2xs[(aux32[1] >> (7 * l)) & 127];
                
                for (int j = 0; j < 8; ++j) {
                    if (out_idx < num_elements) {
                        float val = db * (float)grid[j];
                        float_array[out_idx++] = (signs & kmask_iq2xs[j]) ? -val : val;
                    }
                }
            }
        }
    }
    
    return 0;
}

/* ============================================================================
 * Quantization helpers
 * ============================================================================ */

static inline int nearest_int(float f) {
    return (int)(f + 0.5f - (f < 0));
}

/* Find best neighbor from neighbor list */
static int iq2_find_best_neighbour(const uint16_t *neighbours, const uint64_t *grid,
                                   const float *xval, const float *weight, 
                                   float scale, int8_t *L) {
    int num_neighbors = neighbours[0];
    if (num_neighbors <= 0) return -1;
    
    float best_d2 = FLT_MAX;
    int grid_index = -1;
    
    for (int j = 1; j <= num_neighbors; ++j) {
        const int8_t *pg = (const int8_t *)(grid + neighbours[j]);
        float d2 = 0;
        for (int i = 0; i < 8; ++i) {
            float q = (float)pg[i];
            float diff = scale * q - xval[i];
            d2 += weight[i] * diff * diff;
        }
        if (d2 < best_d2) {
            best_d2 = d2;
            grid_index = neighbours[j];
        }
    }
    
    if (grid_index >= 0) {
        const int8_t *pg = (const int8_t *)(grid + grid_index);
        for (int i = 0; i < 8; ++i) {
            L[i] = (pg[i] - 1) / 2;
        }
    }
    
    return grid_index;
}

/* ============================================================================
 * Quantization (the complex direction)
 * ============================================================================ */

int iq2_xxs_compress(const float *float_array, uint64_t num_elements, iq2_xxs_array_t **out) {
    if (!float_array || num_elements == 0 || !out || *out) return 1;
    
    /* Ensure tables are initialized */
    if (!iq2_xxs_initialized) {
        iq2_xxs_init();
        if (!iq2_xxs_initialized) return 1;
    }
    
    iq2_xxs_array_t *arr = allocate_iq2_xxs_array(num_elements);
    if (!arr) return 1;
    
    const int kMaxQ = 3;  /* Max quantization level (0-3 maps to 1,3,5,7) */
    const float GROUP_MAX_EPS = 1e-8f;
    
    float weight[32];
    float xval[32];
    float waux[32];
    int8_t L[32];
    int8_t Laux[32];
    uint8_t block_signs[4];
    uint32_t q2[16];  /* 2 uint32 per group × 8 groups = 16 */
    float scales[8];
    
    // uint64_t in_idx = 0;
    
    for (uint64_t sb = 0; sb < arr->num_super_blocks; ++sb) {
        memset(q2, 0, sizeof(q2));
        
        /* Compute variance for importance weighting */
        float sumx2 = 0;
        uint64_t block_start = sb * IQ2_XXS_SUPER_BLOCK_SIZE;
        uint64_t block_end = block_start + IQ2_XXS_SUPER_BLOCK_SIZE;
        if (block_end > num_elements) block_end = num_elements;
        // uint64_t block_len = block_end - block_start;
        
        for (uint64_t i = block_start; i < block_end; ++i) {
            sumx2 += float_array[i] * float_array[i];
        }
        float sigma2 = sumx2 / (float)IQ2_XXS_SUPER_BLOCK_SIZE;
        
        float max_scale = 0;
        
        /* Process 8 groups of 32 values */
        for (int ib = 0; ib < 8; ++ib) {
            uint64_t group_start = block_start + ib * 32;
            uint64_t group_end = group_start + 32;
            if (group_end > num_elements) group_end = num_elements;
            
            /* Build weight and absolute values with sign handling */
            for (int i = 0; i < 32; ++i) {
                uint64_t idx = group_start + i;
                float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                weight[i] = sqrtf(sigma2 + v * v);
                waux[i] = sqrtf(weight[i]);
            }
            
            /* Handle signs with parity constraint */
            for (int k = 0; k < 4; ++k) {
                int nflip = 0;
                uint8_t s = 0;
                
                for (int i = 0; i < 8; ++i) {
                    uint64_t idx = group_start + 8 * k + i;
                    float v = (idx < num_elements) ? float_array[idx] : 0.0f;
                    
                    if (v >= 0) {
                        xval[8*k + i] = v;
                    } else {
                        xval[8*k + i] = -v;
                        ++nflip;
                        s |= (1 << i);
                    }
                }
                
                /* Enforce even parity by flipping least important sign */
                if (nflip % 2) {
                    int imin = 0;
                    float min = weight[8*k] * xval[8*k] * xval[8*k];
                    for (int i = 1; i < 8; ++i) {
                        float ax = weight[8*k+i] * xval[8*k+i] * xval[8*k+i];
                        if (ax < min) {
                            min = ax;
                            imin = i;
                        }
                    }
                    xval[8*k + imin] = -xval[8*k + imin];
                    s ^= (1 << imin);
                }
                block_signs[k] = s & 127;
            }
            
            /* Find max for initial scale estimate */
            float max = xval[0];
            for (int i = 1; i < 32; ++i) {
                if (xval[i] > max) max = xval[i];
            }
            
            if (max < GROUP_MAX_EPS) {
                scales[ib] = 0;
                memset(L, 0, 32);
            } else {
                /* Search for optimal scale */
                float best = 0;
                float scale = max / (2 * kMaxQ - 1);
                
                for (int is = -6; is <= 6; ++is) {
                    float id = (2 * kMaxQ - 1 + is * 0.1f) / max;
                    float this_scale = 1.0f / id;
                    
                    /* Quantize each sub-group */
                    for (int k = 0; k < 4; ++k) {
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            Laux[8*k + i] = (int8_t)l;
                        }
                        
                        /* Check if on grid, find neighbors if not */
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            u |= (Laux[8*k+i] << (2*i));
                        }
                        
                        int grid_index = kmap_q2xs[u];
                        if (grid_index < 0) {
                            const uint16_t *neighbours = kneighbors_q2xs - kmap_q2xs[u] - 1;
                            iq2_find_best_neighbour(neighbours, kgrid_q2xs, 
                                                   xval + 8*k, waux + 8*k, 
                                                   this_scale, Laux + 8*k);
                        }
                    }
                    
                    /* Compute weighted error and optimal scale */
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 32; ++i) {
                        float w = weight[i];
                        float q = 2 * Laux[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    
                    if (sumq2 > 0 && sumqx * sumqx > best * sumq2) {
                        scale = sumqx / sumq2;
                        best = scale * sumqx;
                        memcpy(L, Laux, 32);
                    }
                }
                
                /* Final refinement */
                if (scale > 0) {
                    float id = 1.0f / scale;
                    for (int k = 0; k < 4; ++k) {
                        uint16_t u = 0;
                        for (int i = 0; i < 8; ++i) {
                            int l = nearest_int(0.5f * (id * xval[8*k+i] - 1));
                            if (l < 0) l = 0;
                            if (l > kMaxQ - 1) l = kMaxQ - 1;
                            u |= (l << (2*i));
                        }
                        
                        int grid_index = kmap_q2xs[u];
                        if (grid_index < 0) {
                            const uint16_t *neighbours = kneighbors_q2xs - kmap_q2xs[u] - 1;
                            iq2_find_best_neighbour(neighbours, kgrid_q2xs, 
                                                   xval + 8*k, waux + 8*k, 
                                                   scale, L + 8*k);
                        } else {
                            const int8_t *pg = (const int8_t *)(kgrid_q2xs + grid_index);
                            for (int i = 0; i < 8; ++i) {
                                L[8*k+i] = (pg[i] - 1) / 2;
                            }
                        }
                    }
                    
                    /* Recompute optimal scale */
                    float sumqx = 0, sumq2 = 0;
                    for (int i = 0; i < 32; ++i) {
                        float w = weight[i];
                        float q = 2 * L[i] + 1;
                        sumqx += w * xval[i] * q;
                        sumq2 += w * q * q;
                    }
                    if (sumq2 > 0) scale = sumqx / sumq2;
                }
                
                /* Handle negative scale (shouldn't happen but just in case) */
                if (scale < 0) {
                    scale = -scale;
                    for (int k = 0; k < 4; ++k) {
                        block_signs[k] = (~block_signs[k]) & 127;
                    }
                }
                
                scales[ib] = scale;
                if (scale > max_scale) max_scale = scale;
            }
            
            /* Pack grid indices and signs into q2 */
            for (int k = 0; k < 4; ++k) {
                uint16_t u = 0;
                for (int i = 0; i < 8; ++i) {
                    u |= (L[8*k+i] << (2*i));
                }
                int grid_index = kmap_q2xs[u];
                if (grid_index < 0) {
                    /* This shouldn't happen after optimization, but handle gracefully */
                    grid_index = 0;
                }
                q2[2*ib + 0] |= ((uint32_t)grid_index << (8*k));
                q2[2*ib + 1] |= ((uint32_t)block_signs[k] << (7*k));
            }
        }
        
        /* Encode block scale */
        if (max_scale == 0) {
            arr->scales[sb] = 0;
            memset(arr->qs + sb * 64, 0, 64);
        } else {
            float d = max_scale / 31.0f;
            arr->scales[sb] = fp16_ieee_from_fp32_value(d);
            float id = 1.0f / d;
            
            /* Encode group scales into upper 4 bits */
            for (int ib = 0; ib < 8; ++ib) {
                int l = nearest_int(0.5f * (id * scales[ib] - 1));
                if (l < 0) l = 0;
                if (l > 15) l = 15;
                q2[2*ib + 1] |= ((uint32_t)l << 28);
            }
            
            memcpy(arr->qs + sb * 64, q2, 64);
        }
    }
    
    *out = arr;
    return 0;
}



================================================
FILE: src/int_quantization/q2_k_impl.c
================================================
#include "int_quantization/q2_k_impl.h"

#define MAX_VAL(a, b) ((a) > (b) ? (a) : (b))
#define MIN_VAL(a, b) ((a) < (b) ? (a) : (b))
/* The implementation is refer to https://github.com/ggml-org/llama.cpp/blob/master/ggml/src/ggml-quants.c#L622 */

q2_k_array_t *allocate_q2_k_array(uint64_t num_elements) {
    if (!num_elements) return NULL;

    uint64_t num_elements_aligned = (num_elements % WEIGHT_PER_SUPER_BLOCK == 0)
                                        ? num_elements
                                        : num_elements + (WEIGHT_PER_SUPER_BLOCK - (num_elements % WEIGHT_PER_SUPER_BLOCK));

    uint64_t num_super_blocks = num_elements_aligned / WEIGHT_PER_SUPER_BLOCK;
    
    size_t total = sizeof(q2_k_array_t) + num_super_blocks * sizeof(super_block_q2_k);
    q2_k_array_t *qa = (q2_k_array_t *)calloc(1, total);
    if (!qa) return NULL;
    
    qa->num_elements = num_elements;
    qa->num_elements_aligned = num_elements_aligned;
    qa->num_super_blocks = num_super_blocks;
    qa->super_blocks = (super_block_q2_k *)(qa + 1);

    return qa;
}

void free_q2_k_array(q2_k_array_t *q2_k_array) {
    if (!q2_k_array) return;
    free(q2_k_array);
}

int64_t get_q2_k_array_size(const q2_k_array_t *q2_k_array) {
    if (!q2_k_array) return 0;
    return sizeof(q2_k_array_t) + q2_k_array->num_super_blocks * sizeof(super_block_q2_k);
}

q2_k_array_t *load_q2_k_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(q2_k_array_t)) return NULL;

    q2_k_array_t *q2_k_array = (q2_k_array_t *)calloc(1, buffer_size);
    if (!q2_k_array) return NULL;
    
    memcpy(q2_k_array, buffer, buffer_size);
    const int64_t expected = get_q2_k_array_size(q2_k_array);
    if (buffer_size < expected) {
        free(q2_k_array);
        return NULL;
    }

    q2_k_array->super_blocks = (super_block_q2_k *)(q2_k_array + 1);
    return q2_k_array;
}

static void find_optimal_scale_and_min(const float *weights, float *scale, float *min_val) {
    const float q2_scale = 3.f;
    float local_min = INFINITY;
    float local_max = -INFINITY;
    
    for (int l = 0; l < Q2_K_BLOCK_SIZE; l++) {
        if (weights[l] < local_min) local_min = weights[l];
    }

    for (int l = 0; l < Q2_K_BLOCK_SIZE; l++) {
        float shifted = weights[l] - local_min;
        if (shifted > local_max) local_max = shifted;
    }

    *scale = local_max / q2_scale;
    *min_val = local_min;
}

int q2_k_compress(const float *float_array, uint64_t num_elements, q2_k_array_t **q2_k_array) {
    const float q4_scale = 15.f;
    
    uint8_t L[WEIGHT_PER_SUPER_BLOCK];
    float weights[Q2_K_BLOCK_SIZE];
    float mins[Q2_K_SUPER_BLOCK_SIZE];
    float scales[Q2_K_SUPER_BLOCK_SIZE];
    
    if (!float_array || num_elements == 0 || !q2_k_array || *q2_k_array) {
        return 1;
    }
    
    *q2_k_array = allocate_q2_k_array(num_elements);
    if (!*q2_k_array) {
        return 1;
    }
    q2_k_array_t *qa = *q2_k_array;

    float *float_array_aligned = (float *)calloc(qa->num_elements_aligned, sizeof(float));
    if (!float_array_aligned) {
        free_q2_k_array(qa);
        *q2_k_array = NULL;
        return 1;
    }
    memcpy(float_array_aligned, float_array, qa->num_elements * sizeof(float));

    for (uint32_t curr_super_block_index = 0; curr_super_block_index < qa->num_super_blocks; curr_super_block_index++) {
        super_block_q2_k *curr_super_block = &qa->super_blocks[curr_super_block_index];
        const float *sb_base = float_array_aligned + (uint64_t)curr_super_block_index * WEIGHT_PER_SUPER_BLOCK;
        
        float max_scale = -INFINITY;
        float max_abs_min = 0.f;

        for (int j = 0; j < Q2_K_SUPER_BLOCK_SIZE; j++) {
            memcpy(weights, sb_base + j * Q2_K_BLOCK_SIZE, Q2_K_BLOCK_SIZE * sizeof(float));
            find_optimal_scale_and_min(weights, &scales[j], &mins[j]);
            if (scales[j] > max_scale) {
                max_scale = scales[j];
            }
            if (fabsf(mins[j]) > max_abs_min) {
                max_abs_min = fabsf(mins[j]);
            }
        }

        if (max_scale > 0) {
            float iscale = q4_scale / max_scale;
            for (int j = 0; j < Q2_K_SUPER_BLOCK_SIZE; j++) {
                int l = (int)lrintf(iscale * scales[j]);
                curr_super_block->scales[j] = l;
            }
            curr_super_block->super_scale = fp16_ieee_from_fp32_value(max_scale / q4_scale);
        } else {
            memset(curr_super_block->scales, 0, sizeof(curr_super_block->scales));
            curr_super_block->super_scale = fp16_ieee_from_fp32_value(0.f);
        }

        if (max_abs_min > 0) {
            const float iscale = 7.f / max_abs_min;
            for (int j = 0; j < Q2_K_SUPER_BLOCK_SIZE; j++) {
                int l = (int)lrintf(iscale * mins[j]);
                l = MAX_VAL(-8, MIN_VAL(7, l));
                curr_super_block->scales[j] |= ((l & 0xF) << 4);
            }
            curr_super_block->super_min = fp16_ieee_from_fp32_value(max_abs_min / 7.f);
        } else {
            curr_super_block->super_min = fp16_ieee_from_fp32_value(0.f);
        }

        for (int j = 0; j < Q2_K_SUPER_BLOCK_SIZE; j++) {
            const float temp_scale = fp16_ieee_to_fp32_value(curr_super_block->super_scale) * (curr_super_block->scales[j] & 0xF);
            const float m = fp16_ieee_to_fp32_value(curr_super_block->super_min);
            const int8_t min_q = (curr_super_block->scales[j] >> 4);
            const float temp_min = m * ((int8_t)(min_q << 4) >> 4);
        
            for (int ii = 0; ii < Q2_K_BLOCK_SIZE; ii++) {
                float val = (temp_scale > 0.f) ? (sb_base[j * Q2_K_BLOCK_SIZE + ii] - temp_min) / temp_scale : 0.f;
                int l = (int)lrintf(val);
                l = MAX_VAL(0, MIN_VAL(3, l));
                L[j * Q2_K_BLOCK_SIZE + ii] = (uint8_t)l;
            }
        }

        uint32_t packed_run = WEIGHT_PER_SUPER_BLOCK / 2; // 128
        for (int j = 0; j < WEIGHT_PER_SUPER_BLOCK; j += packed_run) {
            for (int l = 0; l < Q2_K_BLOCK_SIZE * 2; l++) { // l = 0..31
                uint8_t b0 = L[j + l + 0];
                uint8_t b1 = L[j + l + 32];
                uint8_t b2 = L[j + l + 64];
                uint8_t b3 = L[j + l + 96];
                curr_super_block->data[j / 4 + l] = b0 | (b1 << 2) | (b2 << 4) | (b3 << 6);
            }
        }
    }

    free(float_array_aligned);
    return 0;
}

int q2_k_decompress(const q2_k_array_t *q2_k_array, float *float_array) {
    if (!q2_k_array || !float_array || q2_k_array->num_super_blocks == 0) {
        return 1;
    }

    const uint64_t total_elements = q2_k_array->num_elements;

    for (uint32_t s = 0; s < q2_k_array->num_super_blocks; ++s) {
        const super_block_q2_k *curr_super_block = &q2_k_array->super_blocks[s];
        const float super_scale = fp16_ieee_to_fp32_value(curr_super_block->super_scale);
        const float super_min   = fp16_ieee_to_fp32_value(curr_super_block->super_min);

        float scales[Q2_K_SUPER_BLOCK_SIZE];
        float mins[Q2_K_SUPER_BLOCK_SIZE];

        for (int i = 0; i < Q2_K_SUPER_BLOCK_SIZE; ++i) {
            uint8_t packed_val = curr_super_block->scales[i];
            scales[i] = super_scale * (packed_val & 0x0F);
            
            int8_t min_q = (packed_val >> 4);
            mins[i] = super_min * ((int8_t)(min_q << 4) >> 4);
        }

        const uint8_t *q = curr_super_block->data;
        const uint64_t base_idx = (uint64_t)s * WEIGHT_PER_SUPER_BLOCK;

        for (int l = 0; l < 32; ++l) {
            uint8_t packed_byte = q[l];
            
            uint64_t idx0 = base_idx + (uint64_t)l;
            uint64_t idx1 = base_idx + (uint64_t)l + 32;
            uint64_t idx2 = base_idx + (uint64_t)l + 64;
            uint64_t idx3 = base_idx + (uint64_t)l + 96;

            const int local0 = l;
            const int local1 = l + 32;
            const int local2 = l + 64;
            const int local3 = l + 96;

            if (idx0 < total_elements) float_array[idx0] = mins[local0/16] + scales[local0/16] * ((packed_byte >> 0) & 3);
            if (idx1 < total_elements) float_array[idx1] = mins[local1/16] + scales[local1/16] * ((packed_byte >> 2) & 3);
            if (idx2 < total_elements) float_array[idx2] = mins[local2/16] + scales[local2/16] * ((packed_byte >> 4) & 3);
            if (idx3 < total_elements) float_array[idx3] = mins[local3/16] + scales[local3/16] * ((packed_byte >> 6) & 3);
        }

        for (int l = 0; l < 32; ++l) {
            uint8_t packed_byte = q[32 + l];
            
            uint64_t idx0 = base_idx + 128 + (uint64_t)l;
            uint64_t idx1 = base_idx + 160 + (uint64_t)l;
            uint64_t idx2 = base_idx + 192 + (uint64_t)l;
            uint64_t idx3 = base_idx + 224 + (uint64_t)l;

            if (idx0 < total_elements) float_array[idx0] = mins[(idx0 - base_idx)/16] + scales[(idx0 - base_idx)/16] * ((packed_byte >> 0) & 3);
            if (idx1 < total_elements) float_array[idx1] = mins[(idx1 - base_idx)/16] + scales[(idx1 - base_idx)/16] * ((packed_byte >> 2) & 3);
            if (idx2 < total_elements) float_array[idx2] = mins[(idx2 - base_idx)/16] + scales[(idx2 - base_idx)/16] * ((packed_byte >> 4) & 3);
            if (idx3 < total_elements) float_array[idx3] = mins[(idx3 - base_idx)/16] + scales[(idx3 - base_idx)/16] * ((packed_byte >> 6) & 3);
        }
    }
    return 0;
}



================================================
FILE: src/int_quantization/q4_0_impl.c
================================================
#include "int_quantization/q4_0_impl.h"

static int64_t _get_q4_0_array_size(const q4_0_array_t *q4_0_array) {
    if (!q4_0_array) return 0;

    const uint64_t num_elements_for_data = (q4_0_array->num_elements + 1) / 2;
    return sizeof(q4_0_array_t)
         + q4_0_array->num_blocks * sizeof(float)
         + num_elements_for_data * sizeof(int8_t);
}

q4_0_array_t *allocate_q4_0_array(uint64_t num_elements,
                                  uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    uint64_t num_elements_for_data = (num_elements + 1) / 2;

    size_t total = sizeof(q4_0_array_t)
                 + num_blocks * sizeof(float)
                 + num_elements_for_data * sizeof(int8_t);

    q4_0_array_t *qa = (q4_0_array_t *)calloc(1, total);
    if (!qa) return NULL;

    qa->num_elements = num_elements;
    qa->num_blocks   = num_blocks;
    qa->block_size   = block_size;

    qa->scales = (float *)(qa + 1);
    qa->data   = (int8_t *)(qa->scales + num_blocks);
    return qa;
}

void free_q4_0_array(q4_0_array_t *q4_0_array) {
    if (!q4_0_array) return;
    free(q4_0_array);
}

int64_t get_q4_0_array_size(const q4_0_array_t *q4_0_array) {
    return _get_q4_0_array_size(q4_0_array);
}

q4_0_array_t *load_q4_0_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(q4_0_array_t)) return NULL;

    q4_0_array_t *q4_0_array = (q4_0_array_t *)calloc(1, buffer_size);
    if (!q4_0_array) return NULL;

    memcpy(q4_0_array, buffer, buffer_size);
    const int64_t expected = _get_q4_0_array_size(q4_0_array);
    if (buffer_size < expected) {
        free(q4_0_array);
        return NULL;
    }

    q4_0_array->scales = (float *)(q4_0_array + 1);
    q4_0_array->data   = (int8_t *)(q4_0_array->scales + q4_0_array->num_blocks);
    return q4_0_array;
}

static int _quantize_q4_0(const float *float_array, q4_0_array_t *q4_0_array) {
    if (!float_array || !q4_0_array) return 1;

    const uint64_t block_size   = q4_0_array->block_size;
    const uint64_t num_blocks   = q4_0_array->num_blocks;
    const uint64_t num_elements = q4_0_array->num_elements;
    uint8_t *data = (uint8_t *)q4_0_array->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = fabsf(float_array[start + i]);
            if (v > abs_max) abs_max = v;
        }

        float scale = (abs_max > 0.0f) ? (abs_max / 7.0f) : 0.0f;
        float inv_scale = (scale > 0.0f) ? (1.0f / scale) : 0.0f;
        q4_0_array->scales[b] = scale;

        for (uint64_t i = 0; i < remain; ++i) {
            float val = float_array[start + i] * inv_scale;
            long qi   = lrintf(val);
            if (qi < -7) qi = -7;
            if (qi >  7) qi =  7;

            const uint8_t four_bit_qi = ((uint8_t)qi) & 0x0F;
            const int data_index = (start + i) / 2;
            if (i % 2 == 0) {
                data[data_index] = (uint8_t)(four_bit_qi << 4);
            } else {
                data[data_index] = (uint8_t)(data[data_index] | four_bit_qi);
            }
        }
    }
    return 0;
}

int q4_0_compress(const float *float_array,
             uint64_t num_elements,
             uint8_t quantized_type,
             q4_0_array_t **q4_0_array) {
    if (!float_array || num_elements == 0 || !q4_0_array || *q4_0_array) return 1;
    /* Only q4_0 is supported at the moment. */
    if (quantized_type != 0) return 1;

    *q4_0_array = allocate_q4_0_array(num_elements, DEFAULT_Q4_0_BLOCK_SIZE);
    if (!*q4_0_array) return 1;

    return _quantize_q4_0(float_array, *q4_0_array);
}

int q4_0_decompress(const q4_0_array_t *q4_0_array,
               float *float_array) {
    if (!q4_0_array || !float_array) return 1;

    const uint64_t block_size   = q4_0_array->block_size;
    const uint64_t num_blocks   = q4_0_array->num_blocks;
    const uint64_t num_elements = q4_0_array->num_elements;
    const uint8_t *src_data = (const uint8_t *)q4_0_array->data;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);
        const float scale = q4_0_array->scales[b];

        for (uint64_t i = 0; i < remain; ++i) {
            const int data_index = (start + i) / 2;
            const uint8_t packed_qi = src_data[data_index];

            uint8_t qi = (i % 2 == 0) ? (packed_qi >> 4) : (packed_qi & 0x0F);
            const int8_t signed_qi = (int8_t)(qi << 4) >> 4;
            float_array[start + i] = scale * (float)(signed_qi);
        }
    }
    return 0;
}



================================================
FILE: src/int_quantization/q8_0_impl.c
================================================
#include "int_quantization/q8_0_impl.h"

static int64_t _get_q8_0_array_size(const q8_0_array_t *q8_0_array) {
    if (!q8_0_array) return 0;
    return sizeof(q8_0_array_t)
         + q8_0_array->num_blocks * sizeof(float)
         + q8_0_array->num_elements * sizeof(int8_t);
}

q8_0_array_t *allocate_q8_0_array(uint64_t num_elements,
                                  uint64_t block_size) {
    if (!num_elements || !block_size) return NULL;

    uint64_t num_blocks = (num_elements + block_size - 1) / block_size;
    size_t total = sizeof(q8_0_array_t)
                 + num_blocks * sizeof(float)
                 + num_elements * sizeof(int8_t);

    q8_0_array_t *qa = (q8_0_array_t *)calloc(1, total);
    if (!qa) return NULL;

    qa->num_elements = num_elements;
    qa->num_blocks   = num_blocks;
    qa->block_size   = block_size;

    qa->scales = (float *)(qa + 1);
    qa->data   = (int8_t *)(qa->scales + num_blocks);
    return qa;
}

void free_q8_0_array(q8_0_array_t *q8_0_array) {
    if (!q8_0_array) return;
    free(q8_0_array);
}

int64_t get_q8_0_array(const q8_0_array_t *q8_0_array) {
    return _get_q8_0_array_size(q8_0_array);
}

q8_0_array_t *load_quantized_array_from_buffer(const void *buffer, int64_t buffer_size) {
    if (!buffer || buffer_size < (int64_t)sizeof(q8_0_array_t)) return NULL;

    q8_0_array_t *q8_0_array = (q8_0_array_t *)calloc(1, buffer_size);
    if (!q8_0_array) return NULL;

    memcpy(q8_0_array, buffer, buffer_size);
    const int64_t expected = _get_q8_0_array_size(q8_0_array);
    if (buffer_size < expected) {
        free(q8_0_array);
        return NULL;
    }

    q8_0_array->scales = (float *)(q8_0_array + 1);
    q8_0_array->data   = (int8_t *)(q8_0_array->scales + q8_0_array->num_blocks);
    return q8_0_array;
}

static int _quantize_q8_0(const float *float_array, q8_0_array_t *q8_0_array) {
    if (!float_array || !q8_0_array) return 1;

    const uint64_t block_size   = q8_0_array->block_size;
    const uint64_t num_blocks   = q8_0_array->num_blocks;
    const uint64_t num_elements = q8_0_array->num_elements;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);

        float abs_max = 0.0f;
        for (uint64_t i = 0; i < remain; ++i) {
            float v = fabsf(float_array[start + i]);
            if (v > abs_max) abs_max = v;
        }

        float scale = (abs_max > 0.0f) ? (abs_max / 127.0f) : 0.0f;
        float inv_scale = (scale > 0.0f) ? (1.0f / scale) : 0.0f;
        q8_0_array->scales[b] = scale;

        for (uint64_t i = 0; i < remain; ++i) {
            float val = float_array[start + i] * inv_scale;
            long qi   = lrintf(val);
            if (qi < -127) qi = -127;
            if (qi >  127) qi =  127;
            q8_0_array->data[start + i] = (int8_t)qi;
        }
    }
    return 0;
}

int q8_0_compress(const float *float_array,
             uint64_t num_elements,
             q8_0_array_t **q8_0_array) {
    if (!float_array || num_elements == 0 || !q8_0_array || *q8_0_array) return 1;

    *q8_0_array = allocate_q8_0_array(num_elements, DEFAULT_Q8_0_BLOCK_SIZE);
    if (!*q8_0_array) return 1;

    return _quantize_q8_0(float_array, *q8_0_array);
}

int q8_0_decompress(const q8_0_array_t *q8_0_array,
               float *float_array) {
    if (!q8_0_array || !float_array) return 1;

    const uint64_t block_size   = q8_0_array->block_size;
    const uint64_t num_blocks   = q8_0_array->num_blocks;
    const uint64_t num_elements = q8_0_array->num_elements;

    for (uint64_t b = 0; b < num_blocks; ++b) {
        const uint64_t start = b * block_size;
        const uint64_t remain = (start + block_size <= num_elements)
                                  ? block_size
                                  : (num_elements - start);
        const float scale = q8_0_array->scales[b];

        for (uint64_t i = 0; i < remain; ++i) {
            float_array[start + i] = scale * (float)q8_0_array->data[start + i];
        }
    }
    return 0;
}



================================================
FILE: src/sparsity_quantization/topk_impl.c
================================================
#include "sparsity/topk_impl.h"

sparse_array_t *allocate_sparse_array(uint16_t num_tokens, uint16_t num_features, float sparse_ratio) {
    if (!num_tokens || !num_features) return NULL;
    if (sparse_ratio < 0.0f || sparse_ratio > 1.0f) return NULL;
    
    float raw_sparse = (float)num_features * sparse_ratio;
    uint16_t num_sparse_features = (uint16_t)roundf(raw_sparse);
    
    // clamp to valid range
    if (num_sparse_features > num_features) {
        num_sparse_features = num_features;
    } else if (num_sparse_features == 0 && sparse_ratio > 0.0f) {
        num_sparse_features = 1;  // Avoid total sparsity if ratio positive;
    }

    uint32_t sparse_elements = (uint32_t)num_tokens * num_sparse_features;
    uint64_t total = sizeof(sparse_array_t) + sparse_elements * (sizeof(float) + sizeof(uint16_t));
    sparse_array_t *sparse_array = (sparse_array_t*)calloc(1, total);
    if (!sparse_array) return NULL;

    /* initialise the header fields */
    sparse_array->num_tokens = num_tokens;
    sparse_array->num_features = num_features;
    sparse_array->num_sparse_features = num_sparse_features;
    sparse_array->sparse_indices = (uint16_t*)(sparse_array + 1);    /* just after the header */
    sparse_array->values = (float*)(sparse_array->sparse_indices + sparse_elements);     /* after the sparse_indices */

    return sparse_array;
}                          

void free_sparse_array(sparse_array_t *sparse_array) {
    if (!sparse_array) return;
    free(sparse_array);
}

uint64_t get_sparse_array_size(const sparse_array_t *sparse_array) {
    if (!sparse_array) return 0;

    uint32_t sparse_elements = (uint32_t)sparse_array->num_tokens * sparse_array->num_sparse_features;
    
    return sizeof(sparse_array_t) + sparse_elements * (sizeof(float) + sizeof(uint16_t));
}

sparse_array_t *load_sparse_array_from_buffer(const void *buffer, uint64_t buffer_size) {
    sparse_array_t *sparse_array = (sparse_array_t*)calloc(1, buffer_size);
    if (!sparse_array) return NULL;
    
    memcpy(sparse_array, buffer, buffer_size);

    uint32_t sparse_elements = (uint32_t)sparse_array->num_tokens * sparse_array->num_sparse_features;

    sparse_array->sparse_indices   = (uint16_t*)(sparse_array + 1);
    sparse_array->values = (float*)(sparse_array->sparse_indices + sparse_elements);

    return sparse_array;
}

typedef struct {
    uint16_t index;
    float abs_val;
} sort_entry_t;

static int abs_sort_cmp(const void *a, const void *b) {
    const float abs_a = ((const sort_entry_t *)a)->abs_val;
    const float abs_b = ((const sort_entry_t *)b)->abs_val;
    if (abs_a != abs_b) {
        return (abs_a > abs_b) ? -1 : 1;
    }
    const uint16_t idx_a = ((const sort_entry_t *)a)->index;
    const uint16_t idx_b = ((const sort_entry_t *)b)->index;
    return (int)idx_a - (int)idx_b;
}

int topk_compress(const float *float_array, uint16_t num_tokens, uint16_t num_features, float sparse_ratio, sparse_array_t **sparse_array) {
    if (!float_array || num_tokens == 0 || num_features == 0 || *sparse_array) return 1;

    /* ---- allocate sparse ------------------------------------------ */
    *sparse_array = allocate_sparse_array(num_tokens, num_features, sparse_ratio);
    if (!*sparse_array) return 1;

// #pragma omp parallel for
    for (uint16_t cur_token_index = 0; cur_token_index < num_tokens; cur_token_index++) {
        sort_entry_t *entries = (sort_entry_t *)malloc(num_features * sizeof(sort_entry_t));
        
        uint32_t dense_base = (uint32_t)cur_token_index * num_features;
        uint32_t sparse_base = (uint32_t)cur_token_index * (*sparse_array)->num_sparse_features;

        for (uint16_t i = 0; i < num_features; i++) {
            entries[i].index = i;
            entries[i].abs_val = fabsf(float_array[dense_base + i]);
        }
        qsort(entries, num_features, sizeof(sort_entry_t), abs_sort_cmp);
        
        for (uint16_t keep_feature_index = 0; keep_feature_index < (*sparse_array)->num_sparse_features; keep_feature_index++) {
            uint16_t orig_index = entries[keep_feature_index].index;
            (*sparse_array)->sparse_indices[sparse_base + keep_feature_index] = orig_index;
            (*sparse_array)->values[sparse_base + keep_feature_index] = float_array[dense_base + orig_index];
        }

        free(entries);
    }

    return 0;
}

int topk_decompress(const sparse_array_t *sparse_array, float *float_array) {
    if (!float_array || !sparse_array) return 1;

    uint32_t num_elements = (uint32_t)sparse_array->num_tokens * sparse_array->num_features;
    memset(float_array, 0, num_elements * sizeof(float));

    for (uint16_t cur_token_index = 0; cur_token_index < sparse_array->num_tokens; cur_token_index++) {
        uint32_t dense_base = (uint32_t)cur_token_index * sparse_array->num_features;
        uint32_t sparse_base = (uint32_t)cur_token_index * sparse_array->num_sparse_features;

        for (uint16_t keep_feature_index = 0; keep_feature_index < sparse_array->num_sparse_features; keep_feature_index++) {
            uint16_t original_feature_index = sparse_array->sparse_indices[sparse_base + keep_feature_index];
            float_array[dense_base + original_feature_index] = sparse_array->values[sparse_base + keep_feature_index];
        }
    }

    return 0;
}



================================================
FILE: src/utils/random.c
================================================
#include "utils/random.h"

float **gen_random_float_arrays(uint64_t count,
                                uint64_t N,
                                float minv,
                                float maxv,
                                unsigned int seed) {
    if (!count || !N || !isfinite(minv) || !isfinite(maxv) || maxv < minv)
        return NULL;

    if (!seed) seed = (unsigned int)time(NULL);
    srand(seed);

    float **arrs = calloc(count, sizeof(*arrs));
    if (!arrs) return NULL;

    for (uint64_t i = 0; i < count; ++i) {
        arrs[i] = malloc(N * sizeof(float));
        if (!arrs[i]) {
            for (uint64_t j = 0; j < i; ++j) free(arrs[j]);
            free(arrs);
            return NULL;
        }
        for (uint64_t j = 0; j < N; ++j) {
            float u = (float)rand() / (float)RAND_MAX;
            arrs[i][j] = minv + u * (maxv - minv);
        }
    }
    return arrs;
}

void free_random_float_arrays(float **arrs, uint64_t count) {
    if (!arrs) return;
    for (uint64_t i = 0; i < count; ++i) free(arrs[i]);
    free(arrs);
}



================================================
FILE: test/test_bf16_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;

        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, BF16, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;

        if (c_res || !buf) {
            fprintf(stderr, "bf16 compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for bf16 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        // PROFILE DECOMPRESS
        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;

        if (d_res) {
            fprintf(stderr, "bf16 decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   BF16: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_fp16_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, FP16, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "fp16 compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for fp16 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "fp16 decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   FP16: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_fp4_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, FP4, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "fp4 compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for fp4 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "fp4 decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   FP4: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("        CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_fp8_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, FP8, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "fp8 compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for fp8 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "fp8 decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   FP8: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("        CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_iq2_s_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;
    const uint64_t N   = 4194304;
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    iq2_s_init();

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, IQ2_S, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "IQ2_S compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            iq2_s_free_tables();
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "IQ2_S decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   IQ2_S: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("          CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    iq2_s_free_tables();
    
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_iq2_xs_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;
    const uint64_t N   = 4194304;
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    iq2_xs_init();

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, IQ2_XS, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "IQ2_XS compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            iq2_xs_free_tables();
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "IQ2_XS decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   IQ2_XS: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("          CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    iq2_xs_free_tables();
    
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_iq2_xxs_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;
    const uint64_t N   = 4194304;
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    /* Initialize IQ2 tables */
    iq2_xxs_init();

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, IQ2_XXS, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "IQ2_XXS compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for IQ2_XXS dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            iq2_xxs_free_tables();
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "IQ2_XXS decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   IQ2_XXS: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("           CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    iq2_xxs_free_tables();
    
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_mxfp4_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, MXFP4, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "mxfp4 compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for mxfp4 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "mxfp4 decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   MXFP4: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_mxfp8_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, MXFP8, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "mxfp8 compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for mxfp8 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "mxfp8 decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   MXFP8: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_nf4_dq_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, NF4_DQ, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "nf4_dq compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for nf4_dq dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "nf4_dq decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   NF4_DQ: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("          CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_nf4_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, NF4, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "nf4 compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for nf4 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "nf4 decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   NF4: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("        CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_nvfp4_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, NVFP4, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "nvfp4 compress failed on array %" PRIu64 "\n", (uint64_t)k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for nvfp4 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "nvfp4 decompress failed on array %" PRIu64 "\n", (uint64_t)k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %llu] N=%llu, original_size=%.3f KB\n",
               (uint64_t)k, (uint64_t)N, N * sizeof(float) / 1024.0);
        printf("   NVFP4: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_q2_k_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X    = 5;            /* number of random arrays */
    const uint64_t N    = 4194304;      /* length of each array    */
    const float  MINV   = -10.0f;
    const float  MAXV   =  10.0f;
    const unsigned int SEED = 12345;    /* deterministic seed      */

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    printf("Testing Q2_K via bitsqueeze (super-block %d, block %d)\n",
           WEIGHT_PER_SUPER_BLOCK, Q2_K_BLOCK_SIZE);

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, Q2_K, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "q2_k compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for q2_k dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "q2_k decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("    Q2_K: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("          CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_q4_0_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays */
    const uint64_t N   = 4194304;      /* length of each array    */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;   /* deterministic seed      */

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, Q4_0, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "q4_0 compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for q4_0 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "q4_0 decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   Q4_0: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_q8_0_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X   = 5;            /* number of random arrays            */
    const uint64_t N   = 4194304;      /* length of each array               */
    const float  MINV  = -10.0f;
    const float  MAXV  =  10.0f;
    const unsigned int SEED = 12345;

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        bitsqueeze_buffer_t *buf = NULL;
        double t0 = get_time_ms();
        int c_res = bsq_compress_1d(inputs[k], N, Q8_0, &buf);
        double t1 = get_time_ms();
        double comp_time = t1 - t0;
        if (c_res || !buf) {
            fprintf(stderr, "q8_0 compress failed on array %" PRIu64 "\n", k);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        float *deq = (float *)malloc(N * sizeof(float));
        if (!deq) {
            fprintf(stderr, "malloc failed for q8_0 dequant buffer\n");
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double t2 = get_time_ms();
        int d_res = bsq_decompress(buf, deq, N);
        double t3 = get_time_ms();
        double decomp_time = t3 - t2;
        if (d_res) {
            fprintf(stderr, "q8_0 decompress failed on array %" PRIu64 "\n", k);
            free(deq);
            bsq_free(buf);
            free_random_float_arrays(inputs, X);
            return EXIT_FAILURE;
        }

        double mae, mse, maxabs;
        measure_metrics(inputs[k], deq, N, &mae, &mse, &maxabs);

        double size_kb = bsq_get_packed_size(buf) / 1024.0;
        double bw = 8.0 * size_kb * 1024.0 / (double)N;

        printf("[array %" PRIu64 "] N=%" PRIu64 ", original_size=%.3f KB\n",
               k, N, N * sizeof(float) / 1024.0);
        printf("   Q8_0: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
               size_kb, bw, mae, mse, maxabs);
        printf("         CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

        free(deq);
        bsq_free(buf);
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/test_topk_impl.c
================================================
#include <stdio.h>
#include <stdlib.h>
#include <stdint.h>
#include <math.h>

#include "bitsqueeze.h"
#include "utils/random.h"
#include "utils/evaluation.h"
#include <inttypes.h>

int main(void) {
    const uint64_t X              = 5;              /* number of random arrays            */
    const uint16_t NUM_TOKENS     = 512;            /* rows in 2D shape                   */
    const uint16_t NUM_FEATURES   = 8192;           /* columns in 2D shape                */
    const uint64_t N              = (uint64_t)NUM_TOKENS * NUM_FEATURES;
    const float  MINV             = -10.0f;
    const float  MAXV             =  10.0f;
    const unsigned int SEED       = 12345;          /* deterministic seed                 */
    const float  SPARSE_RATIOS[]  = {0.2f, 0.1f};   /* sparsity levels to evaluate        */
    const size_t NUM_RATIOS       = sizeof(SPARSE_RATIOS) / sizeof(SPARSE_RATIOS[0]);

    float **inputs = gen_random_float_arrays(X, N, MINV, MAXV, SEED);
    if (!inputs) {
        fprintf(stderr, "failed to allocate random inputs\n");
        return EXIT_FAILURE;
    }

    for (uint64_t k = 0; k < X; ++k) {
        printf("[array %" PRIu64 "] N=%" PRIu64 " (tokens=%u, features=%u), original_size=%.3f KB\n",
               k, N, NUM_TOKENS, NUM_FEATURES, N * sizeof(float) / 1024.0);

        for (size_t r = 0; r < NUM_RATIOS; ++r) {
            const float sparse_ratio = SPARSE_RATIOS[r];

            bitsqueeze_buffer_t *buf = NULL;
            double t0 = get_time_ms();
            int c_res = bsq_compress_2d(inputs[k], NUM_TOKENS, NUM_FEATURES, sparse_ratio, TOPK, &buf);
            double t1 = get_time_ms();
            double comp_time = t1 - t0;
            if (c_res || !buf) {
                fprintf(stderr, "TOPK compress failed for array %" PRIu64 ", ratio %.2f\n", k, sparse_ratio);
                free_random_float_arrays(inputs, X);
                return EXIT_FAILURE;
            }

            float *decomp = malloc(N * sizeof(float));
            if (!decomp) {
                fprintf(stderr, "malloc failed for decomp buffer (array %" PRIu64 ", ratio %.2f)\n", k, sparse_ratio);
                bsq_free(buf);
                free_random_float_arrays(inputs, X);
                return EXIT_FAILURE;
            }

            double t2 = get_time_ms();
            int d_res = bsq_decompress(buf, decomp, N);
            double t3 = get_time_ms();
            double decomp_time = t3 - t2;
            if (d_res) {
                fprintf(stderr, "TOPK decompress failed for array %" PRIu64 ", ratio %.2f\n", k, sparse_ratio);
                free(decomp);
                bsq_free(buf);
                free_random_float_arrays(inputs, X);
                return EXIT_FAILURE;
            }

            double mae, mse, maxabs;
            measure_metrics(inputs[k], decomp, N, &mae, &mse, &maxabs);

            double size_kb = bsq_get_packed_size(buf) / 1024.0;
            double bw = 8.0 * size_kb * 1024.0 / (double)N;
            const sparse_array_t *arr = (const sparse_array_t *)buf->payload;
            double sparsity_ratio_actual = (double)arr->num_sparse_features / (double)arr->num_features;

            printf("   TOPK%.2f: sparsity=%.3f, size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
                   sparse_ratio, sparsity_ratio_actual, size_kb, bw, mae, mse, maxabs);
            printf("            CompTime=%.3f ms, DecompTime=%.3f ms\n", comp_time, decomp_time);

            free(decomp);
            bsq_free(buf);
        }
        printf("\n");
    }

    free_random_float_arrays(inputs, X);
    return EXIT_SUCCESS;
}



================================================
FILE: test/legacy/test_activation_example.c
================================================
// #include <stdio.h>
// #include <stdlib.h>
// #include <stdint.h>
// #include <math.h>
// #include <string.h>

// #include "quantization.h"
// #include "sparsity.h"
// #include "k_quantization.h"

// static void measure_metrics(const float *orig, const float *decomp, uint64_t N,
//                             double *mae, double *mse, double *max_abs) {
//     double m = 0.0, s = 0.0, mx = 0.0;
//     for (uint64_t i = 0; i < N; ++i) {
//         double e = (double)decomp[i] - (double)orig[i];
//         double ae = fabs(e);
//         m   += ae;
//         s   += e * e;
//         if (ae > mx) mx = ae;
//     }
//     *mae     = m / (double)N;
//     *mse     = s / (double)N;
//     *max_abs = mx;
// }

// /* Write decompressed data back to binary file in original format. */
// static int write_recovered_binary(const char *filename, uint8_t type, uint64_t n_embed, uint64_t n_tokens,
//                                   uint64_t tensor_size, const float *data) {
//     FILE *fp = fopen(filename, "wb");
//     if (!fp) {
//         fprintf(stderr, "Failed to open output file %s\n", filename);
//         return -1;
//     }
//     if (fwrite(&type, sizeof(uint8_t), 1, fp) != 1 ||
//         fwrite(&n_embed, sizeof(uint64_t), 1, fp) != 1 ||
//         fwrite(&n_tokens, sizeof(uint64_t), 1, fp) != 1 ||
//         fwrite(&tensor_size, sizeof(uint64_t), 1, fp) != 1) {
//         fprintf(stderr, "Failed to write header to %s\n", filename);
//         fclose(fp);
//         return -1;
//     }
//     if (fwrite(data, 1, tensor_size, fp) != tensor_size) {
//         fprintf(stderr, "Failed to write tensor data to %s\n", filename);
//         fclose(fp);
//         return -1;
//     }
//     fclose(fp);
//     return 0;
// }

// int main(void) {
//     const char *infile = "example/activation_112_3584.bin";
//     FILE *fp = fopen(infile, "rb");
//     if (!fp) {
//         fprintf(stderr, "Failed to open input file %s\n", infile);
//         return EXIT_FAILURE;
//     }

//     /* Read header */
//     uint8_t type;
//     uint64_t n_embed, n_tokens, tensor_size;
//     if (fread(&type, sizeof(uint8_t), 1, fp) != 1 ||
//         fread(&n_embed, sizeof(uint64_t), 1, fp) != 1 ||
//         fread(&n_tokens, sizeof(uint64_t), 1, fp) != 1 ||
//         fread(&tensor_size, sizeof(uint64_t), 1, fp) != 1) {
//         fprintf(stderr, "Failed to read header from %s\n", infile);
//         fclose(fp);
//         return EXIT_FAILURE;
//     }

//     if (type != 0) {
//         fprintf(stderr, "Unsupported element type: %u (expected 0 for FLOAT32)\n", type);
//         fclose(fp);
//         return EXIT_FAILURE;
//     }

//     uint64_t N = n_tokens * n_embed;
//     if (tensor_size != N * sizeof(float)) {
//         fprintf(stderr, "Tensor size mismatch: expected %" PRIu64 " bytes, got %" PRIu64 "\n",
//                 (unsigned long)(N * sizeof(float)), (unsigned long)tensor_size);
//         fclose(fp);
//         return EXIT_FAILURE;
//     }

//     float *orig = (float *)malloc(N * sizeof(float));
//     if (!orig) {
//         fprintf(stderr, "Failed to allocate original data buffer\n");
//         fclose(fp);
//         return EXIT_FAILURE;
//     }

//     if (fread(orig, sizeof(float), N, fp) != N) {
//         fprintf(stderr, "Failed to read tensor data from %s\n", infile);
//         free(orig);
//         fclose(fp);
//         return EXIT_FAILURE;
//     }
//     fclose(fp);

//     printf("Loaded real example: tokens=%" PRIu64 ", embed=%" PRIu64 ", N=%" PRIu64 "\n",
//            (unsigned long)n_tokens, (unsigned long)n_embed, (unsigned long)N);

//     /* Quantization: q8_0 and q4_0 */
//     {
//         const int qtypes[]   = {0 /*q8_0*/, 1 /*q4_0*/};
//         const char *qnames[] = {"q8_0", "q4_0"};

//         for (size_t i = 0; i < 2; ++i) {
//             const int qtype = qtypes[i];
//             const char *qname = qnames[i];
//             char outfile[64];
//             snprintf(outfile, sizeof(outfile), "%s.bin", qname);

//             quantized_array_t *qa = NULL;
//             if (quantize(orig, N, qtype, &qa) || !qa) {
//                 fprintf(stderr, "%s quantization failed\n", qname);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             float *rec = (float *)malloc(N * sizeof(float));
//             if (!rec) {
//                 fprintf(stderr, "Malloc failed for %s recovery buffer\n", qname);
//                 free_quantized_array(qa);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             if (dequantize(qa, rec)) {
//                 fprintf(stderr, "%s dequantization failed\n", qname);
//                 free(rec);
//                 free_quantized_array(qa);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double mae, mse, maxabs;
//             measure_metrics(orig, rec, N, &mae, &mse, &maxabs);

//             if (write_recovered_binary(outfile, type, n_embed, n_tokens, tensor_size, rec) != 0) {
//                 fprintf(stderr, "Failed to write %s\n", outfile);
//                 free(rec);
//                 free_quantized_array(qa);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double size_kb = get_quantized_array_size(qa) / 1024.0;
//             double bw = 8.0 * size_kb * 1024.0 / (double)N;
//             printf("   %s: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
//                    qname, size_kb, bw, mae, mse, maxabs);

//             free(rec);
//             free_quantized_array(qa);
//         }
//     }

//     /* Quantization: Q2_K (K-quant style, fp32 super params) */
//     {
//         if (N % WEIGHT_PER_SUPER_BLOCK != 0) {
//             /* Prevent out-of-bounds writes with current k_dequantize implementation. */
//             fprintf(stderr,
//                     "Q2_K skipped: N (%" PRIu64 ") must be a multiple of %d to be safe with current k_dequantize.\n",
//                     (unsigned long)N, WEIGHT_PER_SUPER_BLOCK);
//         } else {
//             const char *qname = "Q2_K";
//             const char *outfile = "q2_k.bin";

//             quantized_array_q2_k_t *qk = NULL;
//             if (k_quantize(orig, N, &qk) || !qk) {
//                 fprintf(stderr, "q2_k quantization failed\n");
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             float *rec = (float *)malloc(N * sizeof(float));
//             if (!rec) {
//                 fprintf(stderr, "Malloc failed for q2_k recovery buffer\n");
//                 free_quantized_q2_k_array(qk);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             if (k_dequantize(qk, rec)) {
//                 fprintf(stderr, "q2_k dequantization failed\n");
//                 free(rec);
//                 free_quantized_q2_k_array(qk);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double mae, mse, maxabs;
//             measure_metrics(orig, rec, N, &mae, &mse, &maxabs);

//             if (write_recovered_binary(outfile, type, n_embed, n_tokens, tensor_size, rec) != 0) {
//                 fprintf(stderr, "Failed to write %s\n", outfile);
//                 free(rec);
//                 free_quantized_q2_k_array(qk);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double size_kb = get_quantized_q2_k_array_size(qk) / 1024.0;
//             double bw = 8.0 * size_kb * 1024.0 / (double)N;
//             printf("   %s: size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
//                    qname, size_kb, bw, mae, mse, maxabs);

//             free(rec);
//             free_quantized_q2_k_array(qk);
//         }
//     }

//     /* Sparsity variants */
//     {
//         const float ratios[] = {0.20f, 0.10f};
//         const char *rnames[] = {"sparse0.20", "sparse0.10"};

//         for (size_t i = 0; i < 2; ++i) {
//             float ratio = ratios[i];
//             const char *rname = rnames[i];
//             char outfile[64];
//             snprintf(outfile, sizeof(outfile), "%s.bin", rname);

//             sparse_array_t *sparse = NULL;
//             if (compress(orig, (uint16_t)n_tokens, (uint16_t)n_embed, ratio, &sparse)) {
//                 fprintf(stderr, "%s compression failed\n", rname);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             float *rec = (float *)malloc(N * sizeof(float));
//             if (!rec) {
//                 fprintf(stderr, "Malloc failed for %s recovery buffer\n", rname);
//                 free_sparse_array(sparse);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             if (decompress(sparse, rec)) {
//                 fprintf(stderr, "%s decompression failed\n", rname);
//                 free(rec);
//                 free_sparse_array(sparse);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double mae, mse, maxabs;
//             measure_metrics(orig, rec, N, &mae, &mse, &maxabs);

//             if (write_recovered_binary(outfile, type, n_embed, n_tokens, tensor_size, rec) != 0) {
//                 fprintf(stderr, "Failed to write %s\n", outfile);
//                 free(rec);
//                 free_sparse_array(sparse);
//                 free(orig);
//                 return EXIT_FAILURE;
//             }

//             double sparsity_actual = (double)sparse->num_sparse_features / (double)sparse->num_features;
//             double size_kb = get_sparse_array_size(sparse) / 1024.0;
//             double bw = 8.0 * size_kb * 1024.0 / (double)N;
//             printf("   %s: sparsity=%.3f, size=%.3f KB, B/W=%.5f, MAE=%.6f, MSE=%.6f, MaxAbs=%.6f\n",
//                    rname, sparsity_actual, size_kb, bw, mae, mse, maxabs);

//             free(rec);
//             free_sparse_array(sparse);
//         }
//     }

//     free(orig);
//     return EXIT_SUCCESS;
// }



================================================
FILE: test/legacy/test_bf16_datatype.c
================================================
#include <stdio.h>
#include <stdint.h>
#include <string.h>
#include <math.h>
#include "datatype/bf16.h"

// --- Globals for test summary ---
static int global_pass_count = 0;
static int global_fail_count = 0;

// --- Helper functions for float/u32 conversion ---

/**
 * @brief Re-interprets a 32-bit unsigned integer as a 32-bit float.
 */
static float float_from_u32(uint32_t u) {
    float f;
    memcpy(&f, &u, sizeof(f));
    return f;
}

/**
 * @brief Re-interprets a 32-bit float as a 32-bit unsigned integer.
 */
static uint32_t u32_from_float(float f) {
    uint32_t u;
    memcpy(&u, &f, sizeof(u));
    return u;
}

// --- Test functions ---

/**
 * @brief Tests the FP32 -> BF16 (rounding) conversion.
 */
void test_fp32_to_bf16(float f_in, uint16_t u_expected, const char* test_name) {
    uint16_t u_actual = bf16_from_fp32_value(f_in);
    
    if (u_actual == u_expected) {
        printf("[PASS] %s\n", test_name);
        global_pass_count++;
    } else {
        printf("[FAIL] %s: Input=%.10f (0x%08X), Expected=0x%04X, Got=0x%04X\n",
               test_name, f_in, u32_from_float(f_in), u_expected, u_actual);
        global_fail_count++;
    }
}

/**
 * @brief Tests the BF16 -> FP32 (expansion) conversion.
 */
void test_bf16_to_fp32(uint16_t u_in, float f_expected, const char* test_name) {
    float f_actual = fp32_from_bf16_value(u_in);
    
    // This conversion should be exact, so a direct bit-level check is fine.
    if (u32_from_float(f_actual) == u32_from_float(f_expected)) {
        printf("[PASS] %s\n", test_name);
        global_pass_count++;
    } else {
        printf("[FAIL] %s: Input=0x%04X, Expected=%.10f (0x%08X), Got=%.10f (0x%08X)\n",
               test_name, u_in, f_expected, u32_from_float(f_expected), 
               f_actual, u32_from_float(f_actual));
        global_fail_count++;
    }
}


int main(void) {
    printf("--- Starting BF16 Conversion Tests ---\n\n");

    // === Test 1: BF16 -> FP32 (Expansion) ===
    // This function is simpler and just adds 16 zero bits.
    printf("--- Testing bf16_from_fp32_value (BF16 -> FP32) ---\n");
    test_bf16_to_fp32(0x0000, 0.0f,          "BF16->FP32: Positive Zero");
    test_bf16_to_fp32(0x8000, -0.0f,         "BF16->FP32: Negative Zero");
    test_bf16_to_fp32(0x3F80, 1.0f,          "BF16->FP32: 1.0");
    test_bf16_to_fp32(0x4000, 2.0f,          "BF16->FP32: 2.0");
    test_bf16_to_fp32(0xC000, -2.0f,         "BF16->FP32: -2.0");
    test_bf16_to_fp32(0x7F80, INFINITY,      "BF16->FP32: Positive Infinity");
    test_bf16_to_fp32(0xFF80, -INFINITY,     "BF16->FP32: Negative Infinity");
    test_bf16_to_fp32(0x7FC0, NAN,           "BF16->FP32: Quiet NaN (qNaN)");
    test_bf16_to_fp32(0x420C, 35.0f,         "BF16->FP32: 35.0"); // 0x420C0000
    test_bf16_to_fp32(0x3DCD,                // 0.10009765625
                      float_from_u32(0x3DCD0000), 
                                             "BF16->FP32: 0.1 (approx)");

    // === Test 2: FP32 -> BF16 (Rounding) ===
    // This tests the complex RNE logic.
    printf("\n--- Testing bf16_from_fp32_value (FP32 -> BF16) ---\n");
    test_fp32_to_bf16(0.0f, 0x0000,          "FP32->BF16: Positive Zero");
    test_fp32_to_bf16(-0.0f, 0x8000,         "FP32->BF16: Negative Zero");
    test_fp32_to_bf16(1.0f, 0x3F80,          "FP32->BF16: 1.0 (no rounding)");
    test_fp32_to_bf16(INFINITY, 0x7F80,      "FP32->BF16: Positive Infinity");
    test_fp32_to_bf16(-INFINITY, 0xFF80,     "FP32->BF16: Negative Infinity");
    test_fp32_to_bf16(NAN, 0x7FC0,           "FP32->BF16: Quiet NaN (qNaN)");

    // --- RNE: Rounding Down ---
    test_fp32_to_bf16(float_from_u32(0x3F800001), 0x3F80, "RNE: Round Down (small fraction)");
    test_fp32_to_bf16(float_from_u32(0x3F807FFF), 0x3F80, "RNE: Round Down (just below half)");
    
    // --- RNE: Rounding Up ---
    test_fp32_to_bf16(float_from_u32(0x3F808001), 0x3F81, "RNE: Round Up (just above half)");
    test_fp32_to_bf16(float_from_u32(0x3F80FFFF), 0x3F81, "RNE: Round Up (large fraction)");

    // --- RNE: Tie-Breaking (These will likely FAIL with your code) ---
    printf("\n--- RNE Tie-Breaking Tests (EXPECTED TO FAIL with original code) ---\n");
    // Input 0x3F808000: Exactly halfway. LSB of 0x3F80 is 0 (even).
    // Should round DOWN to even.
    test_fp32_to_bf16(float_from_u32(0x3F808000), 0x3F80, 
        "[!!] RNE: Tie-to-Even (0x3F808000 -> 0x3F80)");

    // Input 0x3F818000: Exactly halfway. LSB of 0x3F81 is 1 (odd).
    // Should round UP to even (0x3F82).
    test_fp32_to_bf16(float_from_u32(0x3F818000), 0x3F82, 
        "[!!] RNE: Tie-to-Even (0x3F818000 -> 0x3F82)");

    // Input 0x3F828000: Exactly halfway. LSB of 0x3F82 is 0 (even).
    // Should round DOWN to even.
    test_fp32_to_bf16(float_from_u32(0x3F828000), 0x3F82, 
        "[!!] RNE: Tie-to-Even (0x3F828000 -> 0x3F82)");

    // Input 0x3F838000: Exactly halfway. LSB of 0x3F83 is 1 (odd).
    // Should round UP to even (0x3F84).
    test_fp32_to_bf16(float_from_u32(0x3F838000), 0x3F84, 
        "[!!] RNE: Tie-to-Even (0x3F838000 -> 0x3F84)");


    // --- Summary ---
    printf("\n--- Test Summary ---\n");
    printf("Total Tests: %d\n", global_pass_count + global_fail_count);
    printf("Passed:      %d\n", global_pass_count);
    printf("Failed:      %d\n", global_fail_count);
    printf("\n");

    if (global_fail_count > 0) {
        printf("NOTE: Failures in RNE Tie-Breaking tests are expected due to incorrect rounding logic in bf16.h.\n");
        return 1; // Return error code
    }


    return 0; // All tests passed
}



================================================
FILE: test/legacy/test_fp16_datatype.c
================================================
#include <stdio.h>
#include <stdint.h>
#include <math.h>
#include <string.h>
#include "datatype/fp16/fp16.h"

static uint32_t f32_bits(float x) {
  uint32_t u;
  memcpy(&u, &x, sizeof(u));
  return u;
}

int main(void) {
  float vals[] = {
    0.0f, -0.0f, 1.0f, -1.0f,
    3.1415926f, 1.0e-8f, 1.0e-4f,
    65504.0f,         /* max finite fp16 */
    INFINITY, -INFINITY, NAN
  };
  const size_t n = sizeof(vals)/sizeof(vals[0]);

  printf("C test: fp32 -> fp16 -> fp32\n");
  for (size_t i = 0; i < n; i++) {
    float f = vals[i];
    uint16_t h = fp16_ieee_from_fp32_value(f);
    float fr = fp16_ieee_to_fp32_value(h);

    double abs_err = fabs((double)f - (double)fr);
    int f_nan = isnan(f);
    int fr_nan = isnan(fr);

    printf("[%02zu] in=%-12a bits32=0x%08X  h=0x%04X  out=%-12a bits32=0x%08X",
           i, f, f32_bits(f), h, fr, f32_bits(fr));

    if (f_nan || fr_nan) {
      printf("  note=NaN case\n");
    } else {
      printf("  abs_err=%g\n", abs_err);
    }
  }
  return 0;
}


